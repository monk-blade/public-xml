<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><atom:link href="http://192.168.1.132/?platform=reddit&amp;subreddit=Python&amp;averagePostsPerDay=5&amp;content&amp;view=rss" rel="self" type="application/rss+xml"/><title>/r/Python</title><description>Hot posts in /r/Python (roughly 5 posts per day)</description><link>https://www.reddit.com/r/Python/</link><language>en-us</language><lastBuildDate>Tue, 09 Sep 2025 14:26:49 +0000</lastBuildDate><generator>Upvote RSS</generator><image><url>http://192.168.1.132//app/cache/images/styles-redditmedia-com-t5_2qh0y-styles-communityIcon_mkayghu1502d1-144x400.png</url><title>/r/Python</title><link>https://www.reddit.com/r/Python/</link><width>144</width><height>144</height></image><item><link>https://www.reddit.com/r/Python/comments/1nc7r45/python_type_system_and_tooling_survey_2025/</link><title>Python Type System and Tooling Survey 2025</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nc7r45/python_type_system_and_tooling_survey_2025/</guid><comments>https://www.reddit.com/r/Python/comments/1nc7r45/python_type_system_and_tooling_survey_2025/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1nc7r45/python_type_system_and_tooling_survey_2025/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>This survey was developed with support from the Pyrefly team at Meta, the PyCharm team at JetBrains, and the typing community on discourse.python.org. No typing experience needed -- your perspective as a Python dev matters most. Take a couple minutes to help improve Python typing for all:</p><p><a href="https://docs.google.com/forms/d/e/1FAIpQLSeOFkLutxMLqsU6GPe60OJFYVN699vqjXPtuvUoxbz108eDWQ/viewform?fbzx=-4095906651778441520">https://docs.google.com/forms/d/e/1FAIpQLSeOFkLutxMLqsU6GPe60OJFYVN699vqjXPtuvUoxbz108eDWQ/viewform?fbzx=-4095906651778441520</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Tue, 09 Sep 2025 08:24:32 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nblyt6/webscraping_twitter_or_any/</link><title>Webscraping twitter or any</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nblyt6/webscraping_twitter_or_any/</guid><comments>https://www.reddit.com/r/Python/comments/1nblyt6/webscraping_twitter_or_any/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1nblyt6/webscraping_twitter_or_any/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>So I was trying to learn webscraping. I was following a github repo project based learning. The methods were outdated so the libraries were. It was snscrape. I found the twitter&#39;s own mining api but after one try it was not working . It had rate limit. I searched for few and found playwright and selenium . I only want to learn how to get the data and convert it into datasets. Later I will continue doing analysis on them for learning purpose. Can anyone suggest me something that should follow ?</p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 08 Sep 2025 17:38:58 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nbkych/stop_building_ui_frameworks_in_python/</link><title>Stop building UI frameworks in Python</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nbkych/stop_building_ui_frameworks_in_python/</guid><comments>https://www.reddit.com/r/Python/comments/1nbkych/stop_building_ui_frameworks_in_python/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1nbkych/stop_building_ui_frameworks_in_python/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>7 years back when I started coding, I used Tkinter. Then PyQt. </p><p>I spent some good 2 weeks debating if I should learn Kivy or Java for building an Android app.</p><p>Then we&#39;ve got modern ones: FastUI by Pydantic, NiceGUI (amazing project, it&#39;s the closest bet).</p><p>Python is great for a lot of things. Just stop abusing it by building (or trying to) UI with it. </p><p>Even if you ship something you&#39;ll wake up in mid of night thinking of all the weird scenarios, convincing yourself to go back to sleep since you&#39;ll find a workaround like last time. </p><p>Why I am saying this: Because I&#39;ve tried it all. I&#39;ve tried every possible way to avoid JavaScript and keep building UIs with Python.</p><p>I&#39;ve contributed to some really popular UI libraries in Python, tried inventing one back in Tkinter days. </p><p>I finally caved in and I now build UI with JavaScript, and I&#39;m happier person now. I feel more human.</p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 08 Sep 2025 16:47:22 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nbkguo/i_built_a_programming_language_interpreted_in/</link><title>I built a programming language interpreted in Python!</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nbkguo/i_built_a_programming_language_interpreted_in/</guid><comments>https://www.reddit.com/r/Python/comments/1nbkguo/i_built_a_programming_language_interpreted_in/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1nbkguo/i_built_a_programming_language_interpreted_in/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hey!</p><p>I&#39;d like to share a project I&#39;ve been working on: A functional programming language that I built entirely in Python.</p><p>I&#39;m primarily a Python developer, but I wanted to understand functional programming concepts better. Instead of just reading about them, I decided to build my own FP language from scratch. It started as a tiny DSL (domain specific language) for a specific problem (which it turned out to be terrible for!), but I enjoyed the core ideas enough to expand it into a full functional language.</p><h2>What My Project Does</h2><p>NumFu is a pure functional programming language interpreted in Python featuring:- <strong>Arbitrary precision arithmetic</strong> using <code>mpmath</code> - no floating point issues- <strong>Automatic partial application</strong> and function composition - <strong>Built-in testing syntax</strong> with readable assertions- <strong>Tail call optimization</strong> for efficient recursion- <strong>Clean syntax</strong> with only four types (Number, Boolean, List, String)</p><p>Here&#39;s a taste of the syntax:</p><p>```numfu// Functions automatically partially apply</p><blockquote><blockquote><blockquote><p>{a, b, c -&gt; a + b + c}(_, 5){a, c -&gt; a+5+c}  // Even prints as readable syntax!</p></blockquote></blockquote></blockquote><p>// Composition and pipeslet add1 = {x -&gt; x + 1},    double = {x -&gt; x * 2}in 5 |&gt; (add1 &gt;&gt; double) // 12</p><p>// Built-in testinglet square = {x -&gt; x * x} insquare(7) ---&gt; $ == 49  // ✓ passes```</p><h2>Target Audience</h2><p>This is <strong>not</strong> a production language - it&#39;s 2-5x slower than Python due to double interpretation. It&#39;s more of a learning tool for:- Teaching functional programming concepts without complex syntax- Sketching mathematical algorithms where precision matters more than speed- Understanding how interpreters work</p><h2>Comparison</h2><p>NumFu has much simpler syntax than traditional functional languages like Haskell or ML and no complex type system - just four basic types. It&#39;s less powerful but much more approachable. I designed it to make FP concepts accessible without getting bogged down in advanced language features. Think of it as functional programming with training wheels.</p><h2>Implementation Details</h2><p>The implementation is about 3,500 lines of Python using:- <em>Lark</em> for parsing- <em>Tree-walking interpreter</em> - straightforward recursive evaluation<br/>- <em>mpmath</em> for arbitrary precision arithmetic</p><h2>Try It Out</h2><p><code>bashpip install numfu-langnumfu repl</code></p><h2>Links</h2><p>I actually enjoy web design, so NumFu has a (probably overly fancy) landing page + documentation site. 😅</p><ul><li>GitHub: <a href="https://github.com/rphle/numfu">https://github.com/rphle/numfu</a><br/></li><li>Website: <a href="https://rphle.github.io/numfu/">https://rphle.github.io/numfu/</a></li><li>Documentation: <a href="https://rphle.github.io/numfu/docs">https://rphle.github.io/numfu/docs</a></li><li>PyPI: <a href="https://pypi.org/project/numfu-lang/">https://pypi.org/project/numfu-lang/</a></li></ul><p>I built this as a learning exercise and it&#39;s been fun to work on. Happy to answer questions about design choices or implementation details! I also really appreciate issues and pull requests!</p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 08 Sep 2025 16:20:58 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nb8x34/monday_daily_thread_project_ideas/</link><title>Monday Daily Thread: Project ideas!</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nb8x34/monday_daily_thread_project_ideas/</guid><comments>https://www.reddit.com/r/Python/comments/1nb8x34/monday_daily_thread_project_ideas/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1nb8x34/monday_daily_thread_project_ideas/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><h1>Weekly Thread: Project Ideas 💡</h1><p>Welcome to our weekly Project Ideas thread! Whether you&#39;re a newbie looking for a first project or an expert seeking a new challenge, this is the place for you.</p><h2>How it Works:</h2><ol><li><strong>Suggest a Project</strong>: Comment your project idea—be it beginner-friendly or advanced.</li><li><strong>Build &amp; Share</strong>: If you complete a project, reply to the original comment, share your experience, and attach your source code.</li><li><strong>Explore</strong>: Looking for ideas? Check out Al Sweigart&#39;s <a href="https://www.amazon.com/Big-Book-Small-Python-Programming/dp/1718501242">&quot;The Big Book of Small Python Projects&quot;</a> for inspiration.</li></ol><h2>Guidelines:</h2><ul><li>Clearly state the difficulty level.</li><li>Provide a brief description and, if possible, outline the tech stack.</li><li>Feel free to link to tutorials or resources that might help.</li></ul><h1>Example Submissions:</h1><h2>Project Idea: Chatbot</h2><p><strong>Difficulty</strong>: Intermediate</p><p><strong>Tech Stack</strong>: Python, NLP, Flask/FastAPI/Litestar </p><p><strong>Description</strong>: Create a chatbot that can answer FAQs for a website.</p><p><strong>Resources</strong>: <a href="https://www.youtube.com/watch?v=a37BL0stIuM">Building a Chatbot with Python</a></p><h1>Project Idea: Weather Dashboard</h1><p><strong>Difficulty</strong>: Beginner</p><p><strong>Tech Stack</strong>: HTML, CSS, JavaScript, API</p><p><strong>Description</strong>: Build a dashboard that displays real-time weather information using a weather API.</p><p><strong>Resources</strong>: <a href="https://www.youtube.com/watch?v=9P5MY_2i7K8">Weather API Tutorial</a></p><h2>Project Idea: File Organizer</h2><p><strong>Difficulty</strong>: Beginner</p><p><strong>Tech Stack</strong>: Python, File I/O</p><p><strong>Description</strong>: Create a script that organizes files in a directory into sub-folders based on file type.</p><p><strong>Resources</strong>: <a href="https://automatetheboringstuff.com/2e/chapter9/">Automate the Boring Stuff: Organizing Files</a></p><p>Let&#39;s help each other grow. Happy coding! 🌟</p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 08 Sep 2025 05:30:30 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nb5rhw/lilpipe_a_tiny_typed_pipeline_engine_not_a_dag/</link><title>lilpipe: a tiny, typed pipeline engine (not a DAG)</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nb5rhw/lilpipe_a_tiny_typed_pipeline_engine_not_a_dag/</guid><comments>https://www.reddit.com/r/Python/comments/1nb5rhw/lilpipe_a_tiny_typed_pipeline_engine_not_a_dag/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1nb5rhw/lilpipe_a_tiny_typed_pipeline_engine_not_a_dag/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>At work, I develop data analysis pipelines in Python for the lab teams. Oftentimes, the pipelines are a little too lightweight to justify a full DAG. <a href="https://github.com/andrewruba/lilpipe">lilpipe</a> is my attempt at the minimum feature set to run those pipelines without extra/unnecessary infrastructure.</p><h1>What My Project Does</h1><ul><li>Runs sequential, in-process pipelines (not a DAG/orchestrator).</li><li>Shares a typed, Pydantic PipelineContext across steps (assignment-time validation if you want it).</li><li>Skips work via fingerprint caching (fingerprint_keys).</li><li>Gives simple control signals: ctx.abort_pass() (retry current pass) and ctx.abort_pipeline() (stop).</li><li>Lets you compose steps: Step(&quot;name&quot;, children=[...]).</li></ul><h1>Target Audience</h1><ul><li>Data scientists / lab scientists who use notebooks or small scripts and want a shared context across steps.</li><li>Anyone maintaining “glue” scripts that could use caching and simple retry/abort semantics.</li><li>Bio-analytical analysis: load plate → calibrate → QC → report (ie. this project&#39;s origin story).</li><li>Data engineers with one-box batch jobs (CSV → clean → export) who don’t want a scheduler and metadata DB (a bit of a stretch, I know).</li></ul><h1>Comparison</h1><ul><li>Airflow/Dagster/Prefect: Full DAG/orchestrators with schedulers, UIs, state, lineage, retries, SLAs/backfills. lilpipe is intentionally not that. It’s for linear, in-process pipelines where that stack is overkill.</li><li>scikit-learn Pipeline: ML-specific fit/transform/predict on estimators. lilpipe is general purpose steps with a Pydantic context.</li><li>Other lightweight pipeline libraries: don&#39;t have the exact features that I use on a day-to-day basis. lilpipe does have those features haha.</li></ul><p>Thanks, hoping to get feedback. I know there are many variations of this but it may fit a certain data analysis niche.</p><p><a href="https://github.com/andrewruba/lilpipe">lilpipe</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 08 Sep 2025 03:12:32 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nazumb/class_type_parameters_that_actually_do_something/</link><title>Class type parameters that actually do something</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nazumb/class_type_parameters_that_actually_do_something/</guid><comments>https://www.reddit.com/r/Python/comments/1nazumb/class_type_parameters_that_actually_do_something/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1nazumb/class_type_parameters_that_actually_do_something/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I was bored, so I made type parameters for python classes that are accessible within your class and contribute to behaviour . Check them out:</p><p><a href="https://github.com/arikheinss/ParametricTypes.py">https://github.com/arikheinss/ParametricTypes.py</a></p><pre><code>T = TypeVar(&quot;T&quot;)class wrapper[T](metaclass = ParametricClass):    &quot;silly wrapper class with a type restriction&quot;    def __init__(self, x: T):        self.set(x)    def set(self, v: T):        if not isinstance(v, T):            raise TypeError(f&quot;wrapper of type ({T}) got value of type {type(v)}&quot;)        self.data = v    def get(self) -&gt; T:        return self.data# =============================================w_int = wrapper[int](2)w_int.set(4)print(w_int.get()) # 4print(isinstance(wrapper[int], type)) # Truew_int.set(&quot;hello&quot;) # error!! Wrong type!w_2 = wrapper(None) # error!! Missing type parameters!!</code></pre><p>edit: after some discussion in the comments, I want to highlight that one central component of this mechanism is that we get different types from applying the type parameters, i.e.:</p><p><code>isinstance(w_int, wrapper) # Trueisinstance(w_int, wrapper[int]) # Trueisinstance(w_int, wrapper[float]) # Falsetype(wrapper[str](&quot;&quot;)) == type(wrapper[int](2)) # False</code></p><p>For the Bot, so it does not autoban me again:</p><ul><li><strong>What My Project Does</strong> Is explained above</li><li><strong>Target Audience</strong> Toyproject - Anyone who cares</li><li><strong>Comparison</strong> The Python GenericAlias exists, but does not really integrate with the rest of the type system.</li></ul></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 07 Sep 2025 23:21:49 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nakbd6/pythonjsonlogger_v400rc1_released/</link><title>Python-JSON-Logger v4.0.0.rc1 Released</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nakbd6/pythonjsonlogger_v400rc1_released/</guid><comments>https://www.reddit.com/r/Python/comments/1nakbd6/pythonjsonlogger_v400rc1_released/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1nakbd6/pythonjsonlogger_v400rc1_released/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hi All, maintainer of <a href="https://github.com/nhairs/python-json-logger">python-json-logger</a> here with a new (pre) release for you.</p><p>It can be installed using <code>python-json-logger==4.0.0.rc1</code></p><h1>What&#39;s new?</h1><p>This release has a few quality of life improvements that also happen to be breaking changes. The <a href="https://nhairs.github.io/python-json-logger/4.0.0/changelog/">full change log is here</a> but to give an overview:</p><p><strong>Support for</strong> <code>ext://</code> <strong>when using</strong> <code>dictConfig</code> <strong>/</strong> <code>fileConfig</code></p><p>This allows you to reference Python objects in your config for example:</p><pre><code>version: 1disable_existing_loggers: Falseformatters:  default:    &quot;()&quot;: pythonjsonlogger.json.JsonFormatter    format: &quot;%(asctime)s %(levelname)s %(name)s %(module)s %(funcName)s %(lineno)s %(message)s&quot;    json_default: ext://logging_config.my_json_default    rename_fields:      &quot;asctime&quot;: &quot;timestamp&quot;      &quot;levelname&quot;: &quot;status&quot;    static_fields:      &quot;service&quot;: ext://logging_config.PROJECT_NAME      &quot;env&quot;: ext://logging_config.ENVIRONMENT      &quot;version&quot;: ext://logging_config.PROJECT_VERSION      &quot;app_log&quot;: &quot;true&quot;handlers:  default:    formatter: default    class: logging.StreamHandler    stream: ext://sys.stderr  access:    formatter: default    class: logging.StreamHandler    stream: ext://sys.stdoutloggers:  uvicorn.error:    level: INFO    handlers:      - default    propagate: no  uvicorn.access:    level: INFO    handlers:      - access    propagate: no</code></pre><p><strong>Support for easier to use formats</strong></p><p>We now support a comma <code>style=&quot;,&quot;</code> style which lets use a comma seperate string to specific fields.</p><pre><code>formatter = JsonFormatter(&quot;message,asctime,exc_info&quot;, style=&quot;,&quot;)</code></pre><p>We also using any sequence of strings (e.g. lists or tuples).</p><pre><code>formatter = JsonFormatter([&quot;message&quot;, &quot;asctime&quot;, &quot;exc_info&quot;])</code></pre><h1>What is Python JSON Logger</h1><p>If you&#39;ve not heard of this package, Python JSON Logger enables you produce JSON logs when using Python&#39;s <code>logging</code> package.</p><p>JSON logs are machine readable allowing for much easier parsing and ingestion into log aggregation tools.</p><p>For example here is the (formatted) log output of one of my programs:</p><pre><code>{  &quot;trace_id&quot;: &quot;af922f04redacted&quot;,  &quot;request_id&quot;: &quot;cb1499redacted&quot;,  &quot;parent_request_id&quot;: null,  &quot;message&quot;: &quot;Successfully imported redacted&quot;,  &quot;levelname&quot;: &quot;INFO&quot;,  &quot;name&quot;: &quot;redacted&quot;,  &quot;pathname&quot;: &quot;/code/src/product_data/consumers/games.py&quot;,  &quot;lineno&quot;: 41,  &quot;timestamp&quot;: &quot;2025-09-06T08:00:48.485770+00:00&quot;}</code></pre><h1>Why post to Reddit?</h1><p>Although Python JSON Logger <a href="https://hugovk.github.io/top-pypi-packages/">is in the top 300 downloaded packaged from PyPI</a> (in the last month it&#39;s been downloaded more times that UV! ... just), there&#39;s not many people watching the repository <a href="https://www.reddit.com/r/Python/comments/1hcm2rr/pythonjsonlogger_has_changed_hands/">after it changed hands</a> at the end of 2024.</p><p>This seemed the most appropriate way to share the word in order to minimise disruptions once it is released.</p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 07 Sep 2025 10:18:52 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nag19u/ensures_simple_design_by_contract/</link><title>ensures: simple Design by Contract</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nag19u/ensures_simple_design_by_contract/</guid><comments>https://www.reddit.com/r/Python/comments/1nag19u/ensures_simple_design_by_contract/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1nag19u/ensures_simple_design_by_contract/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><ul><li><strong>What My Project Does</strong></li></ul><p>There are a few other packages for this, but I decided to make one that is simple, readable, accepts arbitrary functions, and uses the Result type from functional programming. You can find more details in the readme: <a href="https://github.com/brunodantas/ensures">https://github.com/brunodantas/ensures</a></p><blockquote><p>ensures is a simple Python package that implements the idea of Design by Contract described in the Pragmatic Paranoia chapter of The Pragmatic Programmer. That&#39;s the chapter where they say you should trust nobody, not even yourself.</p></blockquote><ul><li><strong>Target Audience</strong> (e.g., Is it meant for production, just a toy project, etc.)</li></ul><p>Anyone interested in <del>paranoia</del> decorating functions with precondition functions etc and use a Functional data structure in the process.</p><p>I plan to add pytest tests to make this more production-ready. Any feedback is welcome.</p><ul><li><strong>Comparison</strong> (A brief comparison explaining how it differs from existing alternatives.)</li></ul><p>None of the alternatives I found seem to implement arbitrary functions plus the Result type, while being simple and readable.</p><p>But some of the alternatives are icontract, contracts, deal. Each with varying levels of the above.</p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 07 Sep 2025 06:32:47 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1na9od6/built_a_free_vs_code_extension_for_python/</link><title>Built a free VS Code extension for Python dependencies - no more PyPI tab switching</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1na9od6/built_a_free_vs_code_extension_for_python/</guid><comments>https://www.reddit.com/r/Python/comments/1na9od6/built_a_free_vs_code_extension_for_python/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1na9od6/built_a_free_vs_code_extension_for_python/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Tired of switching to PyPI tabs to check package versions?</p><p>Just released <strong>Tombo</strong> - brings PyPI directly into VS Code:</p><p><strong>What it does (complements your existing workflow):</strong></p><ul><li>uv/poetry handle installation → Tombo handles version selection</li><li>Hover <code>requests</code> → see ALL versions + Python compatibility</li><li>Type <code>numpy&gt;=</code> → intelligent version suggestions for your project</li><li>Perfect for big projects (10+ deps) - no more version hunting</li><li>Then let uv/poetry create the lock files</li></ul><p><strong>Demo in 10 seconds:</strong></p><ol><li>Open any Python project</li><li>Type <code>django&gt;=</code></li><li>Get instant version suggestions</li><li>Hover packages for release info</li></ol><p><strong>Installation:</strong> VS Code → Search &quot;Tombo&quot; → Install</p><p><strong>Free &amp; open source</strong> - no tracking, no accounts, just works.</p><p>⭐ <strong>Star the project</strong> if you find it useful: <a href="https://github.com/benbenbang/tombo">https://github.com/benbenbang/tombo</a></p><p>VS Code Marketplace: <a href="https://marketplace.visualstudio.com/items?itemName=benbenbang.tombo">https://marketplace.visualstudio.com/items?itemName=benbenbang.tombo</a></p><p>Documentation: <a href="https://benbenbang.github.io/tombo/">https://benbenbang.github.io/tombo/</a></p><p>Anyone else tired of manual PyPI lookups? 🤦‍♂️</p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 07 Sep 2025 01:48:17 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1na61l2/ducky_my_opensource_networking_security_toolkit/</link><title>Ducky, my open-source networking &amp;amp; security toolkit for Network Engineers, Sysadmins, and Pentester</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1na61l2/ducky_my_opensource_networking_security_toolkit/</guid><comments>https://www.reddit.com/r/Python/comments/1na61l2/ducky_my_opensource_networking_security_toolkit/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1na61l2/ducky_my_opensource_networking_security_toolkit/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hey everyone, For a long time, I&#39;ve been frustrated with having to switch between a dozen different apps for my networking tasks PuTTY for SSH, a separate port scanner, a subnet calculator, etc.</p><p>To solve this, I built <strong>Ducky</strong>, a free and open-source, all-in-one toolkit that combines these essential tools into one clean, tabbed interface.</p><p><strong>What it does:</strong></p><ul><li><strong>Multi-Protocol Tabbed Terminal:</strong> Full support for SSH, Telnet, and Serial (COM) connections.</li><li><strong>Network Discovery:</strong> An ARP scanner to find live hosts on your local network and a visual Topology Mapper.</li><li><strong>Essential Tools:</strong> It also includes a Port Scanner, CVE Vulnerability Lookup, Hash Cracker, and other handy utilities.</li></ul><p><strong>Target Audience:</strong><br/>I built this for anyone who works with networks or systems, including:</p><ul><li><strong>Network Engineers &amp; Sysadmins:</strong> For managing routers, switches, and servers without juggling multiple windows.</li><li><strong>Cybersecurity Professionals &amp; Students:</strong> A great all-in-one tool for pentesting, vulnerability checks (CVE), and learning.</li><li><strong>Homelabbers &amp; Tech Enthusiasts:</strong> The perfect command center for managing your home lab setup.</li><li><strong>Fellow Python Developers:</strong> To see a practical desktop application built with <strong>PySide6</strong>.</li></ul><p><strong>How you can help:</strong><br/>The project is 100% open-source, and I&#39;m actively looking for contributors and feedback!</p><ul><li><strong>Report bugs or issues:</strong> Find something that doesn&#39;t work right? Please open an issue on GitHub.</li><li><strong>Suggest enhancements:</strong> Have an idea for a new tool or an improvement? Let&#39;s discuss it!</li><li><strong>Contribute code:</strong> Pull Requests are always welcome.</li><li><strong>GitHub Repo (Source Code &amp; Issues):</strong> <a href="https://github.com/thecmdguy/Ducky">https://github.com/thecmdguy/Ducky</a></li><li><strong>Project Homepage:</strong> <a href="https://ducky.ge/">https://ducky.ge/</a></li></ul><p>Thanks for taking a look!</p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 06 Sep 2025 23:23:19 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1na5fk2/from_stress_to_success_load_testing_python_apps/</link><title>From Stress to Success: Load Testing Python Apps – Open Source Example</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1na5fk2/from_stress_to_success_load_testing_python_apps/</guid><comments>https://www.reddit.com/r/Python/comments/1na5fk2/from_stress_to_success_load_testing_python_apps/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1na5fk2/from_stress_to_success_load_testing_python_apps/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>What My Project Does:</strong><br/>This project demonstrates <strong>load testing Python applications</strong> and <strong>visualizing performance metrics</strong>. It uses a sample Python app, Locust for stress testing, Prometheus for metrics collection, and Grafana for dashboards. It’s designed to give a hands-on example of how to simulate load and understand app performance.</p><p><strong>Target Audience:</strong><br/>Developers and Python enthusiasts who want to learn or experiment with load testing and performance visualization. It’s meant as a <strong>learning tool and reference</strong>, not a production-ready system.</p><p><strong>Comparison:</strong><br/>Unlike generic tutorials or scattered examples online, this repo bundles everything together—app, load scripts, Prometheus, and Grafana dashboards—so you can <strong>see the full workflow from stress testing to visualization in one place</strong>.</p><p><strong>Repo Link:</strong><br/><a href="https://github.com/Alleny244/locust-grafana-prometheus">https://github.com/Alleny244/locust-grafana-prometheus</a></p><p>Would love feedback, suggestions, or improvements from the community!</p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 06 Sep 2025 22:59:34 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1na21zu/jollyradio_a_web_based_radio/</link><title>JollyRadio - A web based radio</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1na21zu/jollyradio_a_web_based_radio/</guid><comments>https://www.reddit.com/r/Python/comments/1na21zu/jollyradio_a_web_based_radio/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1na21zu/jollyradio_a_web_based_radio/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>What My Project Does</strong> </p><p>JollyRadio is a web based, simple radio where you can find lots of live streams. It&#39;s designed to be easy to navigate and have less extra fluff. </p><p><strong>Target Audience</strong> </p><p>JollyRadio is for people who want to listen to radio! It has basic filtering to filter out bad stuff, but you may still need to know what to do and not do. </p><p><strong>Comparison</strong> </p><p>Compared to other web based radios, JollyRadio is designed to be local-focused and more minimalistic. There are three sections, exploring, local stations and searching for stations. It is better if you want a easy, minimal interface.</p><p><strong>Technical Explanation</strong></p><p>JollyRadio is written in Python (Flask) with HTML (Bootstrap). I&#39;m new to programming, so please don&#39;t expect a perfect product. It uses the RadioBrowser API to find the radio stations.</p><p><strong>Links</strong></p><p>GitHub Link: <a href="https://github.com/SeafoodStudios/JollyRadio">https://github.com/SeafoodStudios/JollyRadio</a></p><p>Radio Link: <a href="https://tryjollyradio.seafoodstudios.com/">https://tryjollyradio.seafoodstudios.com/</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 06 Sep 2025 20:44:15 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n9urtc/automating_power_supply_measurements_with_pyvisa/</link><title>Automating Power Supply Measurements with PyVisa &amp;amp; Pytest</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n9urtc/automating_power_supply_measurements_with_pyvisa/</guid><comments>https://www.reddit.com/r/Python/comments/1n9urtc/automating_power_supply_measurements_with_pyvisa/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n9urtc/automating_power_supply_measurements_with_pyvisa/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>Target Audience:</strong></p><ul><li>R&amp;D Development &amp; Test Enginners</li><li>Electrical Engineering Students</li><li>Python Automation Experts</li></ul><p><strong>What My Project Does:</strong></p><p>I created a small python library: <a href="https://github.com/ammarkh95/pypm-test">pypm-test</a> which could be used for automating measurements with the pictured instruments.</p><p>You could also use it as reference to automate similar functions with your available instruments. The library is Python based and makes use of <a href="https://pyvisa.readthedocs.io/en/latest/">PyVisa </a>library for communction with electronic eqipment supporting <a href="https://www.ivifoundation.org/About-IVI/scpi.html">SCPI </a>standard.</p><p>The library also includes some <a href="https://docs.pytest.org/en/stable/explanation/fixtures.html">pytest-fixtures</a> which makes it nice to use in automated testing environment.</p><p>Below I share summary of the hardware used and developed python library as well as some example results for an automated DC-DC converter measurements. You can find all the details in my <a href="https://ak-experiments.blogspot.com/2025/09/automating-power-supply-measurements.html">blog post</a></p><p><strong>Hardware:</strong></p><p>I had access to the following instruments:</p><p><a href="https://www.keysight.com/us/en/support/U3606B/multimeter-dc-power-supply.html">Keysight U3606B</a>: Combination of a 5.5 digit digital multimeter and 30-W power supply in a single unit<br/><a href="https://www.keysight.com/us/en/products/source-measure-units-smu/u2722a-u2723a-usb-modular-source-measure-units-smu.html">Keysight U2723A:</a> Modular source measure unit (SMU) Four-quadrant operation (± 120 mA/± 20 V)</p><p><strong>Software:</strong></p><p>The developd library contain wrapper classes that implement the control and measurement functions of the above instruments.</p><p>The exposed functions by the SCPI interface are normally documented in the programming manuals of the equipment published online. So it was just a matter of going through the manuals to get the required <a href="https://www.ivifoundation.org/About-IVI/scpi.html">SCPI</a> commands / queries for a given instrument function and then sending it over to the instrument using <a href="https://pyvisa.readthedocs.io/en/latest/">PyVisa</a> write and query functions.</p><p><strong>Example:</strong></p><p>A classical example application with a power supply and source measure unit is to evaluate the efficiency of DC-DC conversion for a given system. It is also a nice candiate &quot;parameteric study&quot; for automation to see how does the output power compares to the input power (i.e. effeciency) at different inputs voltges / sink currents. You can view the code behind similar test directly from my repo <a href="https://github.com/ammarkh95/pypm-test/blob/f5434110e7dffd4adeff23f09d9ca10877fc1dbb/testing/example_tests/test_dc_dc_converter.py#L84">here</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 06 Sep 2025 14:28:25 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n9qlkv/what_are_some_nonai_toolsextensions_which_have/</link><title>What are some non-AI tools/extensions which have really boosted your work life or made life easier?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n9qlkv/what_are_some_nonai_toolsextensions_which_have/</guid><comments>https://www.reddit.com/r/Python/comments/1n9qlkv/what_are_some_nonai_toolsextensions_which_have/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n9qlkv/what_are_some_nonai_toolsextensions_which_have/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>It can be an extension or a CLI tool or something else, My work mainly involves in developing managing mid sized python applications deployed over aws. I mostly work through cursor and agents have been decently useful but these days all the development on programming tools seems to be about AI integration. Is there something that people here have been using that&#39;s come out in last few years and has made serious impact in how you do things? Can be open source or not, anything goes it just shouldn&#39;t be something AI or a framework.</p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 06 Sep 2025 10:11:33 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n9ov57/simple_python_expression_that_does_complex_things/</link><title>Simple Python expression that does complex things?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n9ov57/simple_python_expression_that_does_complex_things/</guid><comments>https://www.reddit.com/r/Python/comments/1n9ov57/simple_python_expression_that_does_complex_things/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n9ov57/simple_python_expression_that_does_complex_things/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>First time I saw <code>a[::-1]</code> to invert the list <code>a</code>, I was blown away. </p><p><code>a, b = b, a</code> which swaps two variables (without temp variables in between) is also quite elegant. </p><p>What&#39;s your favorite example?</p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 06 Sep 2025 08:37:42 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n9kste/python_type_system_and_tooling_survey_2025_from/</link><title>Python Type System and Tooling Survey 2025 (From Meta &amp;amp; JetBrains)</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n9kste/python_type_system_and_tooling_survey_2025_from/</guid><comments>https://www.reddit.com/r/Python/comments/1n9kste/python_type_system_and_tooling_survey_2025_from/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n9kste/python_type_system_and_tooling_survey_2025_from/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>As mentioned in the title, this survey was developed by Meta &amp; Jetbrains w/ community input to collect opinions around Python&#39;s type system and type-related tooling.</p><blockquote><p>The goal of this survey is to gain insights into the tools and practices you use (if any!), the challenges you face, and how you stay updated on new features. Your responses will help the Python typing community identify common blockers, improve resources, and enhance the overall experience of using Python&#39;s type system. Even if you have never actively used type hints in your code, your thoughts are still valuable and we want to hear from you.</p></blockquote><p>Take the survey <a href="https://docs.google.com/forms/d/e/1FAIpQLSeOFkLutxMLqsU6GPe60OJFYVN699vqjXPtuvUoxbz108eDWQ/viewform">here</a>.</p><p>Original LinkedIn posts (so you know it&#39;s legit):</p><p><a href="https://www.linkedin.com/posts/meta-open-source_python-type-system-and-tooling-survey-2025-activity-7369400929546092548-A0hh?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAB9aSUsBqmxSbrhoW2URuDnxCgS5eVD1AS0">Meta Open Source</a></p><p><a href="https://www.linkedin.com/posts/thepsf_python-type-system-and-tooling-survey-2025-activity-7368968760252059648-ICjo?utm_source=social_share_send&amp;utm_medium=member_desktop_web&amp;rcm=ACoAAB9aSUsBqmxSbrhoW2URuDnxCgS5eVD1AS0">Python Software Foundation</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 06 Sep 2025 05:16:17 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n95jwd/aws_for_python_devs_made_simple/</link><title>AWS for Python devs - made simple</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n95jwd/aws_for_python_devs_made_simple/</guid><comments>https://www.reddit.com/r/Python/comments/1n95jwd/aws_for_python_devs_made_simple/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n95jwd/aws_for_python_devs_made_simple/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>What is Stelvio?</strong><br/>Stelvio is a Python framework for managing and deploying AWS infrastructure. Instead of writing YAML, JSON, or HCL, you define your infrastructure in <strong>pure Python</strong>. The framework provides <strong>smart defaults</strong> for networking, IAM, and security so you can focus on your application logic rather than boilerplate setup.</p><p>With the <code>stlv</code> CLI, you can go from zero to a working AWS environment in seconds, without heavy configuration.</p><p><strong>What My Project Does</strong><br/>Stelvio lets Python developers:</p><ul><li>Spin up AWS resources (e.g. compute, storage, networking) using Python code.</li><li>Deploy isolated environments (personal or team-based) with a single command.</li><li>Skip most of the manual setup thanks to opinionated defaults for IAM roles, VPCs, and security groups.</li></ul><p>The goal is to make cloud deployments <strong>approachable to Python developers who aren’t infrastructure experts</strong>.</p><p><strong>Target Audience</strong></p><ul><li><strong>Python developers</strong> who want to deploy applications to AWS without learning all of Terraform or CloudFormation.</li><li><strong>Small teams and projects</strong> that need quick, reproducible environments.</li><li>It’s designed for <strong>real-world usage</strong>, not just as a toy project, but it’s still early-stage and evolving rapidly.</li></ul><p><strong>Comparison to Alternatives</strong></p><ul><li>Compared to <strong>Terraform</strong>: Stelvio is Python-native, so you don’t need to learn HCL or use external templating.</li><li>Compared to <strong>AWS CDK</strong>: Stelvio emphasizes <strong>zero setup</strong> and <strong>smart defaults</strong>. CDK is very flexible but requires more boilerplate and AWS-specific expertise.</li><li>Compared to <strong>Pulumi</strong>: Stelvio is lighter-weight and focuses narrowly on AWS, aiming to reduce complexity rather than cover all clouds.</li></ul><p><strong>Links</strong></p><ul><li>GitHub: <a href="https://github.com/michal-stlv/stelvio?utm_source=chatgpt.com">https://github.com/michal-stlv/stelvio</a></li><li>Website: <a href="https://stelvio.dev?utm_source=chatgpt.com">https://stelvio.dev</a></li></ul></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 05 Sep 2025 19:09:25 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n9267v/i_built_a_visual_component_library_for/</link><title>I built a visual component library for instrumentation</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n9267v/i_built_a_visual_component_library_for/</guid><comments>https://www.reddit.com/r/Python/comments/1n9267v/i_built_a_visual_component_library_for/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n9267v/i_built_a_visual_component_library_for/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hello everyone,</p><p>as Python is growing more and more in industrial field, I decided to create visual component library for instrumentation.</p><p><strong>What My Project Does:</strong><br/>A Python library with <strong>40+ visual and non-visual components</strong> for building industrial and lab GUIs. Includes analog instruments, sliders, switches, buttons, graphs, and oscilloscope &amp; logic analyzer widgets (PyVISA-compatible). Components are <strong>highly customizable</strong> and designed with a <strong>retro industrial look</strong>.</p><p><strong>Target Audience:</strong><br/>Engineers, scientists, and hobbyists building technical or industrial GUIs. Suitable for both <strong>prototypes and production-ready applications</strong>.</p><p><strong>Comparison / How It’s Different:</strong><br/>Unlike general GUI frameworks, this library is <strong>instrumentation-focused</strong> with ready-made industrial-style meters, gauges, and analyzer components—saving development time and providing a consistent professional look.</p><p><strong>Demo:</strong> <a href="https://imgur.com/a/0j89hPf?utm_source=chatgpt.com">Imgur</a> (Not all components are being shown, just a small sneek-peak)<br/><strong>GitHub Repo:</strong> <a href="https://github.com/tino-posedi/Thales?utm_source=chatgpt.com">Thales</a> (private, still in progress)</p><p><strong>Feedback Questions:</strong></p><ul><li>Are there components you’d find particularly useful for industrial or lab GUIs?</li><li>Is the retro industrial style appealing, or would you prefer alternative themes?</li><li>Any suggestions for improving customization, usability, or performance?</li></ul></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 05 Sep 2025 16:31:47 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n91acl/showcase_i_cocreated_dlt_an_opensource_python/</link><title>Showcase: I co-created dlt, an open-source Python library that lets you build data pipelines in minu</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n91acl/showcase_i_cocreated_dlt_an_opensource_python/</guid><comments>https://www.reddit.com/r/Python/comments/1n91acl/showcase_i_cocreated_dlt_an_opensource_python/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n91acl/showcase_i_cocreated_dlt_an_opensource_python/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>As a 10y+ data engineering professional, I got tired of the boilerplate and complexity required to load data from messy APIs and files into structured destinations. So, with a team, I built <code>dlt</code> to make data loading ridiculously simple for anyone who knows Python.</p><p><strong>Features:</strong></p><ul><li>➡️ <strong>Load anything with Schema Evolution:</strong> Easily pull data from any API, database, or file (JSON, CSV, etc.) and load it into destinations like DuckDB, BigQuery, Snowflake, and more, handling types and nested data flawlessly.</li><li>➡️ <strong>No more schema headaches:</strong> <code>dlt</code> automatically creates and maintains your database tables. If your source data changes, the schema adapts on its own.</li><li>➡️ <strong>Just write Python:</strong> No YAML, no complex configurations. If you can write a Python function, you can build a production-ready data pipeline.</li><li>➡️ <strong>Scales with you:</strong> Start with a simple script and scale up to handle millions of records without changing your code. It&#39;s built for both quick experiments and robust production workflows.</li><li>➡️ <strong>Incremental loading solved:</strong> Easily keep your destination in sync with your source by loading only new data, without the complex state management.</li><li>➡️ <strong>Easily extendible:</strong> <code>dlt</code> is built to be modular. You can add new sources, customize data transformations, and deploy anywhere.</li></ul><p><strong>Link to repo:</strong><a href="https://github.com/dlt-hub/dlt">https://github.com/dlt-hub/dlt</a></p><p>Let us know what you think! We&#39;re always looking for feedback and contributors.</p><h1>What My Project Does</h1><p><code>dlt</code> is an open-source Python library that simplifies the creation of robust and scalable data pipelines. It automates the most painful parts of Extract, Transform, Load (ETL) processes, particularly schema inference and evolution. Users can write simple Python scripts to extract data from various sources, and <code>dlt</code> handles the complex work of normalizing that data and loading it efficiently into a structured destination, ensuring the target schema always matches the source data.</p><h1>Target Audience</h1><p>The tool is for <strong>data scientists, analysts, and Python developers</strong> who need to move data for analysis, machine learning, or operational dashboards but don&#39;t want to become full-time data engineers. It&#39;s perfect for anyone who wants to build production-ready, maintainable data pipelines without the steep learning curve of heavyweight orchestration tools like Airflow or writing extensive custom code. It’s suitable for everything from personal projects to enterprise-level deployments.</p><h1>Comparison (how it differs from existing alternatives)</h1><p>Unlike complex frameworks such as <strong>Airflow</strong> or <strong>Dagster</strong>, which are primarily orchestrators that require significant setup, <code>dlt</code> is a lightweight library focused purely on the &quot;load&quot; part of the data pipeline. Compared to writing <strong>custom Python scripts</strong> using libraries like <code>SQLAlchemy</code> and <code>pandas</code>, <code>dlt</code> abstracts away tedious tasks like schema management, data normalization, and incremental loading logic. This allows developers to create declarative and resilient pipelines with far less code, reducing development time and maintenance overhead.</p></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 05 Sep 2025 15:41:57 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n8jasr/im_building_local_opensource_fast_minimal_and/</link><title>I'm building local, open-source, fast minimal, and extendible python RAG library and CLI tool</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n8jasr/im_building_local_opensource_fast_minimal_and/</guid><comments>https://www.reddit.com/r/Python/comments/1n8jasr/im_building_local_opensource_fast_minimal_and/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n8jasr/im_building_local_opensource_fast_minimal_and/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I got tired of overengineered and bloated AI libraries and needed something to prototype local RAG apps quickly so I decided to make my own library,<br/>Features:<br/>➡️ Get to prototyping local RAG applications in seconds: uvx rocketrag prepare &amp; uv rocketrag ask is all you need<br/>➡️ CLI first interface, you can even visualize embeddings in your terminal<br/>➡️ Native llama.cpp bindings - no Ollama bullshit<br/>➡️ Ready to use minimalistic web app with chat, vectors visualization and browsing documents➡️ Minimal footprint: milvus-lite, llama.cpp, kreuzberg, simple html web app<br/>➡️ Tiny but powerful - use any chucking method from chonkie, any LLM with .gguf provided and any embedding model from sentence-transformers<br/>➡️ Easily extendible - implement your own document loaders, chunkers and BDs, contributions welcome!<br/>Link to repo: <a href="https://github.com/TheLion-ai/RocketRAG">https://github.com/TheLion-ai/RocketRAG</a><br/>Let me know what you think. If anybody wants to collaborate and contribute DM me or just open a PR!  </p><p><strong>What My Project Does</strong><br/>RocketRAG is a high-performance Retrieval-Augmented Generation (RAG) library that loads documents (PDF/TXT/MD…), performs semantic chunking, indexes embeddings into a fast vector DB, then serves answers via a local LLM. It provides both a CLI and a FastAPI-based web server with OpenAI-compatible <code>/ask</code> and streaming endpoints, and is built to prioritize speed, a minimal code footprint, and easy extensibility</p><p><strong>Target Audience</strong><br/>Developers and researchers who want a fast, modular RAG stack for local or self-hosted inference (GGUF / llama-cpp-python), and teams who value low-latency document processing and a plug-and-play architecture. It’s suitable both for experimentation and for production-ready local/offline deployments where performance and customizability matter. </p><p><strong>Comparison (how it differs from existing alternatives)</strong><br/>Unlike heavier, opinionated frameworks, RocketRAG focuses on performance-first building blocks: ultra-fast document loaders (Kreuzberg), semantic chunking (Chonkie/model2vec), Sentence-Transformers embeddings, Milvus Lite for sub-millisecond search, and llama-cpp-python for GGUF inference — all in a pluggable architecture with a small footprint. The goal is lower latency and easier swapping of components compared to larger ecosystems, while still offering a nice CLI </p></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 05 Sep 2025 00:43:21 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n8f0xu/pycon_2025_workshop_agentic_apps_with_pydanticai/</link><title>PyCon 2025 Workshop: Agentic Apps with Pydantic-AI</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n8f0xu/pycon_2025_workshop_agentic_apps_with_pydanticai/</guid><comments>https://www.reddit.com/r/Python/comments/1n8f0xu/pycon_2025_workshop_agentic_apps_with_pydanticai/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n8f0xu/pycon_2025_workshop_agentic_apps_with_pydanticai/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>Hey all!</strong></p><p>I recently gave a workshop talk at <strong>PyCon Greece 2025</strong> about building production-ready agent systems.<br/>To check it out, I put together a demo repo (slides coming soon on my blog: <a href="https://www.petrostechchronicles.com/?utm_source=chatgpt.com">petrostechchronicles.com</a>):</p><p>Repo: <a href="https://github.com/Aherontas/Pycon_Greece_2025_Presentation_Agents?utm_source=chatgpt.com">github.com/Aherontas/Pycon_Greece_2025_Presentation_Agents</a></p><p><strong>The idea</strong>: show how multiple AI agents can collaborate using <strong>FastAPI + Pydantic-AI</strong>, with protocols like <strong>MCP (Model Context Protocol)</strong> and <strong>A2A (Agent-to-Agent)</strong> for safe communication and orchestration.</p><p><strong>Features:</strong></p><ul><li>Multiple agents running in containers</li><li>MCP servers (Brave search, GitHub, filesystem, etc.) as tools</li><li>A2A communication between services</li><li>Minimal UI for experimentation (e.g., repo analysis)</li></ul><p><strong>Why I built this</strong>:<br/>Most agent frameworks look great in isolated demos, but fall apart when you try to glue agents together into a real application.<br/>My goal was to help people experiment with these patterns and move closer to real-world use cases.</p><p>It’s not production-grade, but I’d love <strong>feedback, criticism, or war stories</strong> from anyone who’s tried building multi-agent systems.</p><p><strong>Big question for discussion:</strong><br/>Do you think agent-to-agent protocols like MCP/A2A will stick?<br/>Or will the future be mostly single powerful LLMs with plugin stacks?</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 22:01:51 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n8d6pi/productiongrade_python_logging_made_easier_with/</link><title>Production-Grade Python Logging Made Easier with Loguru</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n8d6pi/productiongrade_python_logging_made_easier_with/</guid><comments>https://www.reddit.com/r/Python/comments/1n8d6pi/productiongrade_python_logging_made_easier_with/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n8d6pi/productiongrade_python_logging_made_easier_with/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>While Python&#39;s standard logging module is powerful, navigating its system of handlers, formatters, and filters can often feel like more work than it should be.</p><p><a href="https://www.dash0.com/guides/python-logging-with-loguru">I wrote a guide</a> on how to achieve the same (and better) results with a fraction of the complexity using Loguru. It’s approachable, can intercept logs from the standard library, and exposes its other great features in a much cleaner API.</p><p>Looking forward to hearing what you think!</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 20:53:33 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n87g91/rant_use_that_second_expression_in_assert/</link><title>Rant: use that second expression in `assert`!</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n87g91/rant_use_that_second_expression_in_assert/</guid><comments>https://www.reddit.com/r/Python/comments/1n87g91/rant_use_that_second_expression_in_assert/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n87g91/rant_use_that_second_expression_in_assert/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>The <code>assert</code> statement is wildly useful for developing and maintaining software. I sprinkle <code>assert</code>s liberally in my code at the beginning to make sure what I think is true, is actually true, and this practice catches a vast number of idiotic errors; and I keep at least some of them in production.</p><p>But often I am in a position where someone else&#39;s assert triggers, and I see in a log something like <code>assert foo.bar().baz() != 0</code> has triggered, and I have no information at all.</p><p>Use that second expression in <code>assert</code>! </p><p>It can be anything you like, even some calculation, and it doesn&#39;t get called unless the assertion fails, so it costs nothing if it never fires. When someone has to find out why your assertion triggered, it will make everyone&#39;s life easier if the assertion explains what&#39;s going on.</p><p>I often use</p><pre><code>assert some_condition(), locals()</code></pre><p>which prints every local variable if the assertion fails. (<code>locals()</code> might be impossibly huge though, if it contains some massive variable, you don&#39;t want to generate some terabyte log, so be a little careful...)</p><p>And remember that <code>assert</code> is a statement, not an expression. That is why this <code>assert</code> will never trigger:</p><pre><code>assert (   condition,   &quot;Long Message&quot;)</code></pre><p>because it asserts that the expression <code>(condition, &quot;Message&quot;)</code> is truthy, which it always is, because it is a two-element tuple.</p><p>Luckily I read an article about this long before I actually did it. I see it every year or two in someone&#39;s production code still.</p><p>Instead, use </p><pre><code>assert condition, (    &quot;Long Message&quot;)</code></pre></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 16:53:00 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n86hnz/i_made_a_script_that_identifies_graded_pokemon/</link><title>I made a script that identifies graded Pokemon cards with OCR</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n86hnz/i_made_a_script_that_identifies_graded_pokemon/</guid><comments>https://www.reddit.com/r/Python/comments/1n86hnz/i_made_a_script_that_identifies_graded_pokemon/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n86hnz/i_made_a_script_that_identifies_graded_pokemon/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hi everyone,</p><p>I run a <a href="https://www.jimmysdealfinder.com">Pokemon deal finder</a> site that finds deals on Pokemon cards on eBay by comparing listing prices to historical card values.</p><p>I used to have graded cards on there, but I had to remove them from the site because too many people would lie in the title about what grade it is. For example, they might put &quot;PSA 10&quot; when it&#39;s only a PSA 9 or they might put &quot;Easily a PSA 10&quot; or &quot;Potential PSA 10&quot; when the card was ungraded. There were enough cards like this that I had to remove graded cards from the site because there were too many misleading graded listings.</p><p>I decided to try to use OCR on the card images to identify the grade rather than trusting what the user says in the title. I managed to write a surprisingly accurate script for identifying the grade of PSA 9 and PSA 10 cards.</p><p>It uses the cv2 and easyocr libraries, and it searches for sections that look purely black and white in the image (likely to be text), then it scans that section for the words &quot;MINT&quot; (grade 9) or &quot;GEM MT&quot; (grade 10) to determine the grade of the card.</p><p>It works surprisingly well, and the best thing is there are no false positives.</p><p>Now I&#39;ve got graded cards back on my site, and they all seem to be identified correctly.</p><p><strong>What My Project Does</strong></p><p>Takes an image of a Pokemon card, and determiners whether it&#39;s a grade 9 or 10 or ungraded.</p><p><strong>Target Audience</strong></p><p>This is mainly for myself as a tool to add graded cards back to my site. Though it could be useful for anyone who needs to identify a graded card from an image.</p><p><strong>Comparison</strong></p><p>When I was first writing this, I did search on Google to see if anyone had done OCR recognition on graded Pokemon cards, but I didn&#39;t really find anything. I think this is unique in that regard.</p><p>You can run it with get_grade_ocr() on either a filename or a URL.</p><p>Github: <a href="https://github.com/sgriffin53/pokemon_ocr">https://github.com/sgriffin53/pokemon_ocr</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 15:59:31 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n85285/typewriter_sound_program/</link><title>Typewriter sound program</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n85285/typewriter_sound_program/</guid><comments>https://www.reddit.com/r/Python/comments/1n85285/typewriter_sound_program/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n85285/typewriter_sound_program/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I love the sound of a typewriter. I like the mechanical sound but I don&#39;t like typing on mechanical keyboards. How would one go about writing a program that imitates the typewriter sound as I&#39;m typing?</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 14:32:18 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n84hjt/pyconfr_at_lyon_france/</link><title>PyconFR at Lyon (France)</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n84hjt/pyconfr_at_lyon_france/</guid><comments>https://www.reddit.com/r/Python/comments/1n84hjt/pyconfr_at_lyon_france/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n84hjt/pyconfr_at_lyon_france/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>The French-Speaking Python Association (AFPy) is organizing PyConFR 2025 from Thursday, October 30 to Sunday, November 2. For this 16th edition, we’ll be hosted by the René Cassin Campus in Lyon!</p><p>PyConFR is a free, four-day event centered around the Python programming language. It includes two days of collaborative development (sprints), followed by two days of talks and workshops.</p><p>The call for proposals is now closed, and we’ll be publishing the schedule soon at <a href="https://www.pycon.fr/2025/en/schedule.html">https://www.pycon.fr/2025/en/schedule.html</a>. There will be an English-language track.</p><p>While attendance is free, registration is required for all participants.</p><p>As every year, we offer support to people who are usually underrepresented at conferences — help with finding a topic, writing a proposal, preparing slides, and rehearsing. Feel free to contact us at [<a href="mailto:diversite@afpy.org">diversite@afpy.org</a>]()</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 13:54:02 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n7sr1x/why_does_processpoolexecutor_mark_some_tasks_as/</link><title>Why does ProcessPoolExecutor mark some tasks as "running" even though all workers are busy?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n7sr1x/why_does_processpoolexecutor_mark_some_tasks_as/</guid><comments>https://www.reddit.com/r/Python/comments/1n7sr1x/why_does_processpoolexecutor_mark_some_tasks_as/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n7sr1x/why_does_processpoolexecutor_mark_some_tasks_as/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I’m using Python’s <code>ProcessPoolExecutor</code> to run a bunch of tasks. Something I noticed is that some tasks are marked as <em>running</em> even though all the workers are already working on other tasks.</p><p>From my understanding, a task should only switch from <em>pending</em> to <em>running</em> once a worker actually starts executing it. But in my case, it seems like the executor marks extra tasks as running before they’re really picked up.</p><p>Is this normal behavior of <code>ProcessPoolExecutor</code>? Or am I missing something about how it manages its internal task queue?</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 03:46:26 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n7r4xb/niche_python_tools_libraries_and_features_whats/</link><title>Niche Python tools, libraries and features - whats your favourite?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n7r4xb/niche_python_tools_libraries_and_features_whats/</guid><comments>https://www.reddit.com/r/Python/comments/1n7r4xb/niche_python_tools_libraries_and_features_whats/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n7r4xb/niche_python_tools_libraries_and_features_whats/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I know we see this get asked every other week, but it always makes for a good discussion.</p><p>I only just found out about <code>pathlib</code> - makes working with files so much cleaner.</p><p>Whats a python tool or library you wish youd known about earlier?</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 02:41:38 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n7pe37/removing_a_dependency_major_minor_or_patch_bump/</link><title>Removing a dependency - Major, Minor or Patch bump?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n7pe37/removing_a_dependency_major_minor_or_patch_bump/</guid><comments>https://www.reddit.com/r/Python/comments/1n7pe37/removing_a_dependency_major_minor_or_patch_bump/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n7pe37/removing_a_dependency_major_minor_or_patch_bump/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I&#39;ve been collaborating on an <a href="https://github.com/jcfitzpatrick12/spectre/issues/167">issue</a> for <a href="https://github.com/jcfitzpatrick12/spectre"><em>Spectre</em></a>, a Python program for recording radio spectrograms with software-defined radios. The motivation for the issue was to remove <a href="https://scipy.org/">Scipy</a> as dependency from a Python package used by the program called <a href="https://github.com/jcfitzpatrick12/spectre-core">spectre-core</a>.</p><p>The <a href="https://github.com/jcfitzpatrick12/spectre-core/pull/52">PR</a> introduced no changes from the perspective of the public API of the package. It just reimplemented the same functionality for our particular use case. However, we removed Scipy as a dependency since it was no longer required. Under <a href="https://semver.org/">semantic versioning</a>, would this constitute a major, minor or patch bump?</p><p>I considered making this a major bump, since any consumer of the package relying on Scipy being a transitive dependency would see a breaking change. But since the Scipy functionality wasn&#39;t exposed publically, I didn&#39;t think this argument was strong enough and so opted for a minor bump. What would you do?</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 01:35:24 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n7ibkk/dinov3clip_adapter/</link><title>DINOv3-CLIP Adapter</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n7ibkk/dinov3clip_adapter/</guid><comments>https://www.reddit.com/r/Python/comments/1n7ibkk/dinov3clip_adapter/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n7ibkk/dinov3clip_adapter/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Created a tiny adapter that connects DINOv3&#39;s image encoder to CLIP&#39;s text space.</p><p>Essentially, DINOv3 has better vision than CLIP, but no text capabilities. This lets you use dinov3 for images and CLIP for text prompts. This is still v1 so the next stages will be mentioned down below. </p><p><strong>Target Audience:</strong></p><p>ML engineers who want zero-shot image search without training massive models</p><p>Works for zero shot image search/labeling. Way smaller than full CLIP. Performance is definitely lower because it wasnt trained on image-text pairs.</p><p><strong>Next steps</strong>: May do image-text pair training. Definitely adding a segmentation or OD head. Better calibration and prompt templates</p><p>Code and more info can be found here: <a href="https://github.com/duriantaco/dinov3clip">https://github.com/duriantaco/dinov3clip</a></p><p>If you&#39;ll like to colab or whatever do ping me here or drop me an email. </p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 03 Sep 2025 21:14:11 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n7e1oa/zuban_is_now_open_source/</link><title>Zuban is now Open Source</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n7e1oa/zuban_is_now_open_source/</guid><comments>https://www.reddit.com/r/Python/comments/1n7e1oa/zuban_is_now_open_source/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n7e1oa/zuban_is_now_open_source/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Zuban, the successor of Jedi is now Open Source: <a href="https://github.com/zubanls/zuban">https://github.com/zubanls/zuban</a></p><p>Zuban is a high-performance Python Language Server and type checker implemented in Rust, by the author of Jedi. Zuban is 20–200× faster than Mypy, while using roughly half the memory and CPU compared to Ty and Pyrefly. It offers both a PyRight-like mode and a Mypy-compatible mode, which behaves just like Mypy; supporting the same config files, command-line flags, and error messages.</p><p>Most important LSP features are supported. Features include diagnostics, completions, goto, references, rename, hover and document highlights.</p><p>Zuban passes over 95% of Mypy’s relevant test suite and offers comprehensive support for Python&#39;s <a href="https://htmlpreview.github.io/?https://github.com/python/typing/blob/main/conformance/results/results.html">type system</a>.</p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 03 Sep 2025 18:25:41 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n75r76/contribution_of_python_to_the_world_is_underrated/</link><title>contribution of python to the world is underrated…</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n75r76/contribution_of_python_to_the_world_is_underrated/</guid><comments>https://www.reddit.com/r/Python/comments/1n75r76/contribution_of_python_to_the_world_is_underrated/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n75r76/contribution_of_python_to_the_world_is_underrated/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>found this on youtube scrolling, <a href="https://youtu.be/DRU-0tHOayc">https://youtu.be/DRU-0tHOayc</a></p><p>found it good at explaining how we got here…from first neuron’s birth to chatGPT, then the thought just struck me, none of it would have been possible without python…much of the world, still not aware about the contribution. Python has done so much in making lives of humans better in every possible way…</p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 03 Sep 2025 10:19:03 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n6xw8z/meet_thoad_high_order_derivatives_for_pytorch/</link><title>Meet THOAD, High Order Derivatives for PyTorch Graphs</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n6xw8z/meet_thoad_high_order_derivatives_for_pytorch/</guid><comments>https://www.reddit.com/r/Python/comments/1n6xw8z/meet_thoad_high_order_derivatives_for_pytorch/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 9 min | <a href='https://www.reddit.com/r/Python/comments/1n6xw8z/meet_thoad_high_order_derivatives_for_pytorch/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I’m excited to share <strong>thoad</strong> (short for Py<strong>T</strong>orch <strong>H</strong>igh <strong>O</strong>rder <strong>A</strong>utomatic <strong>D</strong>ifferentiation), a Python only library that computes arbitrary order partial derivatives directly on a PyTorch computational graph. The package has been developed within a research project at Universidad Pontificia de Comillas (ICAI), and we are considering publishing an academic article in the future that reviews the mathematical details and the implementation design.</p><p>At its core, thoad takes a one output to many inputs view of the graph and pushes high order derivatives back to the leaf tensors. Although a 1→N problem can be rewritten as 1→1 by concatenating flattened inputs, as in functional approaches such as <code>jax.jet</code> or <code>functorch</code>, thoad’s graph aware formulation enables an optimization based on <strong>unifying independent dimensions</strong> (especially batch). This delivers <strong>asymptotically better scaling</strong> with respect to batch size. Additionally, we compute derivatives <strong>vectorially</strong> rather than component by component, which is what makes a pure PyTorch implementation practical without resorting to custom C++ or CUDA.</p><p>The package is <strong>easy to maintain</strong>, because it is written entirely in Python and uses <strong>PyTorch</strong> as its only dependency. The implementation stays at a high level and leans on PyTorch’s vectorized operations, which means no custom C++ or CUDA bindings, no build systems to manage, and fewer platform specific issues.</p><p>The package can be installed from <strong>GitHub</strong> or <strong>PyPI</strong>:</p><ul><li>GitHub: <a href="https://github.com/mntsx/thoad">https://github.com/mntsx/thoad</a></li><li>PyPI: <a href="https://pypi.org/project/thoad/">https://pypi.org/project/thoad/</a></li></ul><p>In our benchmarks, <strong>thoad outperforms</strong> <code>torch.autograd</code> <strong>for Hessian calculations even on CPU</strong>. See the notebook that reproduces the comparison: <a href="https://github.com/mntsx/thoad/blob/master/examples/benchmarks/benchmark%5C_vs%5C_torch%5C_autograd.ipynb">https://github.com/mntsx/thoad/blob/master/examples/benchmarks/benchmark\_vs\_torch\_autograd.ipynb</a>.</p><p>The user experience has been one of our main concerns during development. <strong>thoad</strong> is designed to align closely with PyTorch’s interface philosophy, so running the high order backward pass is practically indistinguishable from calling PyTorch’s own <code>backward</code>. When you need finer control, you can keep or reduce Schwarz symmetries, group variables to restrict mixed partials, and fetch the exact mixed derivative you need. Shapes and independence metadata are also exposed to keep interpretation straightforward.</p><h1>USING THE PACKAGE</h1><p><strong>thoad</strong> exposes two primary interfaces for computing high-order derivatives:</p><ol><li><code>thoad.backward</code>: a function-based interface that closely resembles <code>torch.Tensor.backward</code>. It provides a quick way to compute high-order gradients without needing to manage an explicit controller object, but it offers only the core functionality (derivative computation and storage).</li><li><code>thoad.Controller</code>: a class-based interface that wraps the output tensor’s subgraph in a controller object. In addition to performing the same high-order backward pass, it gives access to advanced features such as fetching specific mixed partials, inspecting batch-dimension optimizations, overriding backward-function implementations, retaining intermediate partials, and registering custom hooks.</li></ol><p><strong>thoad.backward</strong></p><p>The <code>thoad.backward</code> function computes high-order partial derivatives of a given output tensor and stores them in each leaf tensor’s <code>.hgrad</code> attribute.</p><p><strong>Arguments</strong>:</p><ul><li><code>tensor</code>: A PyTorch tensor from which to start the backward pass. This tensor must require gradients and be part of a differentiable graph.</li><li><code>order</code>: A positive integer specifying the maximum order of derivatives to compute.</li><li><code>gradient</code>: A tensor with the same shape as <code>tensor</code> to seed the vector-Jacobian product (i.e., custom upstream gradient). If omitted, the default is used.</li><li><code>crossings</code>: A boolean flag (default=<code>False</code>). If set to <code>True</code>, mixed partial derivatives (i.e., derivatives that involve more than one distinct leaf tensor) will be computed.</li><li><code>groups</code>: An iterable of disjoint groups of leaf tensors. When <code>crossings=False</code>, only those mixed partials whose participating leaf tensors all lie within a single group will be calculated. If <code>crossings=True</code> and <code>groups</code> is provided, a <em>ValueError</em> will be raised (they are mutually exclusive).</li><li><code>keep_batch</code>: A boolean flag (default=<code>False</code>) that controls how output dimensions are organized in the computed gradients.<ul><li><strong>When</strong> <code>keep_batch=False</code>: The derivative preserves one first flattened &quot;primal&quot; axis, followed by each original partial shape, sorted in differentiation order. Concretelly:<ul><li>A single &quot;primal&quot; axis that contains every element of the graph output tensor (flattened into one dimension).</li><li>A group of axes per derivative order, each matching the shape of the respective differentially targeted tensor.</li></ul></li><li>For an N-th order derivative of a leaf tensor with <code>input_numel</code> elements and an output with <code>output_numel</code> elements, the gradient shape is:<ul><li><strong>Axis 1:</strong> indexes all <code>output_numel</code> outputs</li><li><strong>Axes 2…(sum(Nj)+1):</strong> each indexes all <code>input_numel</code> inputs</li></ul></li><li><strong>When</strong> <code>keep_batch=True</code>: The derivative shape follows the same ordering as in the previous case, but includes a series of &quot;independent dimensions&quot; immediately after the &quot;primal&quot; axis:<ul><li><strong>Axis 1</strong> flattens all elements of the output tensor (size = <code>output_numel</code>).</li><li><strong>Axes 2...(k+i+1)</strong> correspond to dimensions shared by multiple input tensors and treated independently throughout the graph. These are dimensions that are only operated on element-wise (e.g. batch dimensions).</li><li><strong>Axes (k+i+1)...(k+i+sum(Nj)+1)</strong> each flatten all <code>input_numel</code> elements of the leaf tensor, one axis per derivative order.</li></ul></li></ul></li><li><code>keep_schwarz</code>: A boolean flag (default=<code>False</code>). If <code>True</code>, symmetric (Schwarz) permutations are retained explicitly instead of being canonicalized/reduced—useful for debugging or inspecting non-reduced layouts.</li></ul><p><strong>Returns</strong>:</p><ul><li>An instance of <code>thoad.Controller</code> wrapping the same tensor and graph</li></ul><p>Executing the automatic differentiation via <code>thoad.backprop</code> looks like this.</p><pre><code>import torchimport thoadfrom torch.nn import functional as F#### Normal PyTorch workflowX = torch.rand(size=(10,15), requires_grad=True)Y = torch.rand(size=(15,20), requires_grad=True)Z = F.scaled_dot_product_attention(query=X, key=Y.T, value=Y.T)#### Call thoad backwardorder = 2thoad.backward(tensor=Z, order=order)#### Checks## check derivative shapesfor o in range(1, 1 + order):   assert X.hgrad[o - 1].shape == (Z.numel(), *(o * tuple(X.shape)))   assert Y.hgrad[o - 1].shape == (Z.numel(), *(o * tuple(Y.shape)))## check first derivatives (jacobians)fn = lambda x, y: F.scaled_dot_product_attention(x, y.T, y.T)J = torch.autograd.functional.jacobian(fn, (X, Y))assert torch.allclose(J[0].flatten(), X.hgrad[0].flatten(), atol=1e-6)assert torch.allclose(J[1].flatten(), Y.hgrad[0].flatten(), atol=1e-6)## check second derivatives (hessians)fn = lambda x, y: F.scaled_dot_product_attention(x, y.T, y.T).sum()H = torch.autograd.functional.hessian(fn, (X, Y))assert torch.allclose(H[0][0].flatten(), X.hgrad[1].sum(0).flatten(), atol=1e-6)assert torch.allclose(H[1][1].flatten(), Y.hgrad[1].sum(0).flatten(), atol=1e-6)</code></pre><p><strong>Instantiation</strong></p><p>Use the constructor to create a controller for any tensor requiring gradients:</p><pre><code>controller = thoad.Controller(tensor=GO)  ## takes graph output tensor</code></pre><ul><li><code>tensor</code>: A PyTorch <code>Tensor</code> with <code>requires_grad=True</code> and a non-<code>None</code> <code>grad_fn</code>.</li></ul><p><strong>Properties</strong></p><ul><li><code>.tensor → Tensor</code> The output tensor underlying this controller. <strong>Setter</strong>: Replaces the tensor (after validation), rebuilds the internal computation graph, and invalidates any previously computed gradients.</li><li><code>.compatible → bool</code> Indicates whether every backward function in the tensor’s subgraph has a supported high-order implementation. If <code>False</code>, some derivatives may fall back or be unavailable.</li><li><code>.index → Dict[Type[torch.autograd.Function], Type[ExtendedAutogradFunction]]</code> A mapping from base PyTorch <code>autograd.Function</code> classes to thoad’s <code>ExtendedAutogradFunction</code> implementations. <strong>Setter</strong>: Validates and injects your custom high-order extensions.</li></ul><p><strong>Core Methods</strong></p><p><strong>.backward(order, gradient=None, crossings=False, groups=None, keep_batch=False, keep_schwarz=False) → None</strong></p><p>Performs the high-order backward pass up to the specified derivative <code>order</code>, storing all computed partials in each leaf tensor’s <code>.hgrad</code> attribute.</p><ul><li><code>order</code> (<code>int &gt; 0</code>): maximum derivative order.</li><li><code>gradient</code> (<code>Optional[Tensor]</code>): custom upstream gradient with the same shape as <code>controller.tensor</code>.</li><li><code>crossings</code> (<code>bool</code>, default <code>False</code>): If <code>True</code>, mixed partial derivatives across different leaf tensors will be computed.</li><li><code>groups</code> (<code>Optional[Iterable[Iterable[Tensor]]]</code>, default <code>None</code>): When <code>crossings=False</code>, restricts mixed partials to those whose leaf tensors all lie within a single group. If <code>crossings=True</code> and <code>groups</code> is provided, a <em>ValueError</em> is raised.</li><li><code>keep_batch</code> (<code>bool</code>, default <code>False</code>): controls whether independent output axes are kept separate (batched) or merged (flattened) in stored/retrieved gradients.</li><li><code>keep_schwarz</code> (<code>bool</code>, default <code>False</code>): if <code>True</code>, retains symmetric permutations explicitly (no Schwarz reduction).</li></ul><p><strong>.display_graph() → None</strong></p><p>Prints a tree representation of the tensor’s backward subgraph. Supported nodes are shown normally; unsupported ones are annotated with <code>(not supported)</code>.</p><p><strong>.register_backward_hook(variables: Sequence[Tensor], hook: Callable) → None</strong></p><p>Registers a user-provided <code>hook</code> to run during the backward pass whenever gradients for any of the specified leaf <code>variables</code> are computed.</p><ul><li><code>variables</code> (<code>Sequence[Tensor]</code>): Leaf tensors to monitor.</li><li><code>hook</code> (<code>Callable[[Tuple[Tensor, Tuple[Shape, ...], Tuple[Indep, ...]], dict[AutogradFunction, set[Tensor]]], Tuple[Tensor, Tuple[Shape, ...], Tuple[Indep, ...]]]</code>): Receives the current <code>(Tensor, shapes, indeps)</code> plus contextual info, and must return the modified triple.</li></ul><p><strong>.require_grad_(variables: Sequence[Tensor]) → None</strong></p><p>Marks the given leaf <code>variables</code> so that all intermediate partials involving them are retained, even if not required for the final requested gradients. Useful for inspecting or re-using higher-order intermediates.</p><p><strong>.fetch_hgrad(variables: Sequence[Tensor], keep_batch: bool = False, keep_schwarz: bool = False) → Tuple[Tensor, Tuple[Tuple[Shape, ...], Tuple[Indep, ...], VPerm]]</strong></p><p>Retrieves the precomputed high-order partial corresponding to the ordered sequence of leaf <code>variables</code>.</p><ul><li><code>variables</code> (<code>Sequence[Tensor]</code>): the leaf tensors whose mixed partial you want.</li><li><code>keep_batch</code> (<code>bool</code>, default <code>False</code>): if <code>True</code>, each independent output axis remains a separate batch dimension in the returned tensor; if <code>False</code>, independent axes are distributed/merged into derivative dimensions.</li><li><code>keep_schwarz</code> (<code>bool</code>, default <code>False</code>): if <code>True</code>, returns derivatives retaining symmetric permutations explicitly.</li></ul><p>Returns a pair:</p><ol><li><strong>Gradient tensor</strong>: the computed partial derivatives, shaped according to output and input dimensions (respecting <code>keep_batch</code>/<code>keep_schwarz</code>).</li><li><strong>Metadata tuple</strong><ul><li><strong>Shapes</strong> (<code>Tuple[Shape, ...]</code>): the original shape of each leaf tensor.</li><li><strong>Indeps</strong> (<code>Tuple[Indep, ...]</code>): for each variable, indicates which output axes remained independent (batch) vs. which were merged into derivative axes.</li><li><strong>VPerm</strong> (<code>Tuple[int, ...]</code>): a permutation that maps the internal derivative layout to the requested <code>variables</code> order.</li></ul></li></ol><p>Use the combination of independent-dimension info and shapes to reshape or interpret the returned gradient tensor in your workflow.</p><pre><code>import torchimport thoadfrom torch.nn import functional as F#### Normal PyTorch workflowX = torch.rand(size=(10,15), requires_grad=True)Y = torch.rand(size=(15,20), requires_grad=True)Z = F.scaled_dot_product_attention(query=X, key=Y.T, value=Y.T)#### Instantiate thoad controller and call backwardorder = 2controller = thoad.Controller(tensor=Z)controller.backward(order=order, crossings=True)#### Fetch Partial Derivatives## fetch X and Y 2nd order derivativespartial_XX, _ = controller.fetch_hgrad(variables=(X, X))partial_YY, _ = controller.fetch_hgrad(variables=(Y, Y))assert torch.allclose(partial_XX, X.hgrad[1])assert torch.allclose(partial_YY, Y.hgrad[1])## fetch cross derivativespartial_XY, _ = controller.fetch_hgrad(variables=(X, Y))partial_YX, _ = controller.fetch_hgrad(variables=(Y, X))</code></pre><blockquote><p>NOTE. A more detailed user guide with examples and feature walkthroughs is available in the notebook: <a href="https://github.com/mntsx/thoad/blob/master/examples/user_guide.ipynb">https://github.com/mntsx/thoad/blob/master/examples/user_guide.ipynb</a></p></blockquote><p>If you give it a try, I would love feedback on the API.</p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 03 Sep 2025 04:07:59 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n6v3tl/pyline_update_terminal_based_text_editor_linux/</link><title>PyLine Update - terminal based text editor (Linux, WSL, MacOS) (New Feats)</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n6v3tl/pyline_update_terminal_based_text_editor_linux/</guid><comments>https://www.reddit.com/r/Python/comments/1n6v3tl/pyline_update_terminal_based_text_editor_linux/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n6v3tl/pyline_update_terminal_based_text_editor_linux/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hello, this is a hobby project I coded entirely in Python 3 , created longer time ago. But came back to it this spring. Now updated with new functionality and better code structure currently at v0.9.7.</p><p>Source at - <a href="https://github.com/Peter-L-SVK/PyLine">PyLine GitHub repo</a>  (you can see screenshots in readme)</p><h1>What My Project Does:</h1><p>It is CLI text editor with:<br/>- function like wc - cw - counts chars, words and lines<br/>- open / create / truncate file<br/>- exec mode that is like file browser and work with directories<br/>- scroll-able text-buffer, currently set to 52 lines<br/>- supports all clipboards for GUI: X11,Wayland, win32yank for WSL and pbpaste for MacOS<br/>- multiple lines selection copy/paste/overwrite and delete<br/>- edit history implemented via LIFO - Last In First Out (limit set to 120)<br/>- highlighting of .py syntax (temporary tho, will find the better way)<br/>- comes with proper install script</p><h1>New features:</h1><p>- Support of args &lt;filename&gt;, -i/--info and -h/--help<br/>- Modular hooks system with priority, runtime enable/disable, cross-language support (Python, Perl, Bash, Ruby, Lua, Node.js, PHP)<br/>- Hook manager UI (list, enable/disable, reload hooks, show info)<br/>- BufferManager, NavigationManager, SelectionManager, PasteBuffer, UndoManager all refactored for composition and extensibility (micro-kernel like architecture)<br/>- Hook-enabled file loading/saving, multi-language event handlers<br/>- Enhanced config and state management (per-user config dir)<br/>- Improved argument parsing and info screens</p><p>It also comes with prepackaged hooks like smart tab indent.</p><p>The editor is using built-in to the terminal foreground/background but I plan to implement themes and config.ini alongside search / replace feature.</p><h1>Target Audience:</h1><p>Basically anyone with Linux, WSL or other Unix-like OS. Nothing complicated to use.</p><p>(I know it&#39;s not too much.. I don&#39;t have any degree in CS or IT engineering or so, just passion)</p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 03 Sep 2025 02:16:35 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n658es/is_it_a_good_idea_to_teach_students_python_but/</link><title>Is it a good idea to teach students Python but using an old version?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n658es/is_it_a_good_idea_to_teach_students_python_but/</guid><comments>https://www.reddit.com/r/Python/comments/1n658es/is_it_a_good_idea_to_teach_students_python_but/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n658es/is_it_a_good_idea_to_teach_students_python_but/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>EDIT: Talking about IDLE here</p><p>Sorry if this is the wrong sub.</p><p>When i went to high school (UK) in 2018, we had 3.4.2 (which at the time wasn&#39;t even the latest 3.4.x). In 2020 they upgraded to 3.7, but just days later downgraded back to 3.4.2. I asked IT manager why and they said its because of older students working on long projects. But doubt that was the reason because fast forward to 2023 the school still had 3.4.2 which was end of life.</p><p>Moved to a college that same year that had 3.12, but this summer 2025, after computer upgrades to windows 11, we are now on 3.10 for some reason. I start a new year in college today so I&#39;ll be sure to ask the teacher.</p><p>Are there any drawbacks to teaching using an old version? It will just be the basics and a project or 2</p></div><!-- SC_ON --></section>]]></description><pubDate>Tue, 02 Sep 2025 05:51:40 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n64bla/i_built_a_simple_opensource_windows_wallpaper/</link><title>I built a simple, open-source Windows wallpaper changer because the built-in one kept failing.</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n64bla/i_built_a_simple_opensource_windows_wallpaper/</guid><comments>https://www.reddit.com/r/Python/comments/1n64bla/i_built_a_simple_opensource_windows_wallpaper/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n64bla/i_built_a_simple_opensource_windows_wallpaper/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><h1>What My Project Does</h1><p>This is a simple, lightweight desktop application for Windows that automatically changes your desktop wallpaper from a folder of images. You can choose a folder, set a custom time interval (in seconds, minutes, or hours), and have your pictures shuffle randomly. It can be minimized to the system tray. The application is built using <code>customtkinter</code> for the GUI and <code>pystray</code> for the system tray functionality.</p><h1>Target Audience</h1><p>I write it for personal use and for anyone who wants a simple and minimalist way to manage their desktop wallpapers. It is a &quot;toy project&quot; in the sense that it started as a solution to a personal frustration, but it is meant to be a tool for everyday use.</p><h1>Comparison</h1><p>I wrote this because the built-in Windows slideshow feature randomly stops working, which is incredibly frustrating and annoying, and they have been too lazy to fix it. Other third-party programs I looked at were often too cluttered with features I didn&#39;t need and/or were also resource-hungry. This application is meant to be a clean, minimal alternative that focuses on its single task.</p><p>You can find it here: <a href="https://github.com/m-sarabi/wallpaper_changer/releases/tag/v1.0.0">Wallpaper Changer</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Tue, 02 Sep 2025 05:08:36 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n5ux0w/python_ocr_automatically_analyze_dota_2_player/</link><title>Python + OCR: Automatically analyze Dota 2 player stats 👀</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n5ux0w/python_ocr_automatically_analyze_dota_2_player/</guid><comments>https://www.reddit.com/r/Python/comments/1n5ux0w/python_ocr_automatically_analyze_dota_2_player/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n5ux0w/python_ocr_automatically_analyze_dota_2_player/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><h1>What My Project Does</h1><p>This Python script uses OCR to read Dota 2 friend IDs from your screen, fetches match data from the OpenDota API, and calculates winrates and most played heroes to detect potential smurfs.<br/>It provides a simple GUI that shows overall winrate and the most played hero of the selected player.</p><h1>Target Audience</h1><p>Python enthusiasts, Dota 2 players, or anyone interested in game data analysis and automation.<br/>This is mainly an educational and experimental project, not intended for cheating or modifying the game.</p><h1>Comparison</h1><p>Unlike other Dota 2 analytics tools, this script uses OCR to automatically read friend IDs from the screen, eliminating the need to manually input player IDs.<br/>It combines GUI feedback, Python automation, and API integration in a single lightweight tool.</p><p><a href="https://github.com/N3uvin/opendota2-vision">GitHub Repository</a></p><p><strong><em>I’m open to feedback, feature suggestions, or any ideas to improve the script!</em></strong></p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 01 Sep 2025 22:55:57 +0530</pubDate></item></channel></rss>
