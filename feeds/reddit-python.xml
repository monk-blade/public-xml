<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><atom:link href="http://192.168.1.132/?platform=reddit&amp;subreddit=Python&amp;averagePostsPerDay=5&amp;content&amp;view=rss" rel="self" type="application/rss+xml"/><title>/r/Python</title><description>Hot posts in /r/Python (roughly 5 posts per day)</description><link>https://www.reddit.com/r/Python/</link><language>en-us</language><lastBuildDate>Sun, 07 Sep 2025 12:54:00 +0000</lastBuildDate><generator>Upvote RSS</generator><image><url>http://192.168.1.132//app/cache/images/styles-redditmedia-com-t5_2qh0y-styles-communityIcon_mkayghu1502d1-144x400.png</url><title>/r/Python</title><link>https://www.reddit.com/r/Python/</link><width>144</width><height>144</height></image><item><link>https://www.reddit.com/r/Python/comments/1nakbd6/pythonjsonlogger_v400rc1_released/</link><title>Python-JSON-Logger v4.0.0.rc1 Released</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nakbd6/pythonjsonlogger_v400rc1_released/</guid><comments>https://www.reddit.com/r/Python/comments/1nakbd6/pythonjsonlogger_v400rc1_released/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1nakbd6/pythonjsonlogger_v400rc1_released/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hi All, maintainer of <a href="https://github.com/nhairs/python-json-logger">python-json-logger</a> here with a new (pre) release for you.</p><p>It can be installed using <code>python-json-logger==4.0.0.rc1</code></p><h1>What&#39;s new?</h1><p>This release has a few quality of life improvements that also happen to be breaking changes. The <a href="https://nhairs.github.io/python-json-logger/4.0.0/changelog/">full change log is here</a> but to give an overview:</p><p><strong>Support for</strong> <code>ext://</code> <strong>when using</strong> <code>dictConfig</code> <strong>/</strong> <code>fileConfig</code></p><p>This allows you to reference Python objects in your config for example:</p><pre><code>version: 1disable_existing_loggers: Falseformatters:  default:    &quot;()&quot;: pythonjsonlogger.json.JsonFormatter    format: &quot;%(asctime)s %(levelname)s %(name)s %(module)s %(funcName)s %(lineno)s %(message)s&quot;    json_default: ext://logging_config.my_json_default    rename_fields:      &quot;asctime&quot;: &quot;timestamp&quot;      &quot;levelname&quot;: &quot;status&quot;    static_fields:      &quot;service&quot;: ext://logging_config.PROJECT_NAME      &quot;env&quot;: ext://logging_config.ENVIRONMENT      &quot;version&quot;: ext://logging_config.PROJECT_VERSION      &quot;app_log&quot;: &quot;true&quot;handlers:  default:    formatter: default    class: logging.StreamHandler    stream: ext://sys.stderr  access:    formatter: default    class: logging.StreamHandler    stream: ext://sys.stdoutloggers:  uvicorn.error:    level: INFO    handlers:      - default    propagate: no  uvicorn.access:    level: INFO    handlers:      - access    propagate: no</code></pre><p><strong>Support for easier to use formats</strong></p><p>We now support a comma <code>style=&quot;,&quot;</code> style which lets use a comma seperate string to specific fields.</p><pre><code>formatter = JsonFormatter(&quot;message,asctime,exc_info&quot;, style=&quot;,&quot;)</code></pre><p>We also using any sequence of strings (e.g. lists or tuples).</p><pre><code>formatter = JsonFormatter([&quot;message&quot;, &quot;asctime&quot;, &quot;exc_info&quot;])</code></pre><h1>What is Python JSON Logger</h1><p>If you&#39;ve not heard of this package, Python JSON Logger enables you produce JSON logs when using Python&#39;s¬†<code>logging</code>¬†package.</p><p>JSON logs are machine readable allowing for much easier parsing and ingestion into log aggregation tools.</p><p>For example here is the (formatted) log output of one of my programs:</p><pre><code>{  &quot;trace_id&quot;: &quot;af922f04redacted&quot;,  &quot;request_id&quot;: &quot;cb1499redacted&quot;,  &quot;parent_request_id&quot;: null,  &quot;message&quot;: &quot;Successfully imported redacted&quot;,  &quot;levelname&quot;: &quot;INFO&quot;,  &quot;name&quot;: &quot;redacted&quot;,  &quot;pathname&quot;: &quot;/code/src/product_data/consumers/games.py&quot;,  &quot;lineno&quot;: 41,  &quot;timestamp&quot;: &quot;2025-09-06T08:00:48.485770+00:00&quot;}</code></pre><h1>Why post to Reddit?</h1><p>Although Python JSON Logger <a href="https://hugovk.github.io/top-pypi-packages/">is in the top 300 downloaded packaged from PyPI</a> (in the last month it&#39;s been downloaded more times that UV! ... just), there&#39;s not many people watching the repository <a href="https://www.reddit.com/r/Python/comments/1hcm2rr/pythonjsonlogger_has_changed_hands/">after it changed hands</a> at the end of 2024.</p><p>This seemed the most appropriate way to share the word in order to minimise disruptions once it is released.</p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 07 Sep 2025 10:18:52 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nag19u/ensures_simple_design_by_contract/</link><title>ensures: simple Design by Contract</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nag19u/ensures_simple_design_by_contract/</guid><comments>https://www.reddit.com/r/Python/comments/1nag19u/ensures_simple_design_by_contract/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1nag19u/ensures_simple_design_by_contract/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><ul><li><strong>What My Project Does</strong></li></ul><p>There are a few other packages for this, but I decided to make one that is simple, readable, accepts arbitrary functions, and uses the Result type from functional programming. You can find more details in the readme: <a href="https://github.com/brunodantas/ensures">https://github.com/brunodantas/ensures</a></p><blockquote><p>ensures is a simple Python package that implements the idea of Design by Contract described in the Pragmatic Paranoia chapter of The Pragmatic Programmer. That&#39;s the chapter where they say you should trust nobody, not even yourself.</p></blockquote><ul><li><strong>Target Audience</strong>¬†(e.g., Is it meant for production, just a toy project, etc.)</li></ul><p>Anyone interested in <del>paranoia</del> decorating functions with precondition functions etc and use a Functional data structure in the process.</p><p>I plan to add pytest tests to make this more production-ready. Any feedback is welcome.</p><ul><li><strong>Comparison</strong>¬†(A brief comparison explaining how it differs from existing alternatives.)</li></ul><p>None of the alternatives I found seem to implement arbitrary functions plus the Result type, while being simple and readable.</p><p>But some of the alternatives are icontract, contracts, deal. Each with varying levels of the above.</p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 07 Sep 2025 06:32:47 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1na9od6/built_a_free_vs_code_extension_for_python/</link><title>Built a free VS Code extension for Python dependencies - no more PyPI tab switching</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1na9od6/built_a_free_vs_code_extension_for_python/</guid><comments>https://www.reddit.com/r/Python/comments/1na9od6/built_a_free_vs_code_extension_for_python/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1na9od6/built_a_free_vs_code_extension_for_python/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Tired of switching to PyPI tabs to check package versions?</p><p>Just released <strong>Tombo</strong> - brings PyPI directly into VS Code:</p><p><strong>What it does (complements your existing workflow):</strong></p><ul><li>uv/poetry handle installation ‚Üí Tombo handles version selection</li><li>Hover <code>requests</code> ‚Üí see ALL versions + Python compatibility</li><li>Type <code>numpy&gt;=</code> ‚Üí intelligent version suggestions for your project</li><li>Perfect for big projects (10+ deps) - no more version hunting</li><li>Then let uv/poetry create the lock files</li></ul><p><strong>Demo in 10 seconds:</strong></p><ol><li>Open any Python project</li><li>Type <code>django&gt;=</code></li><li>Get instant version suggestions</li><li>Hover packages for release info</li></ol><p><strong>Installation:</strong> VS Code ‚Üí Search &quot;Tombo&quot; ‚Üí Install</p><p><strong>Free &amp; open source</strong> - no tracking, no accounts, just works.</p><p>‚≠ê <strong>Star the project</strong> if you find it useful: <a href="https://github.com/benbenbang/tombo">https://github.com/benbenbang/tombo</a></p><p>VS Code Marketplace: <a href="https://marketplace.visualstudio.com/items?itemName=benbenbang.tombo">https://marketplace.visualstudio.com/items?itemName=benbenbang.tombo</a></p><p>Documentation: <a href="https://benbenbang.github.io/tombo/">https://benbenbang.github.io/tombo/</a></p><p>Anyone else tired of manual PyPI lookups? ü§¶‚Äç‚ôÇÔ∏è</p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 07 Sep 2025 01:48:17 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1na61l2/ducky_my_opensource_networking_security_toolkit/</link><title>Ducky, my open-source networking &amp;amp; security toolkit for Network Engineers, Sysadmins, and Pentester</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1na61l2/ducky_my_opensource_networking_security_toolkit/</guid><comments>https://www.reddit.com/r/Python/comments/1na61l2/ducky_my_opensource_networking_security_toolkit/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1na61l2/ducky_my_opensource_networking_security_toolkit/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hey everyone, For a long time, I&#39;ve been frustrated with having to switch between a dozen different apps for my networking tasks PuTTY for SSH, a separate port scanner, a subnet calculator, etc.</p><p>To solve this, I built¬†<strong>Ducky</strong>, a free and open-source, all-in-one toolkit that combines these essential tools into one clean, tabbed interface.</p><p><strong>What it does:</strong></p><ul><li><strong>Multi-Protocol Tabbed Terminal:</strong>¬†Full support for SSH, Telnet, and Serial (COM) connections.</li><li><strong>Network Discovery:</strong>¬†An ARP scanner to find live hosts on your local network and a visual Topology Mapper.</li><li><strong>Essential Tools:</strong>¬†It also includes a Port Scanner, CVE Vulnerability Lookup, Hash Cracker, and other handy utilities.</li></ul><p><strong>Target Audience:</strong><br/>I built this for anyone who works with networks or systems, including:</p><ul><li><strong>Network Engineers &amp; Sysadmins:</strong>¬†For managing routers, switches, and servers without juggling multiple windows.</li><li><strong>Cybersecurity Professionals &amp; Students:</strong>¬†A great all-in-one tool for pentesting, vulnerability checks (CVE), and learning.</li><li><strong>Homelabbers &amp; Tech Enthusiasts:</strong>¬†The perfect command center for managing your home lab setup.</li><li><strong>Fellow Python Developers:</strong>¬†To see a practical desktop application built with¬†<strong>PySide6</strong>.</li></ul><p><strong>How you can help:</strong><br/>The project is 100% open-source, and I&#39;m actively looking for contributors and feedback!</p><ul><li><strong>Report bugs or issues:</strong>¬†Find something that doesn&#39;t work right? Please open an issue on GitHub.</li><li><strong>Suggest enhancements:</strong>¬†Have an idea for a new tool or an improvement? Let&#39;s discuss it!</li><li><strong>Contribute code:</strong>¬†Pull Requests are always welcome.</li><li><strong>GitHub Repo (Source Code &amp; Issues):</strong>¬†<a href="https://github.com/thecmdguy/Ducky">https://github.com/thecmdguy/Ducky</a></li><li><strong>Project Homepage:</strong>¬†<a href="https://ducky.ge/">https://ducky.ge/</a></li></ul><p>Thanks for taking a look!</p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 06 Sep 2025 23:23:19 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1na5fk2/from_stress_to_success_load_testing_python_apps/</link><title>From Stress to Success: Load Testing Python Apps ‚Äì Open Source Example</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1na5fk2/from_stress_to_success_load_testing_python_apps/</guid><comments>https://www.reddit.com/r/Python/comments/1na5fk2/from_stress_to_success_load_testing_python_apps/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1na5fk2/from_stress_to_success_load_testing_python_apps/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>What My Project Does:</strong><br/>This project demonstrates <strong>load testing Python applications</strong> and <strong>visualizing performance metrics</strong>. It uses a sample Python app, Locust for stress testing, Prometheus for metrics collection, and Grafana for dashboards. It‚Äôs designed to give a hands-on example of how to simulate load and understand app performance.</p><p><strong>Target Audience:</strong><br/>Developers and Python enthusiasts who want to learn or experiment with load testing and performance visualization. It‚Äôs meant as a <strong>learning tool and reference</strong>, not a production-ready system.</p><p><strong>Comparison:</strong><br/>Unlike generic tutorials or scattered examples online, this repo bundles everything together‚Äîapp, load scripts, Prometheus, and Grafana dashboards‚Äîso you can <strong>see the full workflow from stress testing to visualization in one place</strong>.</p><p><strong>Repo Link:</strong><br/><a href="https://github.com/Alleny244/locust-grafana-prometheus">https://github.com/Alleny244/locust-grafana-prometheus</a></p><p>Would love feedback, suggestions, or improvements from the community!</p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 06 Sep 2025 22:59:34 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1na21zu/jollyradio_a_web_based_radio/</link><title>JollyRadio - A web based radio</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1na21zu/jollyradio_a_web_based_radio/</guid><comments>https://www.reddit.com/r/Python/comments/1na21zu/jollyradio_a_web_based_radio/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1na21zu/jollyradio_a_web_based_radio/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>What My Project Does</strong> </p><p>JollyRadio is a web based, simple radio where you can find lots of live streams. It&#39;s designed to be easy to navigate and have less extra fluff. </p><p><strong>Target Audience</strong> </p><p>JollyRadio is for people who want to listen to radio! It has basic filtering to filter out bad stuff, but you may still need to know what to do and not do. </p><p><strong>Comparison</strong> </p><p>Compared to other web based radios, JollyRadio is designed to be local-focused and more minimalistic. There are three sections, exploring, local stations and searching for stations. It is better if you want a easy, minimal interface.</p><p><strong>Technical Explanation</strong></p><p>JollyRadio is written in Python (Flask) with HTML (Bootstrap). I&#39;m new to programming, so please don&#39;t expect a perfect product. It uses the RadioBrowser API to find the radio stations.</p><p><strong>Links</strong></p><p>GitHub Link: <a href="https://github.com/SeafoodStudios/JollyRadio">https://github.com/SeafoodStudios/JollyRadio</a></p><p>Radio Link: <a href="https://tryjollyradio.seafoodstudios.com/">https://tryjollyradio.seafoodstudios.com/</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 06 Sep 2025 20:44:15 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n9urtc/automating_power_supply_measurements_with_pyvisa/</link><title>Automating Power Supply Measurements with PyVisa &amp;amp; Pytest</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n9urtc/automating_power_supply_measurements_with_pyvisa/</guid><comments>https://www.reddit.com/r/Python/comments/1n9urtc/automating_power_supply_measurements_with_pyvisa/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n9urtc/automating_power_supply_measurements_with_pyvisa/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>Target Audience:</strong></p><ul><li>R&amp;D Development &amp; Test Enginners</li><li>Electrical Engineering Students</li><li>Python Automation Experts</li></ul><p><strong>What My Project Does:</strong></p><p>I created a small python library: <a href="https://github.com/ammarkh95/pypm-test">pypm-test</a> which could be used for automating measurements with the pictured instruments.</p><p>You could also use it as reference to automate similar functions with your available instruments. The library is Python based and makes use of <a href="https://pyvisa.readthedocs.io/en/latest/">PyVisa </a>library for communction with electronic eqipment supporting <a href="https://www.ivifoundation.org/About-IVI/scpi.html">SCPI </a>standard.</p><p>The library also includes some <a href="https://docs.pytest.org/en/stable/explanation/fixtures.html">pytest-fixtures</a> which makes it nice to use in automated testing environment.</p><p>Below I share summary of the hardware used and developed python library as well as some example results for an automated DC-DC converter measurements. You can find all the details in my <a href="https://ak-experiments.blogspot.com/2025/09/automating-power-supply-measurements.html">blog post</a></p><p><strong>Hardware:</strong></p><p>I had access to the following instruments:</p><p><a href="https://www.keysight.com/us/en/support/U3606B/multimeter-dc-power-supply.html">Keysight U3606B</a>: Combination of a 5.5 digit digital multimeter and 30-W power supply in a single unit<br/><a href="https://www.keysight.com/us/en/products/source-measure-units-smu/u2722a-u2723a-usb-modular-source-measure-units-smu.html">Keysight U2723A:</a> Modular source measure unit (SMU) Four-quadrant operation (¬± 120 mA/¬± 20 V)</p><p><strong>Software:</strong></p><p>The developd library contain wrapper classes that implement the control and measurement functions of the above instruments.</p><p>The exposed functions by the SCPI interface are normally documented in the programming manuals of the equipment published online. So it was just a matter of going through the manuals to get the required <a href="https://www.ivifoundation.org/About-IVI/scpi.html">SCPI</a> commands / queries for a given instrument function and then sending it over to the instrument using <a href="https://pyvisa.readthedocs.io/en/latest/">PyVisa</a> write and query functions.</p><p><strong>Example:</strong></p><p>A classical example application with a power supply and source measure unit is to evaluate the efficiency of DC-DC conversion for a given system. It is also a nice candiate &quot;parameteric study&quot; for automation to see how does the output power compares to the input power (i.e. effeciency) at different inputs voltges / sink currents. You can view the code behind similar test directly from my repo <a href="https://github.com/ammarkh95/pypm-test/blob/f5434110e7dffd4adeff23f09d9ca10877fc1dbb/testing/example_tests/test_dc_dc_converter.py#L84">here</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 06 Sep 2025 14:28:25 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n9qlkv/what_are_some_nonai_toolsextensions_which_have/</link><title>What are some non-AI tools/extensions which have really boosted your work life or made life easier?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n9qlkv/what_are_some_nonai_toolsextensions_which_have/</guid><comments>https://www.reddit.com/r/Python/comments/1n9qlkv/what_are_some_nonai_toolsextensions_which_have/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n9qlkv/what_are_some_nonai_toolsextensions_which_have/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>It can be an extension or a CLI tool or something else, My work mainly involves in developing managing mid sized python applications deployed over aws. I mostly work through cursor and agents have been decently useful but these days all the development on programming tools seems to be about AI integration. Is there something that people here have been using that&#39;s come out in last few years and has made serious impact in how you do things? Can be open source or not, anything goes it just shouldn&#39;t be something AI or a framework.</p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 06 Sep 2025 10:11:33 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n9q2p1/python_idles_practical_upgrade_file_tree_tabbed/</link><title>Python IDLE's practical upgrade: file tree, tabbed editing, console view using only stdlib+tkinter.</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n9q2p1/python_idles_practical_upgrade_file_tree_tabbed/</guid><comments>https://www.reddit.com/r/Python/comments/1n9q2p1/python_idles_practical_upgrade_file_tree_tabbed/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n9q2p1/python_idles_practical_upgrade_file_tree_tabbed/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I was tinkering with IDLE and wondered: what if it had just a few modern quality-of-life improvements, but implemented entirely with Python‚Äôs standard library (so no extra dependencies, just <code>tkinter</code>)?</p><p>Specifically:</p><ul><li>File tree view (browse/open files inside the IDE itself)</li><li>Tabbed editing (each opened file gets its own tab)</li><li>Console view embedded alongside tabs</li><li>Still dead-simple, light, and portable</li></ul><p>The idea isn‚Äôt to compete with full IDEs like PyCharm or VS Code, but to provide a <em>corporate-safe</em>, zero-install, batteries-included IDE that works even on fenced machines where you can‚Äôt pull in external editors or packages.</p><p>Think of it as ‚ÄúIDLE-plus‚Äù ‚Äî familiar, lightweight, but with just enough features to make small/medium coding tasks more pleasant.</p><p>I‚Äôm curious:</p><ul><li>Would people here find this genuinely useful?</li><li>Do fenced corporate environments still rely on IDLE as the only safe option?</li><li>Is it worth polishing into a small open-source project (maybe even proposing as an official IDLE enhancement)?</li></ul><p>What do you think ‚Äî niche toy, or something that could actually see adoption?</p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 06 Sep 2025 09:41:59 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n9ov57/simple_python_expression_that_does_complex_things/</link><title>Simple Python expression that does complex things?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n9ov57/simple_python_expression_that_does_complex_things/</guid><comments>https://www.reddit.com/r/Python/comments/1n9ov57/simple_python_expression_that_does_complex_things/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n9ov57/simple_python_expression_that_does_complex_things/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>First time I saw <code>a[::-1]</code> to invert the list <code>a</code>, I was blown away. </p><p><code>a, b = b, a</code> which swaps two variables (without temp variables in between) is also quite elegant. </p><p>What&#39;s your favorite example?</p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 06 Sep 2025 08:37:42 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n9kste/python_type_system_and_tooling_survey_2025_from/</link><title>Python Type System and Tooling Survey 2025 (From Meta &amp;amp; JetBrains)</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n9kste/python_type_system_and_tooling_survey_2025_from/</guid><comments>https://www.reddit.com/r/Python/comments/1n9kste/python_type_system_and_tooling_survey_2025_from/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n9kste/python_type_system_and_tooling_survey_2025_from/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>As mentioned in the title, this survey was developed by Meta &amp; Jetbrains w/ community input to collect opinions around Python&#39;s type system and type-related tooling.</p><blockquote><p>The goal of this survey is to gain insights into the tools and practices you use (if any!), the challenges you face, and how you stay updated on new features. Your responses will help the Python typing community identify common blockers, improve resources, and enhance the overall experience of using Python&#39;s type system. Even if you have never actively used type hints in your code, your thoughts are still valuable and we want to hear from you.</p></blockquote><p>Take the survey <a href="https://docs.google.com/forms/d/e/1FAIpQLSeOFkLutxMLqsU6GPe60OJFYVN699vqjXPtuvUoxbz108eDWQ/viewform">here</a>.</p><p>Original LinkedIn posts (so you know it&#39;s legit):</p><p><a href="https://www.linkedin.com/posts/meta-open-source_python-type-system-and-tooling-survey-2025-activity-7369400929546092548-A0hh?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAB9aSUsBqmxSbrhoW2URuDnxCgS5eVD1AS0">Meta Open Source</a></p><p><a href="https://www.linkedin.com/posts/thepsf_python-type-system-and-tooling-survey-2025-activity-7368968760252059648-ICjo?utm_source=social_share_send&amp;utm_medium=member_desktop_web&amp;rcm=ACoAAB9aSUsBqmxSbrhoW2URuDnxCgS5eVD1AS0">Python Software Foundation</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 06 Sep 2025 05:16:17 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n95jwd/aws_for_python_devs_made_simple/</link><title>AWS for Python devs - made simple</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n95jwd/aws_for_python_devs_made_simple/</guid><comments>https://www.reddit.com/r/Python/comments/1n95jwd/aws_for_python_devs_made_simple/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n95jwd/aws_for_python_devs_made_simple/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>What is Stelvio?</strong><br/>Stelvio is a Python framework for managing and deploying AWS infrastructure. Instead of writing YAML, JSON, or HCL, you define your infrastructure in <strong>pure Python</strong>. The framework provides <strong>smart defaults</strong> for networking, IAM, and security so you can focus on your application logic rather than boilerplate setup.</p><p>With the <code>stlv</code> CLI, you can go from zero to a working AWS environment in seconds, without heavy configuration.</p><p><strong>What My Project Does</strong><br/>Stelvio lets Python developers:</p><ul><li>Spin up AWS resources (e.g. compute, storage, networking) using Python code.</li><li>Deploy isolated environments (personal or team-based) with a single command.</li><li>Skip most of the manual setup thanks to opinionated defaults for IAM roles, VPCs, and security groups.</li></ul><p>The goal is to make cloud deployments <strong>approachable to Python developers who aren‚Äôt infrastructure experts</strong>.</p><p><strong>Target Audience</strong></p><ul><li><strong>Python developers</strong> who want to deploy applications to AWS without learning all of Terraform or CloudFormation.</li><li><strong>Small teams and projects</strong> that need quick, reproducible environments.</li><li>It‚Äôs designed for <strong>real-world usage</strong>, not just as a toy project, but it‚Äôs still early-stage and evolving rapidly.</li></ul><p><strong>Comparison to Alternatives</strong></p><ul><li>Compared to <strong>Terraform</strong>: Stelvio is Python-native, so you don‚Äôt need to learn HCL or use external templating.</li><li>Compared to <strong>AWS CDK</strong>: Stelvio emphasizes <strong>zero setup</strong> and <strong>smart defaults</strong>. CDK is very flexible but requires more boilerplate and AWS-specific expertise.</li><li>Compared to <strong>Pulumi</strong>: Stelvio is lighter-weight and focuses narrowly on AWS, aiming to reduce complexity rather than cover all clouds.</li></ul><p><strong>Links</strong></p><ul><li>GitHub: <a href="https://github.com/michal-stlv/stelvio?utm_source=chatgpt.com">https://github.com/michal-stlv/stelvio</a></li><li>Website: <a href="https://stelvio.dev?utm_source=chatgpt.com">https://stelvio.dev</a></li></ul></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 05 Sep 2025 19:09:25 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n9267v/i_built_a_visual_component_library_for/</link><title>I built a visual component library for instrumentation</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n9267v/i_built_a_visual_component_library_for/</guid><comments>https://www.reddit.com/r/Python/comments/1n9267v/i_built_a_visual_component_library_for/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n9267v/i_built_a_visual_component_library_for/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hello everyone,</p><p>as Python is growing more and more in industrial field, I decided to create visual component library for instrumentation.</p><p><strong>What My Project Does:</strong><br/>A Python library with <strong>40+ visual and non-visual components</strong> for building industrial and lab GUIs. Includes analog instruments, sliders, switches, buttons, graphs, and oscilloscope &amp; logic analyzer widgets (PyVISA-compatible). Components are <strong>highly customizable</strong> and designed with a <strong>retro industrial look</strong>.</p><p><strong>Target Audience:</strong><br/>Engineers, scientists, and hobbyists building technical or industrial GUIs. Suitable for both <strong>prototypes and production-ready applications</strong>.</p><p><strong>Comparison / How It‚Äôs Different:</strong><br/>Unlike general GUI frameworks, this library is <strong>instrumentation-focused</strong> with ready-made industrial-style meters, gauges, and analyzer components‚Äîsaving development time and providing a consistent professional look.</p><p><strong>Demo:</strong> <a href="https://imgur.com/a/0j89hPf?utm_source=chatgpt.com">Imgur</a> (Not all components are being shown, just a small sneek-peak)<br/><strong>GitHub Repo:</strong> <a href="https://github.com/tino-posedi/Thales?utm_source=chatgpt.com">Thales</a> (private, still in progress)</p><p><strong>Feedback Questions:</strong></p><ul><li>Are there components you‚Äôd find particularly useful for industrial or lab GUIs?</li><li>Is the retro industrial style appealing, or would you prefer alternative themes?</li><li>Any suggestions for improving customization, usability, or performance?</li></ul></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 05 Sep 2025 16:31:47 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n91acl/showcase_i_cocreated_dlt_an_opensource_python/</link><title>Showcase: I co-created dlt, an open-source Python library that lets you build data pipelines in minu</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n91acl/showcase_i_cocreated_dlt_an_opensource_python/</guid><comments>https://www.reddit.com/r/Python/comments/1n91acl/showcase_i_cocreated_dlt_an_opensource_python/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n91acl/showcase_i_cocreated_dlt_an_opensource_python/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>As a 10y+ data engineering professional, I got tired of the boilerplate and complexity required to load data from messy APIs and files into structured destinations. So, with a team, I built <code>dlt</code> to make data loading ridiculously simple for anyone who knows Python.</p><p><strong>Features:</strong></p><ul><li>‚û°Ô∏è <strong>Load anything with Schema Evolution:</strong> Easily pull data from any API, database, or file (JSON, CSV, etc.) and load it into destinations like DuckDB, BigQuery, Snowflake, and more, handling types and nested data flawlessly.</li><li>‚û°Ô∏è <strong>No more schema headaches:</strong> <code>dlt</code> automatically creates and maintains your database tables. If your source data changes, the schema adapts on its own.</li><li>‚û°Ô∏è <strong>Just write Python:</strong> No YAML, no complex configurations. If you can write a Python function, you can build a production-ready data pipeline.</li><li>‚û°Ô∏è <strong>Scales with you:</strong> Start with a simple script and scale up to handle millions of records without changing your code. It&#39;s built for both quick experiments and robust production workflows.</li><li>‚û°Ô∏è <strong>Incremental loading solved:</strong> Easily keep your destination in sync with your source by loading only new data, without the complex state management.</li><li>‚û°Ô∏è <strong>Easily extendible:</strong> <code>dlt</code> is built to be modular. You can add new sources, customize data transformations, and deploy anywhere.</li></ul><p><strong>Link to repo:</strong><a href="https://github.com/dlt-hub/dlt">https://github.com/dlt-hub/dlt</a></p><p>Let us know what you think! We&#39;re always looking for feedback and contributors.</p><h1>What My Project Does</h1><p><code>dlt</code> is an open-source Python library that simplifies the creation of robust and scalable data pipelines. It automates the most painful parts of Extract, Transform, Load (ETL) processes, particularly schema inference and evolution. Users can write simple Python scripts to extract data from various sources, and <code>dlt</code> handles the complex work of normalizing that data and loading it efficiently into a structured destination, ensuring the target schema always matches the source data.</p><h1>Target Audience</h1><p>The tool is for <strong>data scientists, analysts, and Python developers</strong> who need to move data for analysis, machine learning, or operational dashboards but don&#39;t want to become full-time data engineers. It&#39;s perfect for anyone who wants to build production-ready, maintainable data pipelines without the steep learning curve of heavyweight orchestration tools like Airflow or writing extensive custom code. It‚Äôs suitable for everything from personal projects to enterprise-level deployments.</p><h1>Comparison (how it differs from existing alternatives)</h1><p>Unlike complex frameworks such as <strong>Airflow</strong> or <strong>Dagster</strong>, which are primarily orchestrators that require significant setup, <code>dlt</code> is a lightweight library focused purely on the &quot;load&quot; part of the data pipeline. Compared to writing <strong>custom Python scripts</strong> using libraries like <code>SQLAlchemy</code> and <code>pandas</code>, <code>dlt</code> abstracts away tedious tasks like schema management, data normalization, and incremental loading logic. This allows developers to create declarative and resilient pipelines with far less code, reducing development time and maintenance overhead.</p></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 05 Sep 2025 15:41:57 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n8jasr/im_building_local_opensource_fast_minimal_and/</link><title>I'm building local, open-source, fast minimal, and extendible python RAG library and CLI tool</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n8jasr/im_building_local_opensource_fast_minimal_and/</guid><comments>https://www.reddit.com/r/Python/comments/1n8jasr/im_building_local_opensource_fast_minimal_and/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n8jasr/im_building_local_opensource_fast_minimal_and/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I got tired of overengineered and bloated AI libraries and needed something to prototype local RAG apps quickly so I decided to make my own library,<br/>Features:<br/>‚û°Ô∏è Get to prototyping local RAG applications in seconds: uvx rocketrag prepare &amp; uv rocketrag ask is all you need<br/>‚û°Ô∏è CLI first interface, you can even visualize embeddings in your terminal<br/>‚û°Ô∏è Native llama.cpp bindings - no Ollama bullshit<br/>‚û°Ô∏è Ready to use minimalistic web app with chat, vectors visualization and browsing documents‚û°Ô∏è Minimal footprint: milvus-lite, llama.cpp, kreuzberg, simple html web app<br/>‚û°Ô∏è Tiny but powerful - use any chucking method from chonkie, any LLM with .gguf provided and any embedding model from sentence-transformers<br/>‚û°Ô∏è Easily extendible - implement your own document loaders, chunkers and BDs, contributions welcome!<br/>Link to repo: <a href="https://github.com/TheLion-ai/RocketRAG">https://github.com/TheLion-ai/RocketRAG</a><br/>Let me know what you think. If anybody wants to collaborate and contribute DM me or just open a PR!  </p><p><strong>What My Project Does</strong><br/>RocketRAG is a high-performance Retrieval-Augmented Generation (RAG) library that loads documents (PDF/TXT/MD‚Ä¶), performs semantic chunking, indexes embeddings into a fast vector DB, then serves answers via a local LLM. It provides both a CLI and a FastAPI-based web server with OpenAI-compatible <code>/ask</code> and streaming endpoints, and is built to prioritize speed, a minimal code footprint, and easy extensibility</p><p><strong>Target Audience</strong><br/>Developers and researchers who want a fast, modular RAG stack for local or self-hosted inference (GGUF / llama-cpp-python), and teams who value low-latency document processing and a plug-and-play architecture. It‚Äôs suitable both for experimentation and for production-ready local/offline deployments where performance and customizability matter. </p><p><strong>Comparison (how it differs from existing alternatives)</strong><br/>Unlike heavier, opinionated frameworks, RocketRAG focuses on performance-first building blocks: ultra-fast document loaders (Kreuzberg), semantic chunking (Chonkie/model2vec), Sentence-Transformers embeddings, Milvus Lite for sub-millisecond search, and llama-cpp-python for GGUF inference ‚Äî all in a pluggable architecture with a small footprint. The goal is lower latency and easier swapping of components compared to larger ecosystems, while still offering a nice CLI </p></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 05 Sep 2025 00:43:21 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n8f0xu/pycon_2025_workshop_agentic_apps_with_pydanticai/</link><title>PyCon 2025 Workshop: Agentic Apps with Pydantic-AI</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n8f0xu/pycon_2025_workshop_agentic_apps_with_pydanticai/</guid><comments>https://www.reddit.com/r/Python/comments/1n8f0xu/pycon_2025_workshop_agentic_apps_with_pydanticai/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n8f0xu/pycon_2025_workshop_agentic_apps_with_pydanticai/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>Hey all!</strong></p><p>I recently gave a workshop talk at <strong>PyCon Greece 2025</strong> about building production-ready agent systems.<br/>To check it out, I put together a demo repo (slides coming soon on my blog: <a href="https://www.petrostechchronicles.com/?utm_source=chatgpt.com">petrostechchronicles.com</a>):</p><p>Repo: <a href="https://github.com/Aherontas/Pycon_Greece_2025_Presentation_Agents?utm_source=chatgpt.com">github.com/Aherontas/Pycon_Greece_2025_Presentation_Agents</a></p><p><strong>The idea</strong>: show how multiple AI agents can collaborate using <strong>FastAPI + Pydantic-AI</strong>, with protocols like <strong>MCP (Model Context Protocol)</strong> and <strong>A2A (Agent-to-Agent)</strong> for safe communication and orchestration.</p><p><strong>Features:</strong></p><ul><li>Multiple agents running in containers</li><li>MCP servers (Brave search, GitHub, filesystem, etc.) as tools</li><li>A2A communication between services</li><li>Minimal UI for experimentation (e.g., repo analysis)</li></ul><p><strong>Why I built this</strong>:<br/>Most agent frameworks look great in isolated demos, but fall apart when you try to glue agents together into a real application.<br/>My goal was to help people experiment with these patterns and move closer to real-world use cases.</p><p>It‚Äôs not production-grade, but I‚Äôd love <strong>feedback, criticism, or war stories</strong> from anyone who‚Äôs tried building multi-agent systems.</p><p><strong>Big question for discussion:</strong><br/>Do you think agent-to-agent protocols like MCP/A2A will stick?<br/>Or will the future be mostly single powerful LLMs with plugin stacks?</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 22:01:51 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n8d6pi/productiongrade_python_logging_made_easier_with/</link><title>Production-Grade Python Logging Made Easier with Loguru</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n8d6pi/productiongrade_python_logging_made_easier_with/</guid><comments>https://www.reddit.com/r/Python/comments/1n8d6pi/productiongrade_python_logging_made_easier_with/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n8d6pi/productiongrade_python_logging_made_easier_with/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>While Python&#39;s standard logging module is powerful, navigating its system of handlers, formatters, and filters can often feel like more work than it should be.</p><p><a href="https://www.dash0.com/guides/python-logging-with-loguru">I wrote a guide</a> on how to achieve the same (and better) results with a fraction of the complexity using Loguru. It‚Äôs approachable, can intercept logs from the standard library, and exposes its other great features in a much cleaner API.</p><p>Looking forward to hearing what you think!</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 20:53:33 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n87g91/rant_use_that_second_expression_in_assert/</link><title>Rant: use that second expression in `assert`!</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n87g91/rant_use_that_second_expression_in_assert/</guid><comments>https://www.reddit.com/r/Python/comments/1n87g91/rant_use_that_second_expression_in_assert/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n87g91/rant_use_that_second_expression_in_assert/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>The <code>assert</code> statement is wildly useful for developing and maintaining software. I sprinkle <code>assert</code>s liberally in my code at the beginning to make sure what I think is true, is actually true, and this practice catches a vast number of idiotic errors; and I keep at least some of them in production.</p><p>But often I am in a position where someone else&#39;s assert triggers, and I see in a log something like <code>assert foo.bar().baz() != 0</code> has triggered, and I have no information at all.</p><p>Use that second expression in <code>assert</code>! </p><p>It can be anything you like, even some calculation, and it doesn&#39;t get called unless the assertion fails, so it costs nothing if it never fires. When someone has to find out why your assertion triggered, it will make everyone&#39;s life easier if the assertion explains what&#39;s going on.</p><p>I often use</p><pre><code>assert some_condition(), locals()</code></pre><p>which prints every local variable if the assertion fails. (<code>locals()</code> might be impossibly huge though, if it contains some massive variable, you don&#39;t want to generate some terabyte log, so be a little careful...)</p><p>And remember that <code>assert</code> is a statement, not an expression. That is why this <code>assert</code> will never trigger:</p><pre><code>assert (   condition,   &quot;Long Message&quot;)</code></pre><p>because it asserts that the expression <code>(condition, &quot;Message&quot;)</code> is truthy, which it always is, because it is a two-element tuple.</p><p>Luckily I read an article about this long before I actually did it. I see it every year or two in someone&#39;s production code still.</p><p>Instead, use </p><pre><code>assert condition, (    &quot;Long Message&quot;)</code></pre></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 16:53:00 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n86hnz/i_made_a_script_that_identifies_graded_pokemon/</link><title>I made a script that identifies graded Pokemon cards with OCR</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n86hnz/i_made_a_script_that_identifies_graded_pokemon/</guid><comments>https://www.reddit.com/r/Python/comments/1n86hnz/i_made_a_script_that_identifies_graded_pokemon/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n86hnz/i_made_a_script_that_identifies_graded_pokemon/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hi everyone,</p><p>I run a <a href="https://www.jimmysdealfinder.com">Pokemon deal finder</a> site that finds deals on Pokemon cards on eBay by comparing listing prices to historical card values.</p><p>I used to have graded cards on there, but I had to remove them from the site because too many people would lie in the title about what grade it is. For example, they might put &quot;PSA 10&quot; when it&#39;s only a PSA 9 or they might put &quot;Easily a PSA 10&quot; or &quot;Potential PSA 10&quot; when the card was ungraded. There were enough cards like this that I had to remove graded cards from the site because there were too many misleading graded listings.</p><p>I decided to try to use OCR on the card images to identify the grade rather than trusting what the user says in the title. I managed to write a surprisingly accurate script for identifying the grade of PSA 9 and PSA 10 cards.</p><p>It uses the cv2 and easyocr libraries, and it searches for sections that look purely black and white in the image (likely to be text), then it scans that section for the words &quot;MINT&quot; (grade 9) or &quot;GEM MT&quot; (grade 10) to determine the grade of the card.</p><p>It works surprisingly well, and the best thing is there are no false positives.</p><p>Now I&#39;ve got graded cards back on my site, and they all seem to be identified correctly.</p><p><strong>What My Project Does</strong></p><p>Takes an image of a Pokemon card, and determiners whether it&#39;s a grade 9 or 10 or ungraded.</p><p><strong>Target Audience</strong></p><p>This is mainly for myself as a tool to add graded cards back to my site. Though it could be useful for anyone who needs to identify a graded card from an image.</p><p><strong>Comparison</strong></p><p>When I was first writing this, I did search on Google to see if anyone had done OCR recognition on graded Pokemon cards, but I didn&#39;t really find anything. I think this is unique in that regard.</p><p>You can run it with get_grade_ocr() on either a filename or a URL.</p><p>Github: <a href="https://github.com/sgriffin53/pokemon_ocr">https://github.com/sgriffin53/pokemon_ocr</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 15:59:31 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n85285/typewriter_sound_program/</link><title>Typewriter sound program</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n85285/typewriter_sound_program/</guid><comments>https://www.reddit.com/r/Python/comments/1n85285/typewriter_sound_program/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n85285/typewriter_sound_program/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I love the sound of a typewriter. I like the mechanical sound but I don&#39;t like typing on mechanical keyboards. How would one go about writing a program that imitates the typewriter sound as I&#39;m typing?</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 14:32:18 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n84top/showcase_ecma426_source_maps_in_pure_python/</link><title>Showcase: ecma426: Source Maps in Pure Python</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n84top/showcase_ecma426_source_maps_in_pure_python/</guid><comments>https://www.reddit.com/r/Python/comments/1n84top/showcase_ecma426_source_maps_in_pure_python/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n84top/showcase_ecma426_source_maps_in_pure_python/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><h3>What My Project Does</h3><p><strong>ecma426</strong> is a pure-Python implementation of <a href="https://tc39.es/source-map/">ECMA-426: Source Maps</a>. It decodes and encodes sourcemaps, including index maps with <code>sections</code>, and aims to stay close to the specification.</p><h3>Target Audience</h3><p>Anyone working with JavaScript toolchains from Python. For example, build systems, bundlers, error trackers, or debugging tools that need to parse or emit sourcemaps. It‚Äôs intended for production use, not just experimentation.</p><h3>Comparison</h3><p>Most Python sourcemap libraries are either unmaintained or only handle decoding. <strong>ecma426</strong> covers both directions (decode and encode) and supports <code>sections</code> as defined in the spec, while staying dependency-free.</p><h3>Usage</h3><p>```pythonimport ecma426, json</p><p>smap = ecma426.loads(json.load(open(&quot;app.min.js.map&quot;)))</p><h1>strict lookup (exact match only, raises KeyError if absent)</h1><p>m = smap[(10, 42)]</p><h1>nearest-left lookup (devtools convention)</h1><p>m = smap.lookup_left(10, 42)</p><h1>map back into the original text</h1><p>line = smap.raw[&quot;sourcesContent&quot;][0].splitlines()[m.original_line]print(line)print(&quot; &quot; * m.original_column + &quot;^ here&quot;)```</p><h3>Source</h3><p><a href="https://github.com/bugsink/ecma426">https://github.com/bugsink/ecma426</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 14:16:38 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n84hjt/pyconfr_at_lyon_france/</link><title>PyconFR at Lyon (France)</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n84hjt/pyconfr_at_lyon_france/</guid><comments>https://www.reddit.com/r/Python/comments/1n84hjt/pyconfr_at_lyon_france/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n84hjt/pyconfr_at_lyon_france/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>The French-Speaking Python Association (AFPy) is organizing PyConFR 2025 from Thursday, October 30 to Sunday, November 2. For this 16th edition, we‚Äôll be hosted by the Ren√© Cassin Campus in Lyon!</p><p>PyConFR is a free, four-day event centered around the Python programming language. It includes two days of collaborative development (sprints), followed by two days of talks and workshops.</p><p>The call for proposals is now closed, and we‚Äôll be publishing the schedule soon at <a href="https://www.pycon.fr/2025/en/schedule.html">https://www.pycon.fr/2025/en/schedule.html</a>. There will be an English-language track.</p><p>While attendance is free, registration is required for all participants.</p><p>As every year, we offer support to people who are usually underrepresented at conferences ‚Äî help with finding a topic, writing a proposal, preparing slides, and rehearsing. Feel free to contact us at [<a href="mailto:diversite@afpy.org">diversite@afpy.org</a>]()</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 13:54:02 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n7sr1x/why_does_processpoolexecutor_mark_some_tasks_as/</link><title>Why does ProcessPoolExecutor mark some tasks as "running" even though all workers are busy?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n7sr1x/why_does_processpoolexecutor_mark_some_tasks_as/</guid><comments>https://www.reddit.com/r/Python/comments/1n7sr1x/why_does_processpoolexecutor_mark_some_tasks_as/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n7sr1x/why_does_processpoolexecutor_mark_some_tasks_as/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I‚Äôm using Python‚Äôs <code>ProcessPoolExecutor</code> to run a bunch of tasks. Something I noticed is that some tasks are marked as <em>running</em> even though all the workers are already working on other tasks.</p><p>From my understanding, a task should only switch from <em>pending</em> to <em>running</em> once a worker actually starts executing it. But in my case, it seems like the executor marks extra tasks as running before they‚Äôre really picked up.</p><p>Is this normal behavior of <code>ProcessPoolExecutor</code>? Or am I missing something about how it manages its internal task queue?</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 03:46:26 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n7r4xb/niche_python_tools_libraries_and_features_whats/</link><title>Niche Python tools, libraries and features - whats your favourite?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n7r4xb/niche_python_tools_libraries_and_features_whats/</guid><comments>https://www.reddit.com/r/Python/comments/1n7r4xb/niche_python_tools_libraries_and_features_whats/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n7r4xb/niche_python_tools_libraries_and_features_whats/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I know we see this get asked every other week, but it always makes for a good discussion.</p><p>I only just found out about <code>pathlib</code> - makes working with files so much cleaner.</p><p>Whats a python tool or library you wish youd known about earlier?</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 02:41:38 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n7pe37/removing_a_dependency_major_minor_or_patch_bump/</link><title>Removing a dependency - Major, Minor or Patch bump?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n7pe37/removing_a_dependency_major_minor_or_patch_bump/</guid><comments>https://www.reddit.com/r/Python/comments/1n7pe37/removing_a_dependency_major_minor_or_patch_bump/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n7pe37/removing_a_dependency_major_minor_or_patch_bump/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I&#39;ve been collaborating on an <a href="https://github.com/jcfitzpatrick12/spectre/issues/167">issue</a> for <a href="https://github.com/jcfitzpatrick12/spectre"><em>Spectre</em></a>, a Python program for recording radio spectrograms with software-defined radios. The motivation for the issue was to remove <a href="https://scipy.org/">Scipy</a> as dependency from a Python package used by the program called <a href="https://github.com/jcfitzpatrick12/spectre-core">spectre-core</a>.</p><p>The <a href="https://github.com/jcfitzpatrick12/spectre-core/pull/52">PR</a> introduced no changes from the perspective of the public API of the package. It just reimplemented the same functionality for our particular use case. However, we removed Scipy as a dependency since it was no longer required. Under <a href="https://semver.org/">semantic versioning</a>, would this constitute a major, minor or patch bump?</p><p>I considered making this a major bump, since any consumer of the package relying on Scipy being a transitive dependency would see a breaking change. But since the Scipy functionality wasn&#39;t exposed publically, I didn&#39;t think this argument was strong enough and so opted for a minor bump. What would you do?</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 01:35:24 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n7e1oa/zuban_is_now_open_source/</link><title>Zuban is now Open Source</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n7e1oa/zuban_is_now_open_source/</guid><comments>https://www.reddit.com/r/Python/comments/1n7e1oa/zuban_is_now_open_source/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n7e1oa/zuban_is_now_open_source/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Zuban, the successor of Jedi is now Open Source: <a href="https://github.com/zubanls/zuban">https://github.com/zubanls/zuban</a></p><p>Zuban is a high-performance Python Language Server and type checker implemented in Rust, by the author of Jedi. Zuban is 20‚Äì200√ó faster than Mypy, while using roughly half the memory and CPU compared to Ty and Pyrefly. It offers both a PyRight-like mode and a Mypy-compatible mode, which behaves just like Mypy; supporting the same config files, command-line flags, and error messages.</p><p>Most important LSP features are supported. Features include diagnostics, completions, goto, references, rename, hover and document highlights.</p><p>Zuban passes over 95% of Mypy‚Äôs relevant test suite and offers comprehensive support for Python&#39;s <a href="https://htmlpreview.github.io/?https://github.com/python/typing/blob/main/conformance/results/results.html">type system</a>.</p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 03 Sep 2025 18:25:41 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n75r76/contribution_of_python_to_the_world_is_underrated/</link><title>contribution of python to the world is underrated‚Ä¶</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n75r76/contribution_of_python_to_the_world_is_underrated/</guid><comments>https://www.reddit.com/r/Python/comments/1n75r76/contribution_of_python_to_the_world_is_underrated/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n75r76/contribution_of_python_to_the_world_is_underrated/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>found this on youtube scrolling,¬†<a href="https://youtu.be/DRU-0tHOayc">https://youtu.be/DRU-0tHOayc</a></p><p>found it good at explaining how we got here‚Ä¶from first neuron‚Äôs birth to chatGPT, then the thought just struck me, none of it would have been possible without python‚Ä¶much of the world, still not aware about the contribution. Python has done so much in making lives of humans better in every possible way‚Ä¶</p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 03 Sep 2025 10:19:03 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n6xw8z/meet_thoad_high_order_derivatives_for_pytorch/</link><title>Meet THOAD, High Order Derivatives for PyTorch Graphs</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n6xw8z/meet_thoad_high_order_derivatives_for_pytorch/</guid><comments>https://www.reddit.com/r/Python/comments/1n6xw8z/meet_thoad_high_order_derivatives_for_pytorch/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 9 min | <a href='https://www.reddit.com/r/Python/comments/1n6xw8z/meet_thoad_high_order_derivatives_for_pytorch/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I‚Äôm excited to share <strong>thoad</strong> (short for Py<strong>T</strong>orch <strong>H</strong>igh <strong>O</strong>rder <strong>A</strong>utomatic <strong>D</strong>ifferentiation), a Python only library that computes arbitrary order partial derivatives directly on a PyTorch computational graph. The package has been developed within a research project at Universidad Pontificia de Comillas (ICAI), and we are considering publishing an academic article in the future that reviews the mathematical details and the implementation design.</p><p>At its core, thoad takes a one output to many inputs view of the graph and pushes high order derivatives back to the leaf tensors. Although a 1‚ÜíN problem can be rewritten as 1‚Üí1 by concatenating flattened inputs, as in functional approaches such as <code>jax.jet</code> or <code>functorch</code>, thoad‚Äôs graph aware formulation enables an optimization based on <strong>unifying independent dimensions</strong> (especially batch). This delivers <strong>asymptotically better scaling</strong> with respect to batch size. Additionally, we compute derivatives <strong>vectorially</strong> rather than component by component, which is what makes a pure PyTorch implementation practical without resorting to custom C++ or CUDA.</p><p>The package is <strong>easy to maintain</strong>, because it is written entirely in Python and uses <strong>PyTorch</strong> as its only dependency. The implementation stays at a high level and leans on PyTorch‚Äôs vectorized operations, which means no custom C++ or CUDA bindings, no build systems to manage, and fewer platform specific issues.</p><p>The package can be installed from <strong>GitHub</strong> or <strong>PyPI</strong>:</p><ul><li>GitHub: <a href="https://github.com/mntsx/thoad">https://github.com/mntsx/thoad</a></li><li>PyPI: <a href="https://pypi.org/project/thoad/">https://pypi.org/project/thoad/</a></li></ul><p>In our benchmarks, <strong>thoad outperforms</strong> <code>torch.autograd</code> <strong>for Hessian calculations even on CPU</strong>. See the notebook that reproduces the comparison: <a href="https://github.com/mntsx/thoad/blob/master/examples/benchmarks/benchmark%5C_vs%5C_torch%5C_autograd.ipynb">https://github.com/mntsx/thoad/blob/master/examples/benchmarks/benchmark\_vs\_torch\_autograd.ipynb</a>.</p><p>The user experience has been one of our main concerns during development. <strong>thoad</strong> is designed to align closely with PyTorch‚Äôs interface philosophy, so running the high order backward pass is practically indistinguishable from calling PyTorch‚Äôs own <code>backward</code>. When you need finer control, you can keep or reduce Schwarz symmetries, group variables to restrict mixed partials, and fetch the exact mixed derivative you need. Shapes and independence metadata are also exposed to keep interpretation straightforward.</p><h1>USING THE PACKAGE</h1><p><strong>thoad</strong> exposes two primary interfaces for computing high-order derivatives:</p><ol><li><code>thoad.backward</code>: a function-based interface that closely resembles <code>torch.Tensor.backward</code>. It provides a quick way to compute high-order gradients without needing to manage an explicit controller object, but it offers only the core functionality (derivative computation and storage).</li><li><code>thoad.Controller</code>: a class-based interface that wraps the output tensor‚Äôs subgraph in a controller object. In addition to performing the same high-order backward pass, it gives access to advanced features such as fetching specific mixed partials, inspecting batch-dimension optimizations, overriding backward-function implementations, retaining intermediate partials, and registering custom hooks.</li></ol><p><strong>thoad.backward</strong></p><p>The <code>thoad.backward</code> function computes high-order partial derivatives of a given output tensor and stores them in each leaf tensor‚Äôs <code>.hgrad</code> attribute.</p><p><strong>Arguments</strong>:</p><ul><li><code>tensor</code>: A PyTorch tensor from which to start the backward pass. This tensor must require gradients and be part of a differentiable graph.</li><li><code>order</code>: A positive integer specifying the maximum order of derivatives to compute.</li><li><code>gradient</code>: A tensor with the same shape as <code>tensor</code> to seed the vector-Jacobian product (i.e., custom upstream gradient). If omitted, the default is used.</li><li><code>crossings</code>: A boolean flag (default=<code>False</code>). If set to <code>True</code>, mixed partial derivatives (i.e., derivatives that involve more than one distinct leaf tensor) will be computed.</li><li><code>groups</code>: An iterable of disjoint groups of leaf tensors. When <code>crossings=False</code>, only those mixed partials whose participating leaf tensors all lie within a single group will be calculated. If <code>crossings=True</code> and <code>groups</code> is provided, a <em>ValueError</em> will be raised (they are mutually exclusive).</li><li><code>keep_batch</code>: A boolean flag (default=<code>False</code>) that controls how output dimensions are organized in the computed gradients.<ul><li><strong>When</strong> <code>keep_batch=False</code>**:** Gradients are returned in a fully flattened form. Concretely, think of the gradient tensor as having:<ul><li>A single ‚Äúoutput‚Äù axis that lists every element of the original output tensor (flattened into one dimension).</li><li>One axis per derivative order, each listing every element of the corresponding input (also flattened).</li></ul></li><li>For an N-th order derivative of a leaf tensor with <code>input_numel</code> elements and an output with <code>output_numel</code> elements, the gradient shape is:<ul><li><strong>Axis 1:</strong> indexes all <code>output_numel</code> outputs</li><li><strong>Axes 2‚Ä¶(N+1):</strong> each indexes all <code>input_numel</code> inputs</li></ul></li><li><strong>When</strong> <code>keep_batch=True</code>**:** Gradients preserve both a flattened ‚Äúoutput‚Äù axis and each original output dimension before any input axes. You can visualize it as:<ul><li><strong>Axis 1</strong> flattens all elements of the output tensor (size = <code>output_numel</code>).</li><li><strong>Axes 2...(k+1)</strong> correspond to dimensions shared by multiple input tensors and treated independently throughout the graph. These are dimensions that are only operated on element-wise (e.g. batch dimensions).</li><li><strong>Axes (k+2)...(k+N+1)</strong> each flatten all <code>input_numel</code> elements of the leaf tensor, one axis per derivative order.</li></ul></li></ul></li><li><code>keep_schwarz</code>: A boolean flag (default=<code>False</code>). If <code>True</code>, symmetric (Schwarz) permutations are retained explicitly instead of being canonicalized/reduced‚Äîuseful for debugging or inspecting non-reduced layouts.</li></ul><p><strong>Returns</strong>:</p><ul><li>An instance of <code>thoad.Controller</code> wrapping the same tensor and graph</li></ul><p>Executing the automatic differentiation via <code>thoad.backprop</code> looks like this.</p><pre><code>import torchimport thoadfrom torch.nn import functional as F#### Normal PyTorch workflowX = torch.rand(size=(10,15), requires_grad=True)Y = torch.rand(size=(15,20), requires_grad=True)Z = F.scaled_dot_product_attention(query=X, key=Y.T, value=Y.T)#### Call thoad backwardorder = 2thoad.backward(tensor=Z, order=order)#### Checks## check derivative shapesfor o in range(1, 1 + order):   assert X.hgrad[o - 1].shape == (Z.numel(), *(o * tuple(X.shape)))   assert Y.hgrad[o - 1].shape == (Z.numel(), *(o * tuple(Y.shape)))## check first derivatives (jacobians)fn = lambda x, y: F.scaled_dot_product_attention(x, y.T, y.T)J = torch.autograd.functional.jacobian(fn, (X, Y))assert torch.allclose(J[0].flatten(), X.hgrad[0].flatten(), atol=1e-6)assert torch.allclose(J[1].flatten(), Y.hgrad[0].flatten(), atol=1e-6)## check second derivatives (hessians)fn = lambda x, y: F.scaled_dot_product_attention(x, y.T, y.T).sum()H = torch.autograd.functional.hessian(fn, (X, Y))assert torch.allclose(H[0][0].flatten(), X.hgrad[1].sum(0).flatten(), atol=1e-6)assert torch.allclose(H[1][1].flatten(), Y.hgrad[1].sum(0).flatten(), atol=1e-6)</code></pre><p><strong>Instantiation</strong></p><p>Use the constructor to create a controller for any tensor requiring gradients:</p><pre><code>controller = thoad.Controller(tensor=GO)  ## takes graph output tensor</code></pre><ul><li><code>tensor</code>: A PyTorch <code>Tensor</code> with <code>requires_grad=True</code> and a non-<code>None</code> <code>grad_fn</code>.</li></ul><p><strong>Properties</strong></p><ul><li><code>.tensor ‚Üí Tensor</code> The output tensor underlying this controller. <strong>Setter</strong>: Replaces the tensor (after validation), rebuilds the internal computation graph, and invalidates any previously computed gradients.</li><li><code>.compatible ‚Üí bool</code> Indicates whether every backward function in the tensor‚Äôs subgraph has a supported high-order implementation. If <code>False</code>, some derivatives may fall back or be unavailable.</li><li><code>.index ‚Üí Dict[Type[torch.autograd.Function], Type[ExtendedAutogradFunction]]</code> A mapping from base PyTorch <code>autograd.Function</code> classes to thoad‚Äôs <code>ExtendedAutogradFunction</code> implementations. <strong>Setter</strong>: Validates and injects your custom high-order extensions.</li></ul><p><strong>Core Methods</strong></p><p><strong>.backward(order, gradient=None, crossings=False, groups=None, keep_batch=False, keep_schwarz=False) ‚Üí None</strong></p><p>Performs the high-order backward pass up to the specified derivative <code>order</code>, storing all computed partials in each leaf tensor‚Äôs <code>.hgrad</code> attribute.</p><ul><li><code>order</code> (<code>int &gt; 0</code>): maximum derivative order.</li><li><code>gradient</code> (<code>Optional[Tensor]</code>): custom upstream gradient with the same shape as <code>controller.tensor</code>.</li><li><code>crossings</code> (<code>bool</code>, default <code>False</code>): If <code>True</code>, mixed partial derivatives across different leaf tensors will be computed.</li><li><code>groups</code> (<code>Optional[Iterable[Iterable[Tensor]]]</code>, default <code>None</code>): When <code>crossings=False</code>, restricts mixed partials to those whose leaf tensors all lie within a single group. If <code>crossings=True</code> and <code>groups</code> is provided, a <em>ValueError</em> is raised.</li><li><code>keep_batch</code> (<code>bool</code>, default <code>False</code>): controls whether independent output axes are kept separate (batched) or merged (flattened) in stored/retrieved gradients.</li><li><code>keep_schwarz</code> (<code>bool</code>, default <code>False</code>): if <code>True</code>, retains symmetric permutations explicitly (no Schwarz reduction).</li></ul><p><strong>.display_graph() ‚Üí None</strong></p><p>Prints a tree representation of the tensor‚Äôs backward subgraph. Supported nodes are shown normally; unsupported ones are annotated with <code>(not supported)</code>.</p><p><strong>.register_backward_hook(variables: Sequence[Tensor], hook: Callable) ‚Üí None</strong></p><p>Registers a user-provided <code>hook</code> to run during the backward pass whenever gradients for any of the specified leaf <code>variables</code> are computed.</p><ul><li><code>variables</code> (<code>Sequence[Tensor]</code>): Leaf tensors to monitor.</li><li><code>hook</code> (<code>Callable[[Tuple[Tensor, Tuple[Shape, ...], Tuple[Indep, ...]], dict[AutogradFunction, set[Tensor]]], Tuple[Tensor, Tuple[Shape, ...], Tuple[Indep, ...]]]</code>): Receives the current <code>(Tensor, shapes, indeps)</code> plus contextual info, and must return the modified triple.</li></ul><p><strong>.require_grad_(variables: Sequence[Tensor]) ‚Üí None</strong></p><p>Marks the given leaf <code>variables</code> so that all intermediate partials involving them are retained, even if not required for the final requested gradients. Useful for inspecting or re-using higher-order intermediates.</p><p><strong>.fetch_hgrad(variables: Sequence[Tensor], keep_batch: bool = False, keep_schwarz: bool = False) ‚Üí Tuple[Tensor, Tuple[Tuple[Shape, ...], Tuple[Indep, ...], VPerm]]</strong></p><p>Retrieves the precomputed high-order partial corresponding to the ordered sequence of leaf <code>variables</code>.</p><ul><li><code>variables</code> (<code>Sequence[Tensor]</code>): the leaf tensors whose mixed partial you want.</li><li><code>keep_batch</code> (<code>bool</code>, default <code>False</code>): if <code>True</code>, each independent output axis remains a separate batch dimension in the returned tensor; if <code>False</code>, independent axes are distributed/merged into derivative dimensions.</li><li><code>keep_schwarz</code> (<code>bool</code>, default <code>False</code>): if <code>True</code>, returns derivatives retaining symmetric permutations explicitly.</li></ul><p>Returns a pair:</p><ol><li><strong>Gradient tensor</strong>: the computed partial derivatives, shaped according to output and input dimensions (respecting <code>keep_batch</code>/<code>keep_schwarz</code>).</li><li><strong>Metadata tuple</strong><ul><li><strong>Shapes</strong> (<code>Tuple[Shape, ...]</code>): the original shape of each leaf tensor.</li><li><strong>Indeps</strong> (<code>Tuple[Indep, ...]</code>): for each variable, indicates which output axes remained independent (batch) vs. which were merged into derivative axes.</li><li><strong>VPerm</strong> (<code>Tuple[int, ...]</code>): a permutation that maps the internal derivative layout to the requested <code>variables</code> order.</li></ul></li></ol><p>Use the combination of independent-dimension info and shapes to reshape or interpret the returned gradient tensor in your workflow.</p><pre><code>import torchimport thoadfrom torch.nn import functional as F#### Normal PyTorch workflowX = torch.rand(size=(10,15), requires_grad=True)Y = torch.rand(size=(15,20), requires_grad=True)Z = F.scaled_dot_product_attention(query=X, key=Y.T, value=Y.T)#### Instantiate thoad controller and call backwardorder = 2controller = thoad.Controller(tensor=Z)controller.backward(order=order, crossings=True)#### Fetch Partial Derivatives## fetch X and Y 2nd order derivativespartial_XX, _ = controller.fetch_hgrad(variables=(X, X))partial_YY, _ = controller.fetch_hgrad(variables=(Y, Y))assert torch.allclose(partial_XX, X.hgrad[1])assert torch.allclose(partial_YY, Y.hgrad[1])## fetch cross derivativespartial_XY, _ = controller.fetch_hgrad(variables=(X, Y))partial_YX, _ = controller.fetch_hgrad(variables=(Y, X))</code></pre><blockquote><p>NOTE. A more detailed user guide with examples and feature walkthroughs is available in the notebook: <a href="https://github.com/mntsx/thoad/blob/master/examples/user_guide.ipynb">https://github.com/mntsx/thoad/blob/master/examples/user_guide.ipynb</a></p></blockquote><p>If you give it a try, I would love feedback on the API.</p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 03 Sep 2025 04:07:59 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n6v3tl/pyline_update_terminal_based_text_editor_linux/</link><title>PyLine Update - terminal based text editor (Linux, WSL, MacOS) (New Feats)</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n6v3tl/pyline_update_terminal_based_text_editor_linux/</guid><comments>https://www.reddit.com/r/Python/comments/1n6v3tl/pyline_update_terminal_based_text_editor_linux/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n6v3tl/pyline_update_terminal_based_text_editor_linux/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hello, this is a hobby project I coded entirely in Python 3 , created longer time ago. But came back to it this spring. Now updated with new functionality and better code structure currently at v0.9.7.</p><p>Source at -¬†<a href="https://github.com/Peter-L-SVK/PyLine">PyLine GitHub repo</a>  (you can see screenshots in readme)</p><h1>What My Project Does:</h1><p>It is CLI text editor with:<br/>- function like wc - cw - counts chars, words and lines<br/>- open / create / truncate file<br/>- exec mode that is like file browser and work with directories<br/>- scroll-able text-buffer, currently set to 52 lines<br/>- supports all clipboards for GUI: X11,Wayland, win32yank for WSL and pbpaste for MacOS<br/>- multiple lines selection copy/paste/overwrite and delete<br/>- edit history implemented via LIFO - Last In First Out (limit set to 120)<br/>- highlighting of .py syntax (temporary tho, will find the better way)<br/>- comes with proper install script</p><h1>New features:</h1><p>- Support of args &lt;filename&gt;, -i/--info and -h/--help<br/>- Modular hooks system with priority, runtime enable/disable, cross-language support (Python, Perl, Bash, Ruby, Lua, Node.js, PHP)<br/>- Hook manager UI (list, enable/disable, reload hooks, show info)<br/>- BufferManager, NavigationManager, SelectionManager, PasteBuffer, UndoManager all refactored for composition and extensibility (micro-kernel like architecture)<br/>- Hook-enabled file loading/saving, multi-language event handlers<br/>- Enhanced config and state management (per-user config dir)<br/>- Improved argument parsing and info screens</p><p>It also comes with prepackaged hooks like smart tab indent.</p><p>The editor is using built-in to the terminal foreground/background but I plan to implement themes and config.ini alongside search / replace feature.</p><h1>Target Audience:</h1><p>Basically anyone with Linux, WSL or other Unix-like OS. Nothing complicated to use.</p><p>(I know it&#39;s not too much.. I don&#39;t have any degree in CS or IT engineering or so, just passion)</p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 03 Sep 2025 02:16:35 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n658es/is_it_a_good_idea_to_teach_students_python_but/</link><title>Is it a good idea to teach students Python but using an old version?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n658es/is_it_a_good_idea_to_teach_students_python_but/</guid><comments>https://www.reddit.com/r/Python/comments/1n658es/is_it_a_good_idea_to_teach_students_python_but/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n658es/is_it_a_good_idea_to_teach_students_python_but/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>EDIT: Talking about IDLE here</p><p>Sorry if this is the wrong sub.</p><p>When i went to high school (UK) in 2018, we had 3.4.2 (which at the time wasn&#39;t even the latest 3.4.x). In 2020 they upgraded to 3.7, but just days later downgraded back to 3.4.2. I asked IT manager why and they said its because of older students working on long projects. But doubt that was the reason because fast forward to 2023 the school still had 3.4.2 which was end of life.</p><p>Moved to a college that same year that had 3.12, but this summer 2025, after computer upgrades to windows 11, we are now on 3.10 for some reason. I start a new year in college today so I&#39;ll be sure to ask the teacher.</p><p>Are there any drawbacks to teaching using an old version? It will just be the basics and a project or 2</p></div><!-- SC_ON --></section>]]></description><pubDate>Tue, 02 Sep 2025 05:51:40 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n64bla/i_built_a_simple_opensource_windows_wallpaper/</link><title>I built a simple, open-source Windows wallpaper changer because the built-in one kept failing.</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n64bla/i_built_a_simple_opensource_windows_wallpaper/</guid><comments>https://www.reddit.com/r/Python/comments/1n64bla/i_built_a_simple_opensource_windows_wallpaper/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n64bla/i_built_a_simple_opensource_windows_wallpaper/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><h1>What My Project Does</h1><p>This is a simple, lightweight desktop application for Windows that automatically changes your desktop wallpaper from a folder of images. You can choose a folder, set a custom time interval (in seconds, minutes, or hours), and have your pictures shuffle randomly. It can be minimized to the system tray. The application is built using <code>customtkinter</code> for the GUI and <code>pystray</code> for the system tray functionality.</p><h1>Target Audience</h1><p>I write it for personal use and for anyone who wants a simple and minimalist way to manage their desktop wallpapers. It is a &quot;toy project&quot; in the sense that it started as a solution to a personal frustration, but it is meant to be a tool for everyday use.</p><h1>Comparison</h1><p>I wrote this because the built-in Windows slideshow feature randomly stops working, which is incredibly frustrating and annoying, and they have been too lazy to fix it. Other third-party programs I looked at were often too cluttered with features I didn&#39;t need and/or were also resource-hungry. This application is meant to be a clean, minimal alternative that focuses on its single task.</p><p>You can find it here: <a href="https://github.com/m-sarabi/wallpaper_changer/releases/tag/v1.0.0">Wallpaper Changer</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Tue, 02 Sep 2025 05:08:36 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n5ux0w/python_ocr_automatically_analyze_dota_2_player/</link><title>Python + OCR: Automatically analyze Dota 2 player stats üëÄ</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n5ux0w/python_ocr_automatically_analyze_dota_2_player/</guid><comments>https://www.reddit.com/r/Python/comments/1n5ux0w/python_ocr_automatically_analyze_dota_2_player/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n5ux0w/python_ocr_automatically_analyze_dota_2_player/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><h1>What My Project Does</h1><p>This Python script uses OCR to read Dota 2 friend IDs from your screen, fetches match data from the OpenDota API, and calculates winrates and most played heroes to detect potential smurfs.<br/>It provides a simple GUI that shows overall winrate and the most played hero of the selected player.</p><h1>Target Audience</h1><p>Python enthusiasts, Dota 2 players, or anyone interested in game data analysis and automation.<br/>This is mainly an educational and experimental project, not intended for cheating or modifying the game.</p><h1>Comparison</h1><p>Unlike other Dota 2 analytics tools, this script uses OCR to automatically read friend IDs from the screen, eliminating the need to manually input player IDs.<br/>It combines GUI feedback, Python automation, and API integration in a single lightweight tool.</p><p><a href="https://github.com/N3uvin/opendota2-vision">GitHub Repository</a></p><p><strong><em>I‚Äôm open to feedback, feature suggestions, or any ideas to improve the script!</em></strong></p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 01 Sep 2025 22:55:57 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n5q8n0/introducing_dltype_an_ultrafast_runtime_type_and/</link><title>Introducing DLType, an ultra-fast runtime type and shape checking library for deep learning tensors!</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n5q8n0/introducing_dltype_an_ultrafast_runtime_type_and/</guid><comments>https://www.reddit.com/r/Python/comments/1n5q8n0/introducing_dltype_an_ultrafast_runtime_type_and/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n5q8n0/introducing_dltype_an_ultrafast_runtime_type_and/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><h1>What My Project Does</h1><p>DL (Deep-learning) Typing, a runtime shape and type checker for your pytorch tensors or numpy arrays! No more guessing what the shape or data type of your tensors are for your functions. Document tensor shapes using familiar syntax and take the guesswork out of tensor manipulations.</p><p><code>python@dltyped()def transform_tensors(    points: Annotated[np.ndarray, FloatTensor[&quot;N 3&quot;]]    transform: Annotated[torch.Tensor, IntTensor[&quot;3 3&quot;]]) -&gt; Annotated[torch.Tensor, FloatTensor[&quot;N 3&quot;]]:    return torch.from_numpy(points) @ transform</code></p><h1>Target Audience</h1><p>Machine learning engineers primarily, but anyone who uses numpy may find this useful too! </p><h1>Comparison</h1><ul><li>Jaxtyping-inspired syntax for expressions, literals, and anonymous axes</li><li>Supports any version of pytorch and numpy (Python &gt;=3.10)</li><li>First class Pydantic model support, shape and dtype validation directly in model definitions</li><li>Dataclass, named tuple, function, and method checking </li><li>Lightweight and fast, benchmarked to be on-par with manual shape checking and (at least last time we tested it) was as-fast or faster than the current de-facto solution of Jaxtyping + beartype, in some cases by an order of magnitude.</li><li>Custom tensor types, define your own tensor type and override the check method with whatever custom logic you need</li></ul><p>GitHub Page: <a href="https://github.com/stackav-oss/dltype">https://github.com/stackav-oss/dltype</a></p><p><code>pip install dltype</code></p><p>Check it out and let me know what you think! </p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 01 Sep 2025 20:00:17 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n5jjnl/update_docstrange_structured_data_extraction_from/</link><title>[UPDATE] DocStrange - Structured data extraction from images/pdfs/docs</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n5jjnl/update_docstrange_structured_data_extraction_from/</guid><comments>https://www.reddit.com/r/Python/comments/1n5jjnl/update_docstrange_structured_data_extraction_from/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n5jjnl/update_docstrange_structured_data_extraction_from/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I previously shared the open‚Äësource library DocStrange. Now I have hosted it as a free to use web app to upload pdfs/images/docs to get clean structured data in Markdown/CSV/JSON/Specific-fields and other formats.</p><p><strong>Live Demo:</strong>¬†<a href="https://docstrange.nanonets.com/"><strong>https://docstrange.nanonets.com</strong></a></p><p><strong>Github :</strong> <a href="https://github.com/NanoNets/docstrange"><strong>https://github.com/NanoNets/docstrange</strong></a></p><p>Would love to hear feedbacks!</p><p>Original Post :¬†<a href="https://www.reddit.com/r/Python/comments/1mh914m/open_source_tool_for_structured_data_extraction/">https://www.reddit.com/r/Python/comments/1mh914m/open_source_tool_for_structured_data_extraction/</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 01 Sep 2025 14:19:32 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n5idvx/omnilpr_a_multiinterface_server_for_automatic/</link><title>Omni-LPR: A multi-interface server for automatic license plate recognition in Python</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n5idvx/omnilpr_a_multiinterface_server_for_automatic/</guid><comments>https://www.reddit.com/r/Python/comments/1n5idvx/omnilpr_a_multiinterface_server_for_automatic/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n5idvx/omnilpr_a_multiinterface_server_for_automatic/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>What My Project Does</strong></p><p>Hi everyone,</p><p>I&#39;ve made an open-source server in Python (called Omni-LPR) that exposes automatic license plate recognition (or ALPR) as a toolbox for LLMs and AI agents. It can also be used as a standalone microservice.</p><p>Here are some of its features:</p><ul><li>Installable as a Python package: <code>pip install omni-lpr</code>.</li><li>Self-hostable for 100% local and private inference.</li><li>Exposes tools via a native MCP endpoint for agents and a standard REST API.</li><li>Includes examples for direct integration with tools like LM Studio.</li><li>Hardware-accelerated backends for CPU, OpenVINO, and CUDA for faster performance.</li></ul><p>Project&#39;s GitHub repo: <a href="https://github.com/habedi/omni-lpr">https://github.com/habedi/omni-lpr</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 01 Sep 2025 13:04:17 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n562vq/my_first_kinda_complicated_code_started_like_a/</link><title>My first kinda complicated code (started like a month ago)</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n562vq/my_first_kinda_complicated_code_started_like_a/</guid><comments>https://www.reddit.com/r/Python/comments/1n562vq/my_first_kinda_complicated_code_started_like_a/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n562vq/my_first_kinda_complicated_code_started_like_a/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>WHAT MY PROJECT DOESI have made a card game where you are against a bot, and is trying to be the first to have only one Card left. </p><p>TARGET AUDIENCEThis is just a project I made for fun, but I hope some people who are new to Python, or is interested in small text based games Will like this.</p><p>COMPARISONI haven&#39;t seen any project like this, and I at least hope there aren&#39;t any. I feel this is a unique fun card game.</p><p>GitHub link:<a href="https://github.com/Simonkamon11/One-Card.git">https://github.com/Simonkamon11/One-Card.git</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 01 Sep 2025 02:34:57 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n54kbx/django_vs_fastapi_for_saas_with_heavy/</link><title>Django vs FastAPI for SaaS with heavy transactions + AI integrations?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n54kbx/django_vs_fastapi_for_saas_with_heavy/</guid><comments>https://www.reddit.com/r/Python/comments/1n54kbx/django_vs_fastapi_for_saas_with_heavy/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n54kbx/django_vs_fastapi_for_saas_with_heavy/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I‚Äôm building a SaaS that processes lots of transactions, handles AI-driven communications, and integrates with multiple external APIs.</p><p>Would you start with Django for quick ramp up or FastAPI for long-term flexibility? Is Django feasible for my use case? While FastAPI seems to be better due to async, my lack of experience with prod grade DB management makes Django seem good too, due to things such as automated migrations and the in built ORM. Current setup is FastAPI + SQLAlchemy and Alembic.</p><ol><li>Anyone successfully combine them, Django for the monolith, FastAPI for specific endpoints?</li></ol></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 01 Sep 2025 01:33:48 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n4v2zm/gendual_python_library_for_highorder_partial/</link><title>gen-dual: Python library for high-order partial derivatives with dual numbers</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n4v2zm/gendual_python_library_for_highorder_partial/</guid><comments>https://www.reddit.com/r/Python/comments/1n4v2zm/gendual_python_library_for_highorder_partial/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n4v2zm/gendual_python_library_for_highorder_partial/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>What My Project Does:</strong><br/>gen-dual is a Python library for vectorized computation of arbitrary-order partial derivatives of multivariable functions. It supports complex numbers and many functions like LambertW, Gamma, InverseErf, and Abs. Derivatives are computed all at once using a dual-number-like method, useful for analyzing Taylor series, function behavior, or any derivative-related computations.</p><p><strong>Target Audience:</strong><br/>This library is meant for anyone interested in exploring high-precision, multi-variable differentiation in Python, including researchers, students, or hobbyists.</p><p><strong>Comparison:</strong><br/>Unlike standard automatic differentiation libraries, gen-dual supports arbitrary-order derivatives, full vectorization, complex numbers, and rich function support, making it more flexible than most existing alternatives.</p><p><strong>GitHub Link:</strong><br/><a href="https://github.com/LukaLavs/Generalized-Dual">https://github.com/LukaLavs/Generalized-Dual</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 31 Aug 2025 19:13:57 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n4rahf/just_built_pydanticgsheets_to_bring_google_sheets/</link><title>Just built: pydantic-gsheets to bring Google Sheets and Pydantic together</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n4rahf/just_built_pydanticgsheets_to_bring_google_sheets/</guid><comments>https://www.reddit.com/r/Python/comments/1n4rahf/just_built_pydanticgsheets_to_bring_google_sheets/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n4rahf/just_built_pydanticgsheets_to_bring_google_sheets/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hey everyone,<br/>I have developed a small experimental package called¬†<strong>pydantic-gsheets</strong>.</p><h1>What My Project Does</h1><p><a href="https://github.com/Youssefbenhammouda/pydantic-gsheets">pydantic-gsheets</a> is a small experimental package that lets you read and write Google Sheets data in Python using nothing but Pydantic models. Define a BaseModel, and you can validate, parse, and sync data with Sheets without extra boilerplate.</p><h1>Target Audience</h1><p>It‚Äôs meant for quick prototypes, small projects, or teams that love using Google Sheets but want type safety when bringing that data into Python. At this stage it‚Äôs still <strong>experimental</strong>, so not yet recommended for production ‚Äî but great for tinkering, demos, or internal tools.</p><h1>Comparison</h1><p>There are other ways to connect Python to Google Sheets (e.g., gspread, pygsheets), but they typically give you raw dicts or lists that you then have to validate manually. The difference here is that pydantic-gsheets plugs directly into <strong>Pydantic BaseModels</strong>, so your schema, validation, and type coercion happen automatically. You don‚Äôt have to write glue code.</p><h1>Links</h1><p>Links if you want to peek:<br/>* Blog: [Exploring pydantic-gsheets](<a href="https://youssef.benhammouda.ma/blog/pydantic-gsheets">https://youssef.benhammouda.ma/blog/pydantic-gsheets</a>)</p><p>* Docs: [pydantic-gsheets documentation](<a href="https://youssefbenhammouda.github.io/pydantic-gsheets/">https://youssefbenhammouda.github.io/pydantic-gsheets/</a>)</p><p>* GitHub: [pydantic-gsheets repo](<a href="https://github.com/Youssefbenhammouda/pydantic-gsheets">https://github.com/Youssefbenhammouda/pydantic-gsheets</a>)</p><p>Would love to hear thoughts or ideas if you try it out üôÇ</p><p>PS: If you find it useful and want to use it, please know it‚Äôs still¬†<strong>experimental</strong>. That also means collaborators are¬†<strong>very welcome,</strong>¬†whether it‚Äôs testing, bug reports, or PRs.</p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 31 Aug 2025 15:57:49 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n4qygz/introducing_neosqlite/</link><title>Introducing NeoSQLite</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n4qygz/introducing_neosqlite/</guid><comments>https://www.reddit.com/r/Python/comments/1n4qygz/introducing_neosqlite/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n4qygz/introducing_neosqlite/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>Showcase: NeoSQLite ‚Äì Use SQLite with a PyMongo-like API</strong></p><p>I&#39;m excited to introduce <strong>NeoSQLite</strong> (<a href="https://github.com/cwt/neosqlite">https://github.com/cwt/neosqlite</a>), a lightweight Python library that brings a PyMongo-compatible interface to SQLite. This means you can interact with SQLite using familiar MongoDB-style syntax‚Äîinserting, querying, and indexing JSON-like documents‚Äîwhile still benefiting from SQLite‚Äôs simplicity, reliability, and zero configuration.</p><h3>What My Project Does</h3><p>NeoSQLite allows you to:- Use MongoDB-style operations like <code>insert_one</code>, <code>find</code>, <code>update_one</code>, and <code>delete_many</code> with SQLite.- Perform full-text search across multiple languages using the <code>$text</code> operator, powered by an ICU-based tokenizer (via my <a href="https://github.com/cwt/fts5-icu-tokenizer">fts5-icu-tokenizer</a>).- Automatically compress query results using <a href="https://github.com/cwt/quez">quez</a>, reducing memory usage by 50‚Äì80% for large result sets.- Work with embedded documents and nested queries, all backed by SQLite‚Äôs ACID-compliant storage.</p><p>It‚Äôs designed for developers who love MongoDB‚Äôs ease of use but want a lightweight, file-based alternative without external dependencies.</p><h3>Target Audience</h3><p>NeoSQLite is ideal for:- Developers building small to medium-sized applications (e.g., CLI tools, desktop apps, IoT devices) where deploying a full MongoDB instance is overkill.- Projects that need a schema-flexible, document-style database but must remain portable and dependency-free.- Prototyping or educational use, where a MongoDB-like interface speeds up development without requiring server setup.- Environments with limited resources, thanks to its memory-efficient result compression.</p><p>It‚Äôs not intended to replace MongoDB in high-concurrency, large-scale production systems, but it‚Äôs production-ready for lightweight, embedded use cases.</p><h3>Comparison with Existing Alternatives</h3><p>Unlike other SQLite-to-document-store wrappers, NeoSQLite stands out by:- Offering <strong>deep API compatibility with PyMongo</strong>, minimizing the learning curve for developers already familiar with MongoDB.- Supporting <strong>true multilingual full-text search</strong> via ICU (not just ASCII or basic Unicode), which most SQLite FTS solutions lack.- Reducing memory footprint significantly through built-in result compression‚Äîsomething not offered by standard SQLite ORMs like SQLAlchemy or dataset.- Being <strong>zero-configuration and serverless</strong>, unlike MongoDB (which requires a running service) or libraries like TinyDB (which lack indexing, full-text search, or performance optimizations).</p><p>In short, if you‚Äôve ever wished you could use MongoDB‚Äôs API with SQLite‚Äôs simplicity, NeoSQLite is for you.</p><hr/><p>Feedback and contributions are welcome. Check it out at: <a href="https://github.com/cwt/neosqlite">https://github.com/cwt/neosqlite</a></p><hr/><p>20250903: I‚Äôve made a lot of updates since my last post. Performance has improved thanks to the use of temp table. Please check it out and give it a try!</p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 31 Aug 2025 15:36:58 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n4pitk/intentgraph_opensource_python_library_for_repo/</link><title>IntentGraph ‚Äì Open-source Python library for repo dependency graphs &amp;amp; clustering</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n4pitk/intentgraph_opensource_python_library_for_repo/</guid><comments>https://www.reddit.com/r/Python/comments/1n4pitk/intentgraph_opensource_python_library_for_repo/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n4pitk/intentgraph_opensource_python_library_for_repo/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hello everybody,</p><p>I started this project out of a pain point I kept hitting: when working with larger repos, it‚Äôs easy to lose track of how files connect. And when trying to use automation tools (AI or otherwise), the problem gets worse: once you go past a few files, context just disappears, or the token count explodes every time the tool has to look through the whole codebase.</p><p>That‚Äôs what led me to build <strong>IntentGraph</strong>: a Python library to map dependencies and structure repos in a way that‚Äôs useful for developers <em>and</em> for programmatic agents.</p><p><strong>What My Project Does</strong></p><p>IntentGraph is a Python library for analyzing large codebases. It:</p><ul><li><p>Maps dependencies between files and modules</p></li><li><p>Clusters code (analysis, refactoring, navigation)</p></li><li><p>Produces structured outputs at 3 levels (minimal ‚Üí full detail)</p></li><li><p>Designed to be <strong>programmatically queryable</strong>: useful for developers and AI agents that need structured repo context</p></li></ul><p><strong>Target Audience</strong></p><ul><li><p>Developers who want to explore or refactor large Python repos</p></li><li><p>Tool builders needing a structured representation of a codebase</p></li><li><p>Researchers interested in program analysis and code graphing</p></li><li><p>AI/automation workflows that require repo-wide context</p></li></ul><p><strong>Comparison</strong></p><p>Unlike linting/static analysis tools, IntentGraph focuses on structural understanding of the codebase. This structured output makes it lightweight enough for automated tools and AI agents to consume directly.</p><p><strong>Links:</strong></p><p>GitHub: <a href="https://github.com/Raytracer76/IntentGraph">https://github.com/Raytracer76/IntentGraph</a></p><p>PyPI: <a href="https://pypi.org/project/intentgraph/">https://pypi.org/project/intentgraph/</a></p><p><strong>Open Source &amp; Call for Contributions</strong></p><p>IntentGraph is fully open source. I encourage forks, experiments, and extensions ‚Äî for example, expanding it into other languages (Java, Rust, C#, etc.).I likely won‚Äôt drive this much further myself, but I‚Äôd love to see where the community takes it.</p><p><strong>Looking for feedback:</strong></p><ul><li><p>What‚Äôs missing for practical use in Python projects?</p></li><li><p>Ideas for integrations (e.g., VS Code)?</p></li><li><p>Languages you‚Äôd want supported next?</p></li></ul></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 31 Aug 2025 14:03:40 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n4nhbk/my_python_mini_project/</link><title>My python mini project</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n4nhbk/my_python_mini_project/</guid><comments>https://www.reddit.com/r/Python/comments/1n4nhbk/my_python_mini_project/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n4nhbk/my_python_mini_project/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I have made an app that is great for studing python and begginer friendly as well, I would like to introduce you to <code>lisq</code> a single file, lightweight and portable python note-taking app. It would not only serve you as notes but also allow you to add your own functions, advanced searching through out the notes, edit, encrypt and much more (please read README for more information!).</p><p>Official github repository:<a href="https://github.com/funnut/Lisq.git">https://github.com/funnut/Lisq.git</a></p><p>Share &amp; leave a star üåü</p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 31 Aug 2025 11:53:00 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n4ilwx/pysimplegui_hobbyist_license_canceled/</link><title>PySimpleGUI Hobbyist License Canceled</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n4ilwx/pysimplegui_hobbyist_license_canceled/</guid><comments>https://www.reddit.com/r/Python/comments/1n4ilwx/pysimplegui_hobbyist_license_canceled/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n4ilwx/pysimplegui_hobbyist_license_canceled/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>So I used PySimpleGUI for a single project and received the 30 day free trial assuming Id be able to get the hobbyist version once it was over. Is it crazy to anyone else that it cost $99 to just save a few lines of code considering I can create the same, if not a more customizable GUI using C/C++. My project which wasnt too crazy (firetv remote using adb protocol) is now garbage because I will not pay for the dumb licensing fee, but hey maybe a single person should pay the same amount a billion dollar company pays right???`</p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 31 Aug 2025 07:20:49 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n4hc9e/python_type_system/</link><title>Python type system</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n4hc9e/python_type_system/</guid><comments>https://www.reddit.com/r/Python/comments/1n4hc9e/python_type_system/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n4hc9e/python_type_system/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>(Just sharing something)  </p><p>As someone who has taken advantage of TypeScript&#39;s type safety for most of its career, using Python without type safety feels a bit awkward. I put together a page explaining how to take advantage of Python&#39;s type system and how to extend it on your editor.</p><p><a href="https://crocus-ceres-509.notion.site/How-Python-type-system-works-and-how-to-extend-it-on-your-editor-21e3826aa7ed808b93e2f4d18493c6ea">https://crocus-ceres-509.notion.site/How-Python-type-system-works-and-how-to-extend-it-on-your-editor-21e3826aa7ed808b93e2f4d18493c6ea</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 31 Aug 2025 06:16:58 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n40rht/i_built_my_own_torch_in_the_last_two_weeks/</link><title>I built my own torch in the last two weeks!</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n40rht/i_built_my_own_torch_in_the_last_two_weeks/</guid><comments>https://www.reddit.com/r/Python/comments/1n40rht/i_built_my_own_torch_in_the_last_two_weeks/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n40rht/i_built_my_own_torch_in_the_last_two_weeks/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>What my project does:</strong></p><p>In the last two weeks, I have been working on building my own toy project: a deep learning training framework. It is named &quot;mytorch&quot;. It was written from scratch except that I use cublaslt for high performance matmul operations. Now it can do most of the pytorch stuff:</p><p>- cuda support for forward/backward operators in CNN MNIST training and evaluations, such as, BN, Conv, Linear, many elementwise ops, many reduce ops, many essential ops;</p><p>- SGD optimizer;</p><p>- Load/save state dict for module/optimizer</p><p>- Dataset/DataLoader</p><p>- Autograd system: topsort for backward.</p><p><strong>Target Audience:</strong></p><p>It is a toy project for education.</p><p><strong>Comparison with other products:</strong></p><p>In terms of results, when training MNIST for 3 epochs in my 4060 laptop, PyTorch takes 33 seconds while &quot;mytorch&quot; takes 41 seconds which is just 25% slower. PyTorch is a highly optimized framework for production. But my project is for fun and for learning more about cuda programming/autograd system.</p><p>Please leave a star on my git repo or leave a comment below if you are interested. Thanks so much!<br/><a href="https://github.com/tigert1998/mytorch/tree/main">s://github.com/tigert1998/mytorch/tree/main</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 30 Aug 2025 18:16:54 +0530</pubDate></item></channel></rss>
