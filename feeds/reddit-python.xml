<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><atom:link href="http://192.168.1.132/?platform=reddit&amp;subreddit=Python&amp;averagePostsPerDay=5&amp;content&amp;view=rss" rel="self" type="application/rss+xml"/><title>/r/Python</title><description>Hot posts in /r/Python (roughly 5 posts per day)</description><link>https://www.reddit.com/r/Python/</link><language>en-us</language><lastBuildDate>Sat, 06 Sep 2025 20:37:07 +0000</lastBuildDate><generator>Upvote RSS</generator><image><url>http://192.168.1.132//app/cache/images/styles-redditmedia-com-t5_2qh0y-styles-communityIcon_mkayghu1502d1-144x400.png</url><title>/r/Python</title><link>https://www.reddit.com/r/Python/</link><width>144</width><height>144</height></image><item><link>https://www.reddit.com/r/Python/comments/1n9qlkv/what_are_some_nonai_toolsextensions_which_have/</link><title>What are some non-AI tools/extensions which have really boosted your work life or made life easier?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n9qlkv/what_are_some_nonai_toolsextensions_which_have/</guid><comments>https://www.reddit.com/r/Python/comments/1n9qlkv/what_are_some_nonai_toolsextensions_which_have/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n9qlkv/what_are_some_nonai_toolsextensions_which_have/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>It can be an extension or a CLI tool or something else, My work mainly involves in developing managing mid sized python applications deployed over aws. I mostly work through cursor and agents have been decently useful but these days all the development on programming tools seems to be about AI integration. Is there something that people here have been using that&#39;s come out in last few years and has made serious impact in how you do things? Can be open source or not, anything goes it just shouldn&#39;t be something AI or a framework.</p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 06 Sep 2025 10:11:33 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n9ov57/simple_python_expression_that_does_complex_things/</link><title>Simple Python expression that does complex things?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n9ov57/simple_python_expression_that_does_complex_things/</guid><comments>https://www.reddit.com/r/Python/comments/1n9ov57/simple_python_expression_that_does_complex_things/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n9ov57/simple_python_expression_that_does_complex_things/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>First time I saw <code>a[::-1]</code> to invert the list <code>a</code>, I was blown away. </p><p><code>a, b = b, a</code> which swaps two variables (without temp variables in between) is also quite elegant. </p><p>What&#39;s your favorite example?</p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 06 Sep 2025 08:37:42 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n9kste/python_type_system_and_tooling_survey_2025_from/</link><title>Python Type System and Tooling Survey 2025 (From Meta &amp;amp; JetBrains)</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n9kste/python_type_system_and_tooling_survey_2025_from/</guid><comments>https://www.reddit.com/r/Python/comments/1n9kste/python_type_system_and_tooling_survey_2025_from/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n9kste/python_type_system_and_tooling_survey_2025_from/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>As mentioned in the title, this survey was developed by Meta &amp; Jetbrains w/ community input to collect opinions around Python&#39;s type system and type-related tooling.</p><blockquote><p>The goal of this survey is to gain insights into the tools and practices you use (if any!), the challenges you face, and how you stay updated on new features. Your responses will help the Python typing community identify common blockers, improve resources, and enhance the overall experience of using Python&#39;s type system. Even if you have never actively used type hints in your code, your thoughts are still valuable and we want to hear from you.</p></blockquote><p>Take the survey <a href="https://docs.google.com/forms/d/e/1FAIpQLSeOFkLutxMLqsU6GPe60OJFYVN699vqjXPtuvUoxbz108eDWQ/viewform">here</a>.</p><p>Original LinkedIn posts (so you know it&#39;s legit):</p><p><a href="https://www.linkedin.com/posts/meta-open-source_python-type-system-and-tooling-survey-2025-activity-7369400929546092548-A0hh?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAB9aSUsBqmxSbrhoW2URuDnxCgS5eVD1AS0">Meta Open Source</a></p><p><a href="https://www.linkedin.com/posts/thepsf_python-type-system-and-tooling-survey-2025-activity-7368968760252059648-ICjo?utm_source=social_share_send&amp;utm_medium=member_desktop_web&amp;rcm=ACoAAB9aSUsBqmxSbrhoW2URuDnxCgS5eVD1AS0">Python Software Foundation</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 06 Sep 2025 05:16:17 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n95jwd/aws_for_python_devs_made_simple/</link><title>AWS for Python devs - made simple</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n95jwd/aws_for_python_devs_made_simple/</guid><comments>https://www.reddit.com/r/Python/comments/1n95jwd/aws_for_python_devs_made_simple/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n95jwd/aws_for_python_devs_made_simple/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>What is Stelvio?</strong><br/>Stelvio is a Python framework for managing and deploying AWS infrastructure. Instead of writing YAML, JSON, or HCL, you define your infrastructure in <strong>pure Python</strong>. The framework provides <strong>smart defaults</strong> for networking, IAM, and security so you can focus on your application logic rather than boilerplate setup.</p><p>With the <code>stlv</code> CLI, you can go from zero to a working AWS environment in seconds, without heavy configuration.</p><p><strong>What My Project Does</strong><br/>Stelvio lets Python developers:</p><ul><li>Spin up AWS resources (e.g. compute, storage, networking) using Python code.</li><li>Deploy isolated environments (personal or team-based) with a single command.</li><li>Skip most of the manual setup thanks to opinionated defaults for IAM roles, VPCs, and security groups.</li></ul><p>The goal is to make cloud deployments <strong>approachable to Python developers who aren’t infrastructure experts</strong>.</p><p><strong>Target Audience</strong></p><ul><li><strong>Python developers</strong> who want to deploy applications to AWS without learning all of Terraform or CloudFormation.</li><li><strong>Small teams and projects</strong> that need quick, reproducible environments.</li><li>It’s designed for <strong>real-world usage</strong>, not just as a toy project, but it’s still early-stage and evolving rapidly.</li></ul><p><strong>Comparison to Alternatives</strong></p><ul><li>Compared to <strong>Terraform</strong>: Stelvio is Python-native, so you don’t need to learn HCL or use external templating.</li><li>Compared to <strong>AWS CDK</strong>: Stelvio emphasizes <strong>zero setup</strong> and <strong>smart defaults</strong>. CDK is very flexible but requires more boilerplate and AWS-specific expertise.</li><li>Compared to <strong>Pulumi</strong>: Stelvio is lighter-weight and focuses narrowly on AWS, aiming to reduce complexity rather than cover all clouds.</li></ul><p><strong>Links</strong></p><ul><li>GitHub: <a href="https://github.com/michal-stlv/stelvio?utm_source=chatgpt.com">https://github.com/michal-stlv/stelvio</a></li><li>Website: <a href="https://stelvio.dev?utm_source=chatgpt.com">https://stelvio.dev</a></li></ul></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 05 Sep 2025 19:09:25 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n9267v/i_built_a_visual_component_library_for/</link><title>I built a visual component library for instrumentation</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n9267v/i_built_a_visual_component_library_for/</guid><comments>https://www.reddit.com/r/Python/comments/1n9267v/i_built_a_visual_component_library_for/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n9267v/i_built_a_visual_component_library_for/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hello everyone,</p><p>as Python is growing more and more in industrial field, I decided to create visual component library for instrumentation.</p><p><strong>What My Project Does:</strong><br/>A Python library with <strong>40+ visual and non-visual components</strong> for building industrial and lab GUIs. Includes analog instruments, sliders, switches, buttons, graphs, and oscilloscope &amp; logic analyzer widgets (PyVISA-compatible). Components are <strong>highly customizable</strong> and designed with a <strong>retro industrial look</strong>.</p><p><strong>Target Audience:</strong><br/>Engineers, scientists, and hobbyists building technical or industrial GUIs. Suitable for both <strong>prototypes and production-ready applications</strong>.</p><p><strong>Comparison / How It’s Different:</strong><br/>Unlike general GUI frameworks, this library is <strong>instrumentation-focused</strong> with ready-made industrial-style meters, gauges, and analyzer components—saving development time and providing a consistent professional look.</p><p><strong>Demo:</strong> <a href="https://imgur.com/a/0j89hPf?utm_source=chatgpt.com">Imgur</a> (Not all components are being shown, just a small sneek-peak)<br/><strong>GitHub Repo:</strong> <a href="https://github.com/tino-posedi/Thales?utm_source=chatgpt.com">Thales</a> (private, still in progress)</p><p><strong>Feedback Questions:</strong></p><ul><li>Are there components you’d find particularly useful for industrial or lab GUIs?</li><li>Is the retro industrial style appealing, or would you prefer alternative themes?</li><li>Any suggestions for improving customization, usability, or performance?</li></ul></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 05 Sep 2025 16:31:47 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n91acl/showcase_i_cocreated_dlt_an_opensource_python/</link><title>Showcase: I co-created dlt, an open-source Python library that lets you build data pipelines in minu</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n91acl/showcase_i_cocreated_dlt_an_opensource_python/</guid><comments>https://www.reddit.com/r/Python/comments/1n91acl/showcase_i_cocreated_dlt_an_opensource_python/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n91acl/showcase_i_cocreated_dlt_an_opensource_python/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>As a 10y+ data engineering professional, I got tired of the boilerplate and complexity required to load data from messy APIs and files into structured destinations. So, with a team, I built <code>dlt</code> to make data loading ridiculously simple for anyone who knows Python.</p><p><strong>Features:</strong></p><ul><li>➡️ <strong>Load anything with Schema Evolution:</strong> Easily pull data from any API, database, or file (JSON, CSV, etc.) and load it into destinations like DuckDB, BigQuery, Snowflake, and more, handling types and nested data flawlessly.</li><li>➡️ <strong>No more schema headaches:</strong> <code>dlt</code> automatically creates and maintains your database tables. If your source data changes, the schema adapts on its own.</li><li>➡️ <strong>Just write Python:</strong> No YAML, no complex configurations. If you can write a Python function, you can build a production-ready data pipeline.</li><li>➡️ <strong>Scales with you:</strong> Start with a simple script and scale up to handle millions of records without changing your code. It&#39;s built for both quick experiments and robust production workflows.</li><li>➡️ <strong>Incremental loading solved:</strong> Easily keep your destination in sync with your source by loading only new data, without the complex state management.</li><li>➡️ <strong>Easily extendible:</strong> <code>dlt</code> is built to be modular. You can add new sources, customize data transformations, and deploy anywhere.</li></ul><p><strong>Link to repo:</strong><a href="https://github.com/dlt-hub/dlt">https://github.com/dlt-hub/dlt</a></p><p>Let us know what you think! We&#39;re always looking for feedback and contributors.</p><h1>What My Project Does</h1><p><code>dlt</code> is an open-source Python library that simplifies the creation of robust and scalable data pipelines. It automates the most painful parts of Extract, Transform, Load (ETL) processes, particularly schema inference and evolution. Users can write simple Python scripts to extract data from various sources, and <code>dlt</code> handles the complex work of normalizing that data and loading it efficiently into a structured destination, ensuring the target schema always matches the source data.</p><h1>Target Audience</h1><p>The tool is for <strong>data scientists, analysts, and Python developers</strong> who need to move data for analysis, machine learning, or operational dashboards but don&#39;t want to become full-time data engineers. It&#39;s perfect for anyone who wants to build production-ready, maintainable data pipelines without the steep learning curve of heavyweight orchestration tools like Airflow or writing extensive custom code. It’s suitable for everything from personal projects to enterprise-level deployments.</p><h1>Comparison (how it differs from existing alternatives)</h1><p>Unlike complex frameworks such as <strong>Airflow</strong> or <strong>Dagster</strong>, which are primarily orchestrators that require significant setup, <code>dlt</code> is a lightweight library focused purely on the &quot;load&quot; part of the data pipeline. Compared to writing <strong>custom Python scripts</strong> using libraries like <code>SQLAlchemy</code> and <code>pandas</code>, <code>dlt</code> abstracts away tedious tasks like schema management, data normalization, and incremental loading logic. This allows developers to create declarative and resilient pipelines with far less code, reducing development time and maintenance overhead.</p></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 05 Sep 2025 15:41:57 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n8jasr/im_building_local_opensource_fast_minimal_and/</link><title>I'm building local, open-source, fast minimal, and extendible python RAG library and CLI tool</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n8jasr/im_building_local_opensource_fast_minimal_and/</guid><comments>https://www.reddit.com/r/Python/comments/1n8jasr/im_building_local_opensource_fast_minimal_and/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n8jasr/im_building_local_opensource_fast_minimal_and/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I got tired of overengineered and bloated AI libraries and needed something to prototype local RAG apps quickly so I decided to make my own library,<br/>Features:<br/>➡️ Get to prototyping local RAG applications in seconds: uvx rocketrag prepare &amp; uv rocketrag ask is all you need<br/>➡️ CLI first interface, you can even visualize embeddings in your terminal<br/>➡️ Native llama.cpp bindings - no Ollama bullshit<br/>➡️ Ready to use minimalistic web app with chat, vectors visualization and browsing documents➡️ Minimal footprint: milvus-lite, llama.cpp, kreuzberg, simple html web app<br/>➡️ Tiny but powerful - use any chucking method from chonkie, any LLM with .gguf provided and any embedding model from sentence-transformers<br/>➡️ Easily extendible - implement your own document loaders, chunkers and BDs, contributions welcome!<br/>Link to repo: <a href="https://github.com/TheLion-ai/RocketRAG">https://github.com/TheLion-ai/RocketRAG</a><br/>Let me know what you think. If anybody wants to collaborate and contribute DM me or just open a PR!  </p><p><strong>What My Project Does</strong><br/>RocketRAG is a high-performance Retrieval-Augmented Generation (RAG) library that loads documents (PDF/TXT/MD…), performs semantic chunking, indexes embeddings into a fast vector DB, then serves answers via a local LLM. It provides both a CLI and a FastAPI-based web server with OpenAI-compatible <code>/ask</code> and streaming endpoints, and is built to prioritize speed, a minimal code footprint, and easy extensibility</p><p><strong>Target Audience</strong><br/>Developers and researchers who want a fast, modular RAG stack for local or self-hosted inference (GGUF / llama-cpp-python), and teams who value low-latency document processing and a plug-and-play architecture. It’s suitable both for experimentation and for production-ready local/offline deployments where performance and customizability matter. </p><p><strong>Comparison (how it differs from existing alternatives)</strong><br/>Unlike heavier, opinionated frameworks, RocketRAG focuses on performance-first building blocks: ultra-fast document loaders (Kreuzberg), semantic chunking (Chonkie/model2vec), Sentence-Transformers embeddings, Milvus Lite for sub-millisecond search, and llama-cpp-python for GGUF inference — all in a pluggable architecture with a small footprint. The goal is lower latency and easier swapping of components compared to larger ecosystems, while still offering a nice CLI </p></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 05 Sep 2025 00:43:21 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n8f0xu/pycon_2025_workshop_agentic_apps_with_pydanticai/</link><title>PyCon 2025 Workshop: Agentic Apps with Pydantic-AI</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n8f0xu/pycon_2025_workshop_agentic_apps_with_pydanticai/</guid><comments>https://www.reddit.com/r/Python/comments/1n8f0xu/pycon_2025_workshop_agentic_apps_with_pydanticai/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n8f0xu/pycon_2025_workshop_agentic_apps_with_pydanticai/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>Hey all!</strong></p><p>I recently gave a workshop talk at <strong>PyCon Greece 2025</strong> about building production-ready agent systems.<br/>To check it out, I put together a demo repo (slides coming soon on my blog: <a href="https://www.petrostechchronicles.com/?utm_source=chatgpt.com">petrostechchronicles.com</a>):</p><p>Repo: <a href="https://github.com/Aherontas/Pycon_Greece_2025_Presentation_Agents?utm_source=chatgpt.com">github.com/Aherontas/Pycon_Greece_2025_Presentation_Agents</a></p><p><strong>The idea</strong>: show how multiple AI agents can collaborate using <strong>FastAPI + Pydantic-AI</strong>, with protocols like <strong>MCP (Model Context Protocol)</strong> and <strong>A2A (Agent-to-Agent)</strong> for safe communication and orchestration.</p><p><strong>Features:</strong></p><ul><li>Multiple agents running in containers</li><li>MCP servers (Brave search, GitHub, filesystem, etc.) as tools</li><li>A2A communication between services</li><li>Minimal UI for experimentation (e.g., repo analysis)</li></ul><p><strong>Why I built this</strong>:<br/>Most agent frameworks look great in isolated demos, but fall apart when you try to glue agents together into a real application.<br/>My goal was to help people experiment with these patterns and move closer to real-world use cases.</p><p>It’s not production-grade, but I’d love <strong>feedback, criticism, or war stories</strong> from anyone who’s tried building multi-agent systems.</p><p><strong>Big question for discussion:</strong><br/>Do you think agent-to-agent protocols like MCP/A2A will stick?<br/>Or will the future be mostly single powerful LLMs with plugin stacks?</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 22:01:51 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n8d6pi/productiongrade_python_logging_made_easier_with/</link><title>Production-Grade Python Logging Made Easier with Loguru</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n8d6pi/productiongrade_python_logging_made_easier_with/</guid><comments>https://www.reddit.com/r/Python/comments/1n8d6pi/productiongrade_python_logging_made_easier_with/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n8d6pi/productiongrade_python_logging_made_easier_with/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>While Python&#39;s standard logging module is powerful, navigating its system of handlers, formatters, and filters can often feel like more work than it should be.</p><p><a href="https://www.dash0.com/guides/python-logging-with-loguru">I wrote a guide</a> on how to achieve the same (and better) results with a fraction of the complexity using Loguru. It’s approachable, can intercept logs from the standard library, and exposes its other great features in a much cleaner API.</p><p>Looking forward to hearing what you think!</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 20:53:33 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n87g91/rant_use_that_second_expression_in_assert/</link><title>Rant: use that second expression in `assert`!</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n87g91/rant_use_that_second_expression_in_assert/</guid><comments>https://www.reddit.com/r/Python/comments/1n87g91/rant_use_that_second_expression_in_assert/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n87g91/rant_use_that_second_expression_in_assert/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>The <code>assert</code> statement is wildly useful for developing and maintaining software. I sprinkle <code>assert</code>s liberally in my code at the beginning to make sure what I think is true, is actually true, and this practice catches a vast number of idiotic errors; and I keep at least some of them in production.</p><p>But often I am in a position where someone else&#39;s assert triggers, and I see in a log something like <code>assert foo.bar().baz() != 0</code> has triggered, and I have no information at all.</p><p>Use that second expression in <code>assert</code>! </p><p>It can be anything you like, even some calculation, and it doesn&#39;t get called unless the assertion fails, so it costs nothing if it never fires. When someone has to find out why your assertion triggered, it will make everyone&#39;s life easier if the assertion explains what&#39;s going on.</p><p>I often use</p><pre><code>assert some_condition(), locals()</code></pre><p>which prints every local variable if the assertion fails. (<code>locals()</code> might be impossibly huge though, if it contains some massive variable, you don&#39;t want to generate some terabyte log, so be a little careful...)</p><p>And remember that <code>assert</code> is a statement, not an expression. That is why this <code>assert</code> will never trigger:</p><pre><code>assert (   condition,   &quot;Long Message&quot;)</code></pre><p>because it asserts that the expression <code>(condition, &quot;Message&quot;)</code> is truthy, which it always is, because it is a two-element tuple.</p><p>Luckily I read an article about this long before I actually did it. I see it every year or two in someone&#39;s production code still.</p><p>Instead, use </p><pre><code>assert condition, (    &quot;Long Message&quot;)</code></pre></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 16:53:00 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n86hnz/i_made_a_script_that_identifies_graded_pokemon/</link><title>I made a script that identifies graded Pokemon cards with OCR</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n86hnz/i_made_a_script_that_identifies_graded_pokemon/</guid><comments>https://www.reddit.com/r/Python/comments/1n86hnz/i_made_a_script_that_identifies_graded_pokemon/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n86hnz/i_made_a_script_that_identifies_graded_pokemon/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hi everyone,</p><p>I run a <a href="https://www.jimmysdealfinder.com">Pokemon deal finder</a> site that finds deals on Pokemon cards on eBay by comparing listing prices to historical card values.</p><p>I used to have graded cards on there, but I had to remove them from the site because too many people would lie in the title about what grade it is. For example, they might put &quot;PSA 10&quot; when it&#39;s only a PSA 9 or they might put &quot;Easily a PSA 10&quot; or &quot;Potential PSA 10&quot; when the card was ungraded. There were enough cards like this that I had to remove graded cards from the site because there were too many misleading graded listings.</p><p>I decided to try to use OCR on the card images to identify the grade rather than trusting what the user says in the title. I managed to write a surprisingly accurate script for identifying the grade of PSA 9 and PSA 10 cards.</p><p>It uses the cv2 and easyocr libraries, and it searches for sections that look purely black and white in the image (likely to be text), then it scans that section for the words &quot;MINT&quot; (grade 9) or &quot;GEM MT&quot; (grade 10) to determine the grade of the card.</p><p>It works surprisingly well, and the best thing is there are no false positives.</p><p>Now I&#39;ve got graded cards back on my site, and they all seem to be identified correctly.</p><p><strong>What My Project Does</strong></p><p>Takes an image of a Pokemon card, and determiners whether it&#39;s a grade 9 or 10 or ungraded.</p><p><strong>Target Audience</strong></p><p>This is mainly for myself as a tool to add graded cards back to my site. Though it could be useful for anyone who needs to identify a graded card from an image.</p><p><strong>Comparison</strong></p><p>When I was first writing this, I did search on Google to see if anyone had done OCR recognition on graded Pokemon cards, but I didn&#39;t really find anything. I think this is unique in that regard.</p><p>You can run it with get_grade_ocr() on either a filename or a URL.</p><p>Github: <a href="https://github.com/sgriffin53/pokemon_ocr">https://github.com/sgriffin53/pokemon_ocr</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 15:59:31 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n85285/typewriter_sound_program/</link><title>Typewriter sound program</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n85285/typewriter_sound_program/</guid><comments>https://www.reddit.com/r/Python/comments/1n85285/typewriter_sound_program/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n85285/typewriter_sound_program/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I love the sound of a typewriter. I like the mechanical sound but I don&#39;t like typing on mechanical keyboards. How would one go about writing a program that imitates the typewriter sound as I&#39;m typing?</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 14:32:18 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n84hjt/pyconfr_at_lyon_france/</link><title>PyconFR at Lyon (France)</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n84hjt/pyconfr_at_lyon_france/</guid><comments>https://www.reddit.com/r/Python/comments/1n84hjt/pyconfr_at_lyon_france/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n84hjt/pyconfr_at_lyon_france/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>The French-Speaking Python Association (AFPy) is organizing PyConFR 2025 from Thursday, October 30 to Sunday, November 2. For this 16th edition, we’ll be hosted by the René Cassin Campus in Lyon!</p><p>PyConFR is a free, four-day event centered around the Python programming language. It includes two days of collaborative development (sprints), followed by two days of talks and workshops.</p><p>The call for proposals is now closed, and we’ll be publishing the schedule soon at <a href="https://www.pycon.fr/2025/en/schedule.html">https://www.pycon.fr/2025/en/schedule.html</a>. There will be an English-language track.</p><p>While attendance is free, registration is required for all participants.</p><p>As every year, we offer support to people who are usually underrepresented at conferences — help with finding a topic, writing a proposal, preparing slides, and rehearsing. Feel free to contact us at [<a href="mailto:diversite@afpy.org">diversite@afpy.org</a>]()</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 13:54:02 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n7sr1x/why_does_processpoolexecutor_mark_some_tasks_as/</link><title>Why does ProcessPoolExecutor mark some tasks as "running" even though all workers are busy?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n7sr1x/why_does_processpoolexecutor_mark_some_tasks_as/</guid><comments>https://www.reddit.com/r/Python/comments/1n7sr1x/why_does_processpoolexecutor_mark_some_tasks_as/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n7sr1x/why_does_processpoolexecutor_mark_some_tasks_as/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I’m using Python’s <code>ProcessPoolExecutor</code> to run a bunch of tasks. Something I noticed is that some tasks are marked as <em>running</em> even though all the workers are already working on other tasks.</p><p>From my understanding, a task should only switch from <em>pending</em> to <em>running</em> once a worker actually starts executing it. But in my case, it seems like the executor marks extra tasks as running before they’re really picked up.</p><p>Is this normal behavior of <code>ProcessPoolExecutor</code>? Or am I missing something about how it manages its internal task queue?</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 03:46:26 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n7r4xb/niche_python_tools_libraries_and_features_whats/</link><title>Niche Python tools, libraries and features - whats your favourite?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n7r4xb/niche_python_tools_libraries_and_features_whats/</guid><comments>https://www.reddit.com/r/Python/comments/1n7r4xb/niche_python_tools_libraries_and_features_whats/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n7r4xb/niche_python_tools_libraries_and_features_whats/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I know we see this get asked every other week, but it always makes for a good discussion.</p><p>I only just found out about <code>pathlib</code> - makes working with files so much cleaner.</p><p>Whats a python tool or library you wish youd known about earlier?</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 02:41:38 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n7pe37/removing_a_dependency_major_minor_or_patch_bump/</link><title>Removing a dependency - Major, Minor or Patch bump?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n7pe37/removing_a_dependency_major_minor_or_patch_bump/</guid><comments>https://www.reddit.com/r/Python/comments/1n7pe37/removing_a_dependency_major_minor_or_patch_bump/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n7pe37/removing_a_dependency_major_minor_or_patch_bump/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I&#39;ve been collaborating on an <a href="https://github.com/jcfitzpatrick12/spectre/issues/167">issue</a> for <a href="https://github.com/jcfitzpatrick12/spectre"><em>Spectre</em></a>, a Python program for recording radio spectrograms with software-defined radios. The motivation for the issue was to remove <a href="https://scipy.org/">Scipy</a> as dependency from a Python package used by the program called <a href="https://github.com/jcfitzpatrick12/spectre-core">spectre-core</a>.</p><p>The <a href="https://github.com/jcfitzpatrick12/spectre-core/pull/52">PR</a> introduced no changes from the perspective of the public API of the package. It just reimplemented the same functionality for our particular use case. However, we removed Scipy as a dependency since it was no longer required. Under <a href="https://semver.org/">semantic versioning</a>, would this constitute a major, minor or patch bump?</p><p>I considered making this a major bump, since any consumer of the package relying on Scipy being a transitive dependency would see a breaking change. But since the Scipy functionality wasn&#39;t exposed publically, I didn&#39;t think this argument was strong enough and so opted for a minor bump. What would you do?</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 04 Sep 2025 01:35:24 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n7e1oa/zuban_is_now_open_source/</link><title>Zuban is now Open Source</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n7e1oa/zuban_is_now_open_source/</guid><comments>https://www.reddit.com/r/Python/comments/1n7e1oa/zuban_is_now_open_source/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n7e1oa/zuban_is_now_open_source/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Zuban, the successor of Jedi is now Open Source: <a href="https://github.com/zubanls/zuban">https://github.com/zubanls/zuban</a></p><p>Zuban is a high-performance Python Language Server and type checker implemented in Rust, by the author of Jedi. Zuban is 20–200× faster than Mypy, while using roughly half the memory and CPU compared to Ty and Pyrefly. It offers both a PyRight-like mode and a Mypy-compatible mode, which behaves just like Mypy; supporting the same config files, command-line flags, and error messages.</p><p>Most important LSP features are supported. Features include diagnostics, completions, goto, references, rename, hover and document highlights.</p><p>Zuban passes over 95% of Mypy’s relevant test suite and offers comprehensive support for Python&#39;s <a href="https://htmlpreview.github.io/?https://github.com/python/typing/blob/main/conformance/results/results.html">type system</a>.</p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 03 Sep 2025 18:25:41 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n75r76/contribution_of_python_to_the_world_is_underrated/</link><title>contribution of python to the world is underrated…</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n75r76/contribution_of_python_to_the_world_is_underrated/</guid><comments>https://www.reddit.com/r/Python/comments/1n75r76/contribution_of_python_to_the_world_is_underrated/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n75r76/contribution_of_python_to_the_world_is_underrated/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>found this on youtube scrolling, <a href="https://youtu.be/DRU-0tHOayc">https://youtu.be/DRU-0tHOayc</a></p><p>found it good at explaining how we got here…from first neuron’s birth to chatGPT, then the thought just struck me, none of it would have been possible without python…much of the world, still not aware about the contribution. Python has done so much in making lives of humans better in every possible way…</p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 03 Sep 2025 10:19:03 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n6xw8z/meet_thoad_high_order_derivatives_for_pytorch/</link><title>Meet THOAD, High Order Derivatives for PyTorch Graphs</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n6xw8z/meet_thoad_high_order_derivatives_for_pytorch/</guid><comments>https://www.reddit.com/r/Python/comments/1n6xw8z/meet_thoad_high_order_derivatives_for_pytorch/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 9 min | <a href='https://www.reddit.com/r/Python/comments/1n6xw8z/meet_thoad_high_order_derivatives_for_pytorch/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I’m excited to share <strong>thoad</strong> (short for Py<strong>T</strong>orch <strong>H</strong>igh <strong>O</strong>rder <strong>A</strong>utomatic <strong>D</strong>ifferentiation), a Python only library that computes arbitrary order partial derivatives directly on a PyTorch computational graph. The package has been developed within a research project at Universidad Pontificia de Comillas (ICAI), and we are considering publishing an academic article in the future that reviews the mathematical details and the implementation design.</p><p>At its core, thoad takes a one output to many inputs view of the graph and pushes high order derivatives back to the leaf tensors. Although a 1→N problem can be rewritten as 1→1 by concatenating flattened inputs, as in functional approaches such as <code>jax.jet</code> or <code>functorch</code>, thoad’s graph aware formulation enables an optimization based on <strong>unifying independent dimensions</strong> (especially batch). This delivers <strong>asymptotically better scaling</strong> with respect to batch size. Additionally, we compute derivatives <strong>vectorially</strong> rather than component by component, which is what makes a pure PyTorch implementation practical without resorting to custom C++ or CUDA.</p><p>The package is <strong>easy to maintain</strong>, because it is written entirely in Python and uses <strong>PyTorch</strong> as its only dependency. The implementation stays at a high level and leans on PyTorch’s vectorized operations, which means no custom C++ or CUDA bindings, no build systems to manage, and fewer platform specific issues.</p><p>The package can be installed from <strong>GitHub</strong> or <strong>PyPI</strong>:</p><ul><li>GitHub: <a href="https://github.com/mntsx/thoad">https://github.com/mntsx/thoad</a></li><li>PyPI: <a href="https://pypi.org/project/thoad/">https://pypi.org/project/thoad/</a></li></ul><p>In our benchmarks, <strong>thoad outperforms</strong> <code>torch.autograd</code> <strong>for Hessian calculations even on CPU</strong>. See the notebook that reproduces the comparison: <a href="https://github.com/mntsx/thoad/blob/master/examples/benchmarks/benchmark%5C_vs%5C_torch%5C_autograd.ipynb">https://github.com/mntsx/thoad/blob/master/examples/benchmarks/benchmark\_vs\_torch\_autograd.ipynb</a>.</p><p>The user experience has been one of our main concerns during development. <strong>thoad</strong> is designed to align closely with PyTorch’s interface philosophy, so running the high order backward pass is practically indistinguishable from calling PyTorch’s own <code>backward</code>. When you need finer control, you can keep or reduce Schwarz symmetries, group variables to restrict mixed partials, and fetch the exact mixed derivative you need. Shapes and independence metadata are also exposed to keep interpretation straightforward.</p><h1>USING THE PACKAGE</h1><p><strong>thoad</strong> exposes two primary interfaces for computing high-order derivatives:</p><ol><li><code>thoad.backward</code>: a function-based interface that closely resembles <code>torch.Tensor.backward</code>. It provides a quick way to compute high-order gradients without needing to manage an explicit controller object, but it offers only the core functionality (derivative computation and storage).</li><li><code>thoad.Controller</code>: a class-based interface that wraps the output tensor’s subgraph in a controller object. In addition to performing the same high-order backward pass, it gives access to advanced features such as fetching specific mixed partials, inspecting batch-dimension optimizations, overriding backward-function implementations, retaining intermediate partials, and registering custom hooks.</li></ol><p><strong>thoad.backward</strong></p><p>The <code>thoad.backward</code> function computes high-order partial derivatives of a given output tensor and stores them in each leaf tensor’s <code>.hgrad</code> attribute.</p><p><strong>Arguments</strong>:</p><ul><li><code>tensor</code>: A PyTorch tensor from which to start the backward pass. This tensor must require gradients and be part of a differentiable graph.</li><li><code>order</code>: A positive integer specifying the maximum order of derivatives to compute.</li><li><code>gradient</code>: A tensor with the same shape as <code>tensor</code> to seed the vector-Jacobian product (i.e., custom upstream gradient). If omitted, the default is used.</li><li><code>crossings</code>: A boolean flag (default=<code>False</code>). If set to <code>True</code>, mixed partial derivatives (i.e., derivatives that involve more than one distinct leaf tensor) will be computed.</li><li><code>groups</code>: An iterable of disjoint groups of leaf tensors. When <code>crossings=False</code>, only those mixed partials whose participating leaf tensors all lie within a single group will be calculated. If <code>crossings=True</code> and <code>groups</code> is provided, a <em>ValueError</em> will be raised (they are mutually exclusive).</li><li><code>keep_batch</code>: A boolean flag (default=<code>False</code>) that controls how output dimensions are organized in the computed gradients.<ul><li><strong>When</strong> <code>keep_batch=False</code>**:** Gradients are returned in a fully flattened form. Concretely, think of the gradient tensor as having:<ul><li>A single “output” axis that lists every element of the original output tensor (flattened into one dimension).</li><li>One axis per derivative order, each listing every element of the corresponding input (also flattened).</li></ul></li><li>For an N-th order derivative of a leaf tensor with <code>input_numel</code> elements and an output with <code>output_numel</code> elements, the gradient shape is:<ul><li><strong>Axis 1:</strong> indexes all <code>output_numel</code> outputs</li><li><strong>Axes 2…(N+1):</strong> each indexes all <code>input_numel</code> inputs</li></ul></li><li><strong>When</strong> <code>keep_batch=True</code>**:** Gradients preserve both a flattened “output” axis and each original output dimension before any input axes. You can visualize it as:<ul><li><strong>Axis 1</strong> flattens all elements of the output tensor (size = <code>output_numel</code>).</li><li><strong>Axes 2...(k+1)</strong> correspond to dimensions shared by multiple input tensors and treated independently throughout the graph. These are dimensions that are only operated on element-wise (e.g. batch dimensions).</li><li><strong>Axes (k+2)...(k+N+1)</strong> each flatten all <code>input_numel</code> elements of the leaf tensor, one axis per derivative order.</li></ul></li></ul></li><li><code>keep_schwarz</code>: A boolean flag (default=<code>False</code>). If <code>True</code>, symmetric (Schwarz) permutations are retained explicitly instead of being canonicalized/reduced—useful for debugging or inspecting non-reduced layouts.</li></ul><p><strong>Returns</strong>:</p><ul><li>An instance of <code>thoad.Controller</code> wrapping the same tensor and graph</li></ul><p>Executing the automatic differentiation via <code>thoad.backprop</code> looks like this.</p><pre><code>import torchimport thoadfrom torch.nn import functional as F#### Normal PyTorch workflowX = torch.rand(size=(10,15), requires_grad=True)Y = torch.rand(size=(15,20), requires_grad=True)Z = F.scaled_dot_product_attention(query=X, key=Y.T, value=Y.T)#### Call thoad backwardorder = 2thoad.backward(tensor=Z, order=order)#### Checks## check derivative shapesfor o in range(1, 1 + order):   assert X.hgrad[o - 1].shape == (Z.numel(), *(o * tuple(X.shape)))   assert Y.hgrad[o - 1].shape == (Z.numel(), *(o * tuple(Y.shape)))## check first derivatives (jacobians)fn = lambda x, y: F.scaled_dot_product_attention(x, y.T, y.T)J = torch.autograd.functional.jacobian(fn, (X, Y))assert torch.allclose(J[0].flatten(), X.hgrad[0].flatten(), atol=1e-6)assert torch.allclose(J[1].flatten(), Y.hgrad[0].flatten(), atol=1e-6)## check second derivatives (hessians)fn = lambda x, y: F.scaled_dot_product_attention(x, y.T, y.T).sum()H = torch.autograd.functional.hessian(fn, (X, Y))assert torch.allclose(H[0][0].flatten(), X.hgrad[1].sum(0).flatten(), atol=1e-6)assert torch.allclose(H[1][1].flatten(), Y.hgrad[1].sum(0).flatten(), atol=1e-6)</code></pre><p><strong>Instantiation</strong></p><p>Use the constructor to create a controller for any tensor requiring gradients:</p><pre><code>controller = thoad.Controller(tensor=GO)  ## takes graph output tensor</code></pre><ul><li><code>tensor</code>: A PyTorch <code>Tensor</code> with <code>requires_grad=True</code> and a non-<code>None</code> <code>grad_fn</code>.</li></ul><p><strong>Properties</strong></p><ul><li><code>.tensor → Tensor</code> The output tensor underlying this controller. <strong>Setter</strong>: Replaces the tensor (after validation), rebuilds the internal computation graph, and invalidates any previously computed gradients.</li><li><code>.compatible → bool</code> Indicates whether every backward function in the tensor’s subgraph has a supported high-order implementation. If <code>False</code>, some derivatives may fall back or be unavailable.</li><li><code>.index → Dict[Type[torch.autograd.Function], Type[ExtendedAutogradFunction]]</code> A mapping from base PyTorch <code>autograd.Function</code> classes to thoad’s <code>ExtendedAutogradFunction</code> implementations. <strong>Setter</strong>: Validates and injects your custom high-order extensions.</li></ul><p><strong>Core Methods</strong></p><p><strong>.backward(order, gradient=None, crossings=False, groups=None, keep_batch=False, keep_schwarz=False) → None</strong></p><p>Performs the high-order backward pass up to the specified derivative <code>order</code>, storing all computed partials in each leaf tensor’s <code>.hgrad</code> attribute.</p><ul><li><code>order</code> (<code>int &gt; 0</code>): maximum derivative order.</li><li><code>gradient</code> (<code>Optional[Tensor]</code>): custom upstream gradient with the same shape as <code>controller.tensor</code>.</li><li><code>crossings</code> (<code>bool</code>, default <code>False</code>): If <code>True</code>, mixed partial derivatives across different leaf tensors will be computed.</li><li><code>groups</code> (<code>Optional[Iterable[Iterable[Tensor]]]</code>, default <code>None</code>): When <code>crossings=False</code>, restricts mixed partials to those whose leaf tensors all lie within a single group. If <code>crossings=True</code> and <code>groups</code> is provided, a <em>ValueError</em> is raised.</li><li><code>keep_batch</code> (<code>bool</code>, default <code>False</code>): controls whether independent output axes are kept separate (batched) or merged (flattened) in stored/retrieved gradients.</li><li><code>keep_schwarz</code> (<code>bool</code>, default <code>False</code>): if <code>True</code>, retains symmetric permutations explicitly (no Schwarz reduction).</li></ul><p><strong>.display_graph() → None</strong></p><p>Prints a tree representation of the tensor’s backward subgraph. Supported nodes are shown normally; unsupported ones are annotated with <code>(not supported)</code>.</p><p><strong>.register_backward_hook(variables: Sequence[Tensor], hook: Callable) → None</strong></p><p>Registers a user-provided <code>hook</code> to run during the backward pass whenever gradients for any of the specified leaf <code>variables</code> are computed.</p><ul><li><code>variables</code> (<code>Sequence[Tensor]</code>): Leaf tensors to monitor.</li><li><code>hook</code> (<code>Callable[[Tuple[Tensor, Tuple[Shape, ...], Tuple[Indep, ...]], dict[AutogradFunction, set[Tensor]]], Tuple[Tensor, Tuple[Shape, ...], Tuple[Indep, ...]]]</code>): Receives the current <code>(Tensor, shapes, indeps)</code> plus contextual info, and must return the modified triple.</li></ul><p><strong>.require_grad_(variables: Sequence[Tensor]) → None</strong></p><p>Marks the given leaf <code>variables</code> so that all intermediate partials involving them are retained, even if not required for the final requested gradients. Useful for inspecting or re-using higher-order intermediates.</p><p><strong>.fetch_hgrad(variables: Sequence[Tensor], keep_batch: bool = False, keep_schwarz: bool = False) → Tuple[Tensor, Tuple[Tuple[Shape, ...], Tuple[Indep, ...], VPerm]]</strong></p><p>Retrieves the precomputed high-order partial corresponding to the ordered sequence of leaf <code>variables</code>.</p><ul><li><code>variables</code> (<code>Sequence[Tensor]</code>): the leaf tensors whose mixed partial you want.</li><li><code>keep_batch</code> (<code>bool</code>, default <code>False</code>): if <code>True</code>, each independent output axis remains a separate batch dimension in the returned tensor; if <code>False</code>, independent axes are distributed/merged into derivative dimensions.</li><li><code>keep_schwarz</code> (<code>bool</code>, default <code>False</code>): if <code>True</code>, returns derivatives retaining symmetric permutations explicitly.</li></ul><p>Returns a pair:</p><ol><li><strong>Gradient tensor</strong>: the computed partial derivatives, shaped according to output and input dimensions (respecting <code>keep_batch</code>/<code>keep_schwarz</code>).</li><li><strong>Metadata tuple</strong><ul><li><strong>Shapes</strong> (<code>Tuple[Shape, ...]</code>): the original shape of each leaf tensor.</li><li><strong>Indeps</strong> (<code>Tuple[Indep, ...]</code>): for each variable, indicates which output axes remained independent (batch) vs. which were merged into derivative axes.</li><li><strong>VPerm</strong> (<code>Tuple[int, ...]</code>): a permutation that maps the internal derivative layout to the requested <code>variables</code> order.</li></ul></li></ol><p>Use the combination of independent-dimension info and shapes to reshape or interpret the returned gradient tensor in your workflow.</p><pre><code>import torchimport thoadfrom torch.nn import functional as F#### Normal PyTorch workflowX = torch.rand(size=(10,15), requires_grad=True)Y = torch.rand(size=(15,20), requires_grad=True)Z = F.scaled_dot_product_attention(query=X, key=Y.T, value=Y.T)#### Instantiate thoad controller and call backwardorder = 2controller = thoad.Controller(tensor=Z)controller.backward(order=order, crossings=True)#### Fetch Partial Derivatives## fetch X and Y 2nd order derivativespartial_XX, _ = controller.fetch_hgrad(variables=(X, X))partial_YY, _ = controller.fetch_hgrad(variables=(Y, Y))assert torch.allclose(partial_XX, X.hgrad[1])assert torch.allclose(partial_YY, Y.hgrad[1])## fetch cross derivativespartial_XY, _ = controller.fetch_hgrad(variables=(X, Y))partial_YX, _ = controller.fetch_hgrad(variables=(Y, X))</code></pre><blockquote><p>NOTE. A more detailed user guide with examples and feature walkthroughs is available in the notebook: <a href="https://github.com/mntsx/thoad/blob/master/examples/user_guide.ipynb">https://github.com/mntsx/thoad/blob/master/examples/user_guide.ipynb</a></p></blockquote><p>If you give it a try, I would love feedback on the API.</p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 03 Sep 2025 04:07:59 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n6v3tl/pyline_update_terminal_based_text_editor_linux/</link><title>PyLine Update - terminal based text editor (Linux, WSL, MacOS) (New Feats)</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n6v3tl/pyline_update_terminal_based_text_editor_linux/</guid><comments>https://www.reddit.com/r/Python/comments/1n6v3tl/pyline_update_terminal_based_text_editor_linux/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n6v3tl/pyline_update_terminal_based_text_editor_linux/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hello, this is a hobby project I coded entirely in Python 3 , created longer time ago. But came back to it this spring. Now updated with new functionality and better code structure currently at v0.9.7.</p><p>Source at - <a href="https://github.com/Peter-L-SVK/PyLine">PyLine GitHub repo</a>  (you can see screenshots in readme)</p><h1>What My Project Does:</h1><p>It is CLI text editor with:<br/>- function like wc - cw - counts chars, words and lines<br/>- open / create / truncate file<br/>- exec mode that is like file browser and work with directories<br/>- scroll-able text-buffer, currently set to 52 lines<br/>- supports all clipboards for GUI: X11,Wayland, win32yank for WSL and pbpaste for MacOS<br/>- multiple lines selection copy/paste/overwrite and delete<br/>- edit history implemented via LIFO - Last In First Out (limit set to 120)<br/>- highlighting of .py syntax (temporary tho, will find the better way)<br/>- comes with proper install script</p><h1>New features:</h1><p>- Support of args &lt;filename&gt;, -i/--info and -h/--help<br/>- Modular hooks system with priority, runtime enable/disable, cross-language support (Python, Perl, Bash, Ruby, Lua, Node.js, PHP)<br/>- Hook manager UI (list, enable/disable, reload hooks, show info)<br/>- BufferManager, NavigationManager, SelectionManager, PasteBuffer, UndoManager all refactored for composition and extensibility (micro-kernel like architecture)<br/>- Hook-enabled file loading/saving, multi-language event handlers<br/>- Enhanced config and state management (per-user config dir)<br/>- Improved argument parsing and info screens</p><p>It also comes with prepackaged hooks like smart tab indent.</p><p>The editor is using built-in to the terminal foreground/background but I plan to implement themes and config.ini alongside search / replace feature.</p><h1>Target Audience:</h1><p>Basically anyone with Linux, WSL or other Unix-like OS. Nothing complicated to use.</p><p>(I know it&#39;s not too much.. I don&#39;t have any degree in CS or IT engineering or so, just passion)</p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 03 Sep 2025 02:16:35 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n658es/is_it_a_good_idea_to_teach_students_python_but/</link><title>Is it a good idea to teach students Python but using an old version?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n658es/is_it_a_good_idea_to_teach_students_python_but/</guid><comments>https://www.reddit.com/r/Python/comments/1n658es/is_it_a_good_idea_to_teach_students_python_but/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n658es/is_it_a_good_idea_to_teach_students_python_but/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>EDIT: Talking about IDLE here</p><p>Sorry if this is the wrong sub.</p><p>When i went to high school (UK) in 2018, we had 3.4.2 (which at the time wasn&#39;t even the latest 3.4.x). In 2020 they upgraded to 3.7, but just days later downgraded back to 3.4.2. I asked IT manager why and they said its because of older students working on long projects. But doubt that was the reason because fast forward to 2023 the school still had 3.4.2 which was end of life.</p><p>Moved to a college that same year that had 3.12, but this summer 2025, after computer upgrades to windows 11, we are now on 3.10 for some reason. I start a new year in college today so I&#39;ll be sure to ask the teacher.</p><p>Are there any drawbacks to teaching using an old version? It will just be the basics and a project or 2</p></div><!-- SC_ON --></section>]]></description><pubDate>Tue, 02 Sep 2025 05:51:40 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n64bla/i_built_a_simple_opensource_windows_wallpaper/</link><title>I built a simple, open-source Windows wallpaper changer because the built-in one kept failing.</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n64bla/i_built_a_simple_opensource_windows_wallpaper/</guid><comments>https://www.reddit.com/r/Python/comments/1n64bla/i_built_a_simple_opensource_windows_wallpaper/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n64bla/i_built_a_simple_opensource_windows_wallpaper/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><h1>What My Project Does</h1><p>This is a simple, lightweight desktop application for Windows that automatically changes your desktop wallpaper from a folder of images. You can choose a folder, set a custom time interval (in seconds, minutes, or hours), and have your pictures shuffle randomly. It can be minimized to the system tray. The application is built using <code>customtkinter</code> for the GUI and <code>pystray</code> for the system tray functionality.</p><h1>Target Audience</h1><p>I write it for personal use and for anyone who wants a simple and minimalist way to manage their desktop wallpapers. It is a &quot;toy project&quot; in the sense that it started as a solution to a personal frustration, but it is meant to be a tool for everyday use.</p><h1>Comparison</h1><p>I wrote this because the built-in Windows slideshow feature randomly stops working, which is incredibly frustrating and annoying, and they have been too lazy to fix it. Other third-party programs I looked at were often too cluttered with features I didn&#39;t need and/or were also resource-hungry. This application is meant to be a clean, minimal alternative that focuses on its single task.</p><p>You can find it here: <a href="https://github.com/m-sarabi/wallpaper_changer/releases/tag/v1.0.0">Wallpaper Changer</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Tue, 02 Sep 2025 05:08:36 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n5ux0w/python_ocr_automatically_analyze_dota_2_player/</link><title>Python + OCR: Automatically analyze Dota 2 player stats 👀</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n5ux0w/python_ocr_automatically_analyze_dota_2_player/</guid><comments>https://www.reddit.com/r/Python/comments/1n5ux0w/python_ocr_automatically_analyze_dota_2_player/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n5ux0w/python_ocr_automatically_analyze_dota_2_player/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><h1>What My Project Does</h1><p>This Python script uses OCR to read Dota 2 friend IDs from your screen, fetches match data from the OpenDota API, and calculates winrates and most played heroes to detect potential smurfs.<br/>It provides a simple GUI that shows overall winrate and the most played hero of the selected player.</p><h1>Target Audience</h1><p>Python enthusiasts, Dota 2 players, or anyone interested in game data analysis and automation.<br/>This is mainly an educational and experimental project, not intended for cheating or modifying the game.</p><h1>Comparison</h1><p>Unlike other Dota 2 analytics tools, this script uses OCR to automatically read friend IDs from the screen, eliminating the need to manually input player IDs.<br/>It combines GUI feedback, Python automation, and API integration in a single lightweight tool.</p><p><a href="https://github.com/N3uvin/opendota2-vision">GitHub Repository</a></p><p><strong><em>I’m open to feedback, feature suggestions, or any ideas to improve the script!</em></strong></p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 01 Sep 2025 22:55:57 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n5q8n0/introducing_dltype_an_ultrafast_runtime_type_and/</link><title>Introducing DLType, an ultra-fast runtime type and shape checking library for deep learning tensors!</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n5q8n0/introducing_dltype_an_ultrafast_runtime_type_and/</guid><comments>https://www.reddit.com/r/Python/comments/1n5q8n0/introducing_dltype_an_ultrafast_runtime_type_and/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n5q8n0/introducing_dltype_an_ultrafast_runtime_type_and/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><h1>What My Project Does</h1><p>DL (Deep-learning) Typing, a runtime shape and type checker for your pytorch tensors or numpy arrays! No more guessing what the shape or data type of your tensors are for your functions. Document tensor shapes using familiar syntax and take the guesswork out of tensor manipulations.</p><p><code>python@dltyped()def transform_tensors(    points: Annotated[np.ndarray, FloatTensor[&quot;N 3&quot;]]    transform: Annotated[torch.Tensor, IntTensor[&quot;3 3&quot;]]) -&gt; Annotated[torch.Tensor, FloatTensor[&quot;N 3&quot;]]:    return torch.from_numpy(points) @ transform</code></p><h1>Target Audience</h1><p>Machine learning engineers primarily, but anyone who uses numpy may find this useful too! </p><h1>Comparison</h1><ul><li>Jaxtyping-inspired syntax for expressions, literals, and anonymous axes</li><li>Supports any version of pytorch and numpy (Python &gt;=3.10)</li><li>First class Pydantic model support, shape and dtype validation directly in model definitions</li><li>Dataclass, named tuple, function, and method checking </li><li>Lightweight and fast, benchmarked to be on-par with manual shape checking and (at least last time we tested it) was as-fast or faster than the current de-facto solution of Jaxtyping + beartype, in some cases by an order of magnitude.</li><li>Custom tensor types, define your own tensor type and override the check method with whatever custom logic you need</li></ul><p>GitHub Page: <a href="https://github.com/stackav-oss/dltype">https://github.com/stackav-oss/dltype</a></p><p><code>pip install dltype</code></p><p>Check it out and let me know what you think! </p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 01 Sep 2025 20:00:17 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n5jjnl/update_docstrange_structured_data_extraction_from/</link><title>[UPDATE] DocStrange - Structured data extraction from images/pdfs/docs</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n5jjnl/update_docstrange_structured_data_extraction_from/</guid><comments>https://www.reddit.com/r/Python/comments/1n5jjnl/update_docstrange_structured_data_extraction_from/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n5jjnl/update_docstrange_structured_data_extraction_from/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I previously shared the open‑source library DocStrange. Now I have hosted it as a free to use web app to upload pdfs/images/docs to get clean structured data in Markdown/CSV/JSON/Specific-fields and other formats.</p><p><strong>Live Demo:</strong> <a href="https://docstrange.nanonets.com/"><strong>https://docstrange.nanonets.com</strong></a></p><p><strong>Github :</strong> <a href="https://github.com/NanoNets/docstrange"><strong>https://github.com/NanoNets/docstrange</strong></a></p><p>Would love to hear feedbacks!</p><p>Original Post : <a href="https://www.reddit.com/r/Python/comments/1mh914m/open_source_tool_for_structured_data_extraction/">https://www.reddit.com/r/Python/comments/1mh914m/open_source_tool_for_structured_data_extraction/</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 01 Sep 2025 14:19:32 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n562vq/my_first_kinda_complicated_code_started_like_a/</link><title>My first kinda complicated code (started like a month ago)</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n562vq/my_first_kinda_complicated_code_started_like_a/</guid><comments>https://www.reddit.com/r/Python/comments/1n562vq/my_first_kinda_complicated_code_started_like_a/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n562vq/my_first_kinda_complicated_code_started_like_a/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>WHAT MY PROJECT DOESI have made a card game where you are against a bot, and is trying to be the first to have only one Card left. </p><p>TARGET AUDIENCEThis is just a project I made for fun, but I hope some people who are new to Python, or is interested in small text based games Will like this.</p><p>COMPARISONI haven&#39;t seen any project like this, and I at least hope there aren&#39;t any. I feel this is a unique fun card game.</p><p>GitHub link:<a href="https://github.com/Simonkamon11/One-Card.git">https://github.com/Simonkamon11/One-Card.git</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 01 Sep 2025 02:34:57 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n54kbx/django_vs_fastapi_for_saas_with_heavy/</link><title>Django vs FastAPI for SaaS with heavy transactions + AI integrations?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n54kbx/django_vs_fastapi_for_saas_with_heavy/</guid><comments>https://www.reddit.com/r/Python/comments/1n54kbx/django_vs_fastapi_for_saas_with_heavy/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n54kbx/django_vs_fastapi_for_saas_with_heavy/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I’m building a SaaS that processes lots of transactions, handles AI-driven communications, and integrates with multiple external APIs.</p><p>Would you start with Django for quick ramp up or FastAPI for long-term flexibility? Is Django feasible for my use case? While FastAPI seems to be better due to async, my lack of experience with prod grade DB management makes Django seem good too, due to things such as automated migrations and the in built ORM. Current setup is FastAPI + SQLAlchemy and Alembic.</p><ol><li>Anyone successfully combine them, Django for the monolith, FastAPI for specific endpoints?</li></ol></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 01 Sep 2025 01:33:48 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n4v2zm/gendual_python_library_for_highorder_partial/</link><title>gen-dual: Python library for high-order partial derivatives with dual numbers</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n4v2zm/gendual_python_library_for_highorder_partial/</guid><comments>https://www.reddit.com/r/Python/comments/1n4v2zm/gendual_python_library_for_highorder_partial/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n4v2zm/gendual_python_library_for_highorder_partial/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>What My Project Does:</strong><br/>gen-dual is a Python library for vectorized computation of arbitrary-order partial derivatives of multivariable functions. It supports complex numbers and many functions like LambertW, Gamma, InverseErf, and Abs. Derivatives are computed all at once using a dual-number-like method, useful for analyzing Taylor series, function behavior, or any derivative-related computations.</p><p><strong>Target Audience:</strong><br/>This library is meant for anyone interested in exploring high-precision, multi-variable differentiation in Python, including researchers, students, or hobbyists.</p><p><strong>Comparison:</strong><br/>Unlike standard automatic differentiation libraries, gen-dual supports arbitrary-order derivatives, full vectorization, complex numbers, and rich function support, making it more flexible than most existing alternatives.</p><p><strong>GitHub Link:</strong><br/><a href="https://github.com/LukaLavs/Generalized-Dual">https://github.com/LukaLavs/Generalized-Dual</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 31 Aug 2025 19:13:57 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n4rahf/just_built_pydanticgsheets_to_bring_google_sheets/</link><title>Just built: pydantic-gsheets to bring Google Sheets and Pydantic together</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n4rahf/just_built_pydanticgsheets_to_bring_google_sheets/</guid><comments>https://www.reddit.com/r/Python/comments/1n4rahf/just_built_pydanticgsheets_to_bring_google_sheets/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n4rahf/just_built_pydanticgsheets_to_bring_google_sheets/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hey everyone,<br/>I have developed a small experimental package called <strong>pydantic-gsheets</strong>.</p><h1>What My Project Does</h1><p><a href="https://github.com/Youssefbenhammouda/pydantic-gsheets">pydantic-gsheets</a> is a small experimental package that lets you read and write Google Sheets data in Python using nothing but Pydantic models. Define a BaseModel, and you can validate, parse, and sync data with Sheets without extra boilerplate.</p><h1>Target Audience</h1><p>It’s meant for quick prototypes, small projects, or teams that love using Google Sheets but want type safety when bringing that data into Python. At this stage it’s still <strong>experimental</strong>, so not yet recommended for production — but great for tinkering, demos, or internal tools.</p><h1>Comparison</h1><p>There are other ways to connect Python to Google Sheets (e.g., gspread, pygsheets), but they typically give you raw dicts or lists that you then have to validate manually. The difference here is that pydantic-gsheets plugs directly into <strong>Pydantic BaseModels</strong>, so your schema, validation, and type coercion happen automatically. You don’t have to write glue code.</p><h1>Links</h1><p>Links if you want to peek:<br/>* Blog: [Exploring pydantic-gsheets](<a href="https://youssef.benhammouda.ma/blog/pydantic-gsheets">https://youssef.benhammouda.ma/blog/pydantic-gsheets</a>)</p><p>* Docs: [pydantic-gsheets documentation](<a href="https://youssefbenhammouda.github.io/pydantic-gsheets/">https://youssefbenhammouda.github.io/pydantic-gsheets/</a>)</p><p>* GitHub: [pydantic-gsheets repo](<a href="https://github.com/Youssefbenhammouda/pydantic-gsheets">https://github.com/Youssefbenhammouda/pydantic-gsheets</a>)</p><p>Would love to hear thoughts or ideas if you try it out 🙂</p><p>PS: If you find it useful and want to use it, please know it’s still <strong>experimental</strong>. That also means collaborators are <strong>very welcome,</strong> whether it’s testing, bug reports, or PRs.</p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 31 Aug 2025 15:57:49 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n4qygz/introducing_neosqlite/</link><title>Introducing NeoSQLite</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n4qygz/introducing_neosqlite/</guid><comments>https://www.reddit.com/r/Python/comments/1n4qygz/introducing_neosqlite/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n4qygz/introducing_neosqlite/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>Showcase: NeoSQLite – Use SQLite with a PyMongo-like API</strong></p><p>I&#39;m excited to introduce <strong>NeoSQLite</strong> (<a href="https://github.com/cwt/neosqlite">https://github.com/cwt/neosqlite</a>), a lightweight Python library that brings a PyMongo-compatible interface to SQLite. This means you can interact with SQLite using familiar MongoDB-style syntax—inserting, querying, and indexing JSON-like documents—while still benefiting from SQLite’s simplicity, reliability, and zero configuration.</p><h3>What My Project Does</h3><p>NeoSQLite allows you to:- Use MongoDB-style operations like <code>insert_one</code>, <code>find</code>, <code>update_one</code>, and <code>delete_many</code> with SQLite.- Perform full-text search across multiple languages using the <code>$text</code> operator, powered by an ICU-based tokenizer (via my <a href="https://github.com/cwt/fts5-icu-tokenizer">fts5-icu-tokenizer</a>).- Automatically compress query results using <a href="https://github.com/cwt/quez">quez</a>, reducing memory usage by 50–80% for large result sets.- Work with embedded documents and nested queries, all backed by SQLite’s ACID-compliant storage.</p><p>It’s designed for developers who love MongoDB’s ease of use but want a lightweight, file-based alternative without external dependencies.</p><h3>Target Audience</h3><p>NeoSQLite is ideal for:- Developers building small to medium-sized applications (e.g., CLI tools, desktop apps, IoT devices) where deploying a full MongoDB instance is overkill.- Projects that need a schema-flexible, document-style database but must remain portable and dependency-free.- Prototyping or educational use, where a MongoDB-like interface speeds up development without requiring server setup.- Environments with limited resources, thanks to its memory-efficient result compression.</p><p>It’s not intended to replace MongoDB in high-concurrency, large-scale production systems, but it’s production-ready for lightweight, embedded use cases.</p><h3>Comparison with Existing Alternatives</h3><p>Unlike other SQLite-to-document-store wrappers, NeoSQLite stands out by:- Offering <strong>deep API compatibility with PyMongo</strong>, minimizing the learning curve for developers already familiar with MongoDB.- Supporting <strong>true multilingual full-text search</strong> via ICU (not just ASCII or basic Unicode), which most SQLite FTS solutions lack.- Reducing memory footprint significantly through built-in result compression—something not offered by standard SQLite ORMs like SQLAlchemy or dataset.- Being <strong>zero-configuration and serverless</strong>, unlike MongoDB (which requires a running service) or libraries like TinyDB (which lack indexing, full-text search, or performance optimizations).</p><p>In short, if you’ve ever wished you could use MongoDB’s API with SQLite’s simplicity, NeoSQLite is for you.</p><hr/><p>Feedback and contributions are welcome. Check it out at: <a href="https://github.com/cwt/neosqlite">https://github.com/cwt/neosqlite</a></p><hr/><p>20250903: I’ve made a lot of updates since my last post. Performance has improved thanks to the use of temp table. Please check it out and give it a try!</p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 31 Aug 2025 15:36:58 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n4pitk/intentgraph_opensource_python_library_for_repo/</link><title>IntentGraph – Open-source Python library for repo dependency graphs &amp;amp; clustering</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n4pitk/intentgraph_opensource_python_library_for_repo/</guid><comments>https://www.reddit.com/r/Python/comments/1n4pitk/intentgraph_opensource_python_library_for_repo/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n4pitk/intentgraph_opensource_python_library_for_repo/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hello everybody,</p><p>I started this project out of a pain point I kept hitting: when working with larger repos, it’s easy to lose track of how files connect. And when trying to use automation tools (AI or otherwise), the problem gets worse: once you go past a few files, context just disappears, or the token count explodes every time the tool has to look through the whole codebase.</p><p>That’s what led me to build <strong>IntentGraph</strong>: a Python library to map dependencies and structure repos in a way that’s useful for developers <em>and</em> for programmatic agents.</p><p><strong>What My Project Does</strong></p><p>IntentGraph is a Python library for analyzing large codebases. It:</p><ul><li><p>Maps dependencies between files and modules</p></li><li><p>Clusters code (analysis, refactoring, navigation)</p></li><li><p>Produces structured outputs at 3 levels (minimal → full detail)</p></li><li><p>Designed to be <strong>programmatically queryable</strong>: useful for developers and AI agents that need structured repo context</p></li></ul><p><strong>Target Audience</strong></p><ul><li><p>Developers who want to explore or refactor large Python repos</p></li><li><p>Tool builders needing a structured representation of a codebase</p></li><li><p>Researchers interested in program analysis and code graphing</p></li><li><p>AI/automation workflows that require repo-wide context</p></li></ul><p><strong>Comparison</strong></p><p>Unlike linting/static analysis tools, IntentGraph focuses on structural understanding of the codebase. This structured output makes it lightweight enough for automated tools and AI agents to consume directly.</p><p><strong>Links:</strong></p><p>GitHub: <a href="https://github.com/Raytracer76/IntentGraph">https://github.com/Raytracer76/IntentGraph</a></p><p>PyPI: <a href="https://pypi.org/project/intentgraph/">https://pypi.org/project/intentgraph/</a></p><p><strong>Open Source &amp; Call for Contributions</strong></p><p>IntentGraph is fully open source. I encourage forks, experiments, and extensions — for example, expanding it into other languages (Java, Rust, C#, etc.).I likely won’t drive this much further myself, but I’d love to see where the community takes it.</p><p><strong>Looking for feedback:</strong></p><ul><li><p>What’s missing for practical use in Python projects?</p></li><li><p>Ideas for integrations (e.g., VS Code)?</p></li><li><p>Languages you’d want supported next?</p></li></ul></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 31 Aug 2025 14:03:40 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n4nhbk/my_python_mini_project/</link><title>My python mini project</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n4nhbk/my_python_mini_project/</guid><comments>https://www.reddit.com/r/Python/comments/1n4nhbk/my_python_mini_project/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n4nhbk/my_python_mini_project/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I have made an app that is great for studing python and begginer friendly as well, I would like to introduce you to <code>lisq</code> a single file, lightweight and portable python note-taking app. It would not only serve you as notes but also allow you to add your own functions, advanced searching through out the notes, edit, encrypt and much more (please read README for more information!).</p><p>Official github repository:<a href="https://github.com/funnut/Lisq.git">https://github.com/funnut/Lisq.git</a></p><p>Share &amp; leave a star 🌟</p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 31 Aug 2025 11:53:00 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n4ilwx/pysimplegui_hobbyist_license_canceled/</link><title>PySimpleGUI Hobbyist License Canceled</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n4ilwx/pysimplegui_hobbyist_license_canceled/</guid><comments>https://www.reddit.com/r/Python/comments/1n4ilwx/pysimplegui_hobbyist_license_canceled/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n4ilwx/pysimplegui_hobbyist_license_canceled/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>So I used PySimpleGUI for a single project and received the 30 day free trial assuming Id be able to get the hobbyist version once it was over. Is it crazy to anyone else that it cost $99 to just save a few lines of code considering I can create the same, if not a more customizable GUI using C/C++. My project which wasnt too crazy (firetv remote using adb protocol) is now garbage because I will not pay for the dumb licensing fee, but hey maybe a single person should pay the same amount a billion dollar company pays right???`</p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 31 Aug 2025 07:20:49 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n4hc9e/python_type_system/</link><title>Python type system</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n4hc9e/python_type_system/</guid><comments>https://www.reddit.com/r/Python/comments/1n4hc9e/python_type_system/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n4hc9e/python_type_system/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>(Just sharing something)  </p><p>As someone who has taken advantage of TypeScript&#39;s type safety for most of its career, using Python without type safety feels a bit awkward. I put together a page explaining how to take advantage of Python&#39;s type system and how to extend it on your editor.</p><p><a href="https://crocus-ceres-509.notion.site/How-Python-type-system-works-and-how-to-extend-it-on-your-editor-21e3826aa7ed808b93e2f4d18493c6ea">https://crocus-ceres-509.notion.site/How-Python-type-system-works-and-how-to-extend-it-on-your-editor-21e3826aa7ed808b93e2f4d18493c6ea</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 31 Aug 2025 06:16:58 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n40rht/i_built_my_own_torch_in_the_last_two_weeks/</link><title>I built my own torch in the last two weeks!</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n40rht/i_built_my_own_torch_in_the_last_two_weeks/</guid><comments>https://www.reddit.com/r/Python/comments/1n40rht/i_built_my_own_torch_in_the_last_two_weeks/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n40rht/i_built_my_own_torch_in_the_last_two_weeks/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>What my project does:</strong></p><p>In the last two weeks, I have been working on building my own toy project: a deep learning training framework. It is named &quot;mytorch&quot;. It was written from scratch except that I use cublaslt for high performance matmul operations. Now it can do most of the pytorch stuff:</p><p>- cuda support for forward/backward operators in CNN MNIST training and evaluations, such as, BN, Conv, Linear, many elementwise ops, many reduce ops, many essential ops;</p><p>- SGD optimizer;</p><p>- Load/save state dict for module/optimizer</p><p>- Dataset/DataLoader</p><p>- Autograd system: topsort for backward.</p><p><strong>Target Audience:</strong></p><p>It is a toy project for education.</p><p><strong>Comparison with other products:</strong></p><p>In terms of results, when training MNIST for 3 epochs in my 4060 laptop, PyTorch takes 33 seconds while &quot;mytorch&quot; takes 41 seconds which is just 25% slower. PyTorch is a highly optimized framework for production. But my project is for fun and for learning more about cuda programming/autograd system.</p><p>Please leave a star on my git repo or leave a comment below if you are interested. Thanks so much!<br/><a href="https://github.com/tigert1998/mytorch/tree/main">s://github.com/tigert1998/mytorch/tree/main</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 30 Aug 2025 18:16:54 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n3ne68/pythonbased_magic_the_gathering_commander_deck/</link><title>Python-Based Magic: The Gathering Commander Deck Builder</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n3ne68/pythonbased_magic_the_gathering_commander_deck/</guid><comments>https://www.reddit.com/r/Python/comments/1n3ne68/pythonbased_magic_the_gathering_commander_deck/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 4 min | <a href='https://www.reddit.com/r/Python/comments/1n3ne68/pythonbased_magic_the_gathering_commander_deck/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hi r/Python, I&#39;ve been working off-and-on (mostly off) on a Python-based deck builder for a Magic: the Gathering Commander format. Last week I had a mostly working command line driven version I shared over on those related subs, but this week I&#39;ve got a fleshed out build, this time with a fully-featured web UI.</p><p>This is my first actual software dev release and I&#39;m proud to put it out there.</p><h1>What my Project Does</h1><ul><li>Pick your commander and up to three themes (e.g., Aristocrats, +1/+1, Kindred, Aggro).</li><li>It proposes a clean 100‑card list that fits those themes, with clear stage‑by‑stage reasons.</li><li>Multi‑copy strategies? If your pick supports Persistent Petitioners, Dragon’s Approach, or Shadowborn Apostle, it offers a package. You choose how many, it keeps you at 100, and you can include Thrumming Stone when it makes sense.</li><li>Web: multi‑copy packages are now offered right after commander selection, so there are no surprises later.</li><li>Web: the package is applied first, and land building happens after—counts and targets auto‑adjust so the deck stays clean at 100.</li><li>Web polish: the UI shows when targets were adjusted and if anything was clamped. Small fixes for names with apostrophes.</li></ul><h1>Target Audience</h1><ul><li>Magic: The Gathering fans</li><li>People like me, who like to theorycraft, who like to throw together decks online they may not ever actually use</li><li>People who just want to give a base set of instructions and have something throw a deck together for them</li></ul><h1>Comparison</h1><p>Honestly I&#39;m not sure if there is one or at least that I&#39;ve seen? Obviously EDHRec and Moxfield/Archidekt can help with the deck building, but you generally need to do input every step of the way.</p><p>I originally started working on this last November because I wanted a way to throw a bunch of decks together without needing to do it all manually. At the time I wasn&#39;t really seeing anything Python-based or otherwise that does it in a more hands-off way.</p><p>This way also let&#39;s me throw together a handful of the decks with the same commander, themes, and ideologies, then compare them for differences or see what&#39;s different.</p><h1>Web UI at a glance</h1><ul><li>Mobile support not quite working (landscape get squished), recommended to load from a computer or in portrait mode</li><li>&quot;New Deck” modal: search commander, pick up to 3 themes (AND/OR), choose bracket (not fully implemented), an optional deck name, and the ideal counts for a variety of card types you&#39;ll want in every deck (lands, card draw, wipes, etc...).</li><li>Multi-copy packages: suggests Petitioners/Approach/Apostles when relevant; you pick counts (Thrumming Stone optional). Applied first with auto target tweaks and a 100-card clamp.</li><li>Fast iteration: lock favorites, Replace any pick with alternatives (Owned-only filter), and Rerun Stage to re-roll just creatures/spells/lands (respects locks).</li><li>Use your collection: upload TXT/CSV owned lists; build owned-only or prefer owned. Short owned-only builds get a recommendations file.</li><li>Visual clarity: Mana Curve, Color Pips, and Sources with hover-to-highlight and cross-highlighting; includes colorless ‘C’.</li><li>Exports: TXT for Moxfield/Archidekt, CSV with tags (and Owned column), plus a simple printout.</li><li>Nice-to-use touches: optional virtualized lists for speed, lazy-loaded images, reduced-motion friendly, theme selector, and helpful keyboard shortcuts.</li></ul><h1>Tune and iterate</h1><ul><li>Lock cards you love so reruns keep them.</li><li>Swap any pick for an alternative; filter to owned cards if you want.</li><li>Compare versions side‑by‑side to see what changed.</li></ul><h1>Use your collection</h1><ul><li>Drop TXT/CSV lists of your owned cards.</li><li>Build using only owned cards, or simply prefer owned while still picking the best fits.</li><li>If an owned‑only build runs short, it exports a “recommended pickups” list so you can finish it out.</li></ul><h1>At‑a‑glance clarity</h1><ul><li>Mana curve and color sources summaries with hover‑to‑highlight matching cards.</li><li>CSV export marks which cards you own.</li></ul><h1>Exports</h1><ul><li>TXT ready for Moxfield/Archidekt</li><li>CSV with tags and details</li><li>Simple printable list</li></ul><h1>Try it</h1><ul><li>Live example available here: <a href="https://deck-builder.wiz-ops.com/">https://deck-builder.wiz-ops.com/</a> (do note if you run the setup/tag it will take a few minutes)</li><li>Docker Hub (easiest, opens the Web UI): <a href="https://hub.docker.com/r/mwisnowski/mtg-python-deckbuilder">https://hub.docker.com/r/mwisnowski/mtg-python-deckbuilder</a></li><li>Use the dockerhub-docker-compose.yml file to do it all for you.</li><li>Windows EXE or run from source: see the latest release below.</li></ul><h1>Links</h1><ul><li>Latest release (notes + downloads): <a href="https://github.com/mwisnowski/mtg_python_deckbuilder/releases/latest">https://github.com/mwisnowski/mtg_python_deckbuilder/releases/latest</a></li><li>Source: <a href="https://github.com/mwisnowski/mtg_python_deckbuilder">https://github.com/mwisnowski/mtg_python_deckbuilder</a></li></ul><h1>Roadmap</h1><ul><li>Proper bracket implementation: tighter, consistent power targets across all stages.</li><li>Random modes: “surprise me” overall, random by theme, and one‑click random complete builds.</li><li>Budget mode: soft/hard caps with price tiers and a pickups list that fits a budget.</li><li>Must‑include / must‑exclude lists: lock in pet cards or avoid specific pieces.</li><li>Smarter land bases: basics‑heavy vs. fixing‑heavy profiles guided by curve and color pips.</li><li>Expanded multi‑copy helpers (where legal) with clearer guidance when they’re viable.</li></ul><p>Missing a theme for your favorite commander or found a bug? Issues/PRs welcome.</p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 30 Aug 2025 05:35:10 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n39ov5/what_are_your_tips_to_find_the_newest/</link><title>What are your tips to find the newest libraries/tools?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n39ov5/what_are_your_tips_to_find_the_newest/</guid><comments>https://www.reddit.com/r/Python/comments/1n39ov5/what_are_your_tips_to_find_the_newest/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n39ov5/what_are_your_tips_to_find_the_newest/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>The question is more for your intended use case, but it still stands for improvements I might not even know that I wanted.</p><p>I&#39;ve tried looking through my favorite libraries for documentation updates, listening to podcasts and watching Youtube videos, etc.</p></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 29 Aug 2025 20:27:17 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n324wb/python_feels_easy_until_it_doesnt_what_was_your/</link><title>Python feels easy… until it doesn’t. What was your first real struggle?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n324wb/python_feels_easy_until_it_doesnt_what_was_your/</guid><comments>https://www.reddit.com/r/Python/comments/1n324wb/python_feels_easy_until_it_doesnt_what_was_your/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1n324wb/python_feels_easy_until_it_doesnt_what_was_your/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>When I started Python, I thought it was the easiest language ever… until virtual environments and package management hit me like a truck.</p><p>What was your first ‘Oh no, this isn’t as easy as I thought’ moment with Python?</p></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 29 Aug 2025 14:19:52 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1n2gypa/i_built_a_tool_that_autosyncs_precommit_hook/</link><title>I Built a tool that auto-syncs pre-commit hook versions with `uv.lock`</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1n2gypa/i_built_a_tool_that_autosyncs_precommit_hook/</guid><comments>https://www.reddit.com/r/Python/comments/1n2gypa/i_built_a_tool_that_autosyncs_precommit_hook/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1n2gypa/i_built_a_tool_that_autosyncs_precommit_hook/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>TL;DR:</strong> Auto-sync your pre-commit hook versions with <code>uv.lock</code></p><pre><code># Add this to .pre-commit-config.yaml- repo: https://github.com/tsvikas/sync-with-uv  rev: v0.3.0  hooks:    - id: sync-with-uv</code></pre><p><strong>Benefits:</strong></p><ul><li>Consistent tool versions everywhere (local/pre-commit/CI)</li><li>Zero maintenance</li><li>Keeps pre-commit&#39;s isolation and caching benefits</li><li>Works with <a href="http://pre-commit.ci">pre-commit.ci</a></li></ul><h1>The Problem</h1><p><a href="https://peps.python.org/pep-0735/">PEP 735</a> recommends putting dev tools in <code>pyproject.toml</code> under <code>[dependency-groups]</code>. But if you also use these tools as pre-commit hooks, you get version drift:</p><ul><li><code>uv update</code> bumps <code>black</code> to <code>25.1.0</code> in your lockfile</li><li>Pre-commit still runs <code>black==24.2.0</code></li><li>Result: inconsistent results between local tool and pre-commit.</li></ul><h1>What My Project Does</h1><p>This tool reads your <code>uv.lock</code> and automatically updates <code>.pre-commit-config.yaml</code> to match.</p><p>Works as a pre-commit (see above) or as a one-time run: <code>uvx sync-with-uv</code></p><h1>Target Audience</h1><p>developers using <code>uv</code> and <code>pre-commit</code></p><h1>Comparison </h1><p>❌ Using manual updates?</p><ul><li>Cumbersome</li><li>Easy to forget</li></ul><p>❌ Using  local hooks?</p><pre><code>- repo: local  hooks:    - id: black      entry: uv run black</code></pre><ul><li>Breaks <a href="http://pre-commit.ci">pre-commit.ci</a></li><li>Loses pre-commit&#39;s environment isolation and tool caching</li></ul><p>❌ Removing the tools from <code>pyproject.toml</code>?</p><ul><li>Annoying to repeatedly type <code>pre-commit run black</code></li><li>Can&#39;t pass different CLI flags (<code>ruff --select E501 --fix</code>)</li><li>Some IDE integration breaks (when it requires the tool in your environment)</li><li>Some CI integrations break (like the black action auto-detect of the installed version)</li></ul><p>Similar tools:</p><ul><li><a href="https://github.com/floatingpurr/sync_with_poetry"><code>sync_with_poetry</code></a> - Poetry version</li><li><a href="https://github.com/GabDug/sync-pre-commit-lock"><code>sync-pre-commit-lock</code></a> - PDM/Poetry plugin</li></ul><h1>Try it out: <a href="https://github.com/tsvikas/sync-with-uv">https://github.com/tsvikas/sync-with-uv</a></h1><p>⭐ <strong>Star if it helps!</strong> Issues and PRs welcome. ⭐</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 28 Aug 2025 21:57:48 +0530</pubDate></item></channel></rss>
