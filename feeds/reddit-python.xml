<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><atom:link href="http://192.168.1.132/?platform=reddit&amp;subreddit=Python&amp;averagePostsPerDay=5&amp;content&amp;view=rss" rel="self" type="application/rss+xml"/><title>/r/Python</title><description>Hot posts in /r/Python (roughly 5 posts per day)</description><link>https://www.reddit.com/r/Python/</link><language>en-us</language><lastBuildDate>Wed, 17 Sep 2025 23:50:25 +0000</lastBuildDate><generator>Upvote RSS</generator><image><url>http://192.168.1.132//app/cache/images/styles-redditmedia-com-t5_2qh0y-styles-communityIcon_mkayghu1502d1-144x400.png</url><title>/r/Python</title><link>https://www.reddit.com/r/Python/</link><width>144</width><height>144</height></image><item><link>https://www.reddit.com/r/Python/comments/1nj12yr/do_you_prefer_sticking_to_the_standard_library_or/</link><title>Do you prefer sticking to the standard library or pulling in external packages?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nj12yr/do_you_prefer_sticking_to_the_standard_library_or/</guid><comments>https://www.reddit.com/r/Python/comments/1nj12yr/do_you_prefer_sticking_to_the_standard_library_or/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1nj12yr/do_you_prefer_sticking_to_the_standard_library_or/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I‚Äôve been writing Python for a while and I keep running into this situation. Python‚Äôs standard library is huge and covers so much, but sometimes it feels easier (or just faster) to grab a popular external package from PyPI.</p><p>For example, I‚Äôve seen people write entire data processing scripts with just built-in modules, while others immediately bring in pandas or requests even for simple tasks.</p><p>I‚Äôm curious how you all approach this. Do you try to keep dependencies minimal and stick to the stdlib as much as possible, or do you reach for external packages early to save development time?</p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 17 Sep 2025 07:53:09 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nitzoz/list_of_87_programming_ideas_for_beginners_with/</link><title>List of 87 Programming Ideas for Beginners (with Python implementations)</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nitzoz/list_of_87_programming_ideas_for_beginners_with/</guid><comments>https://www.reddit.com/r/Python/comments/1nitzoz/list_of_87_programming_ideas_for_beginners_with/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1nitzoz/list_of_87_programming_ideas_for_beginners_with/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><a href="https://inventwithpython.com/blog/programming-ideas-beginners-big-book-python.html">https://inventwithpython.com/blog/programming-ideas-beginners-big-book-python.html</a></p><p>I&#39;ve compiled a list of beginner-friendly programming projects, with example implementations in Python. These projects are drawn from my free Python books, but since they only use stdio text, you can implement them in any language.</p><p>I got tired of the copy-paste &quot;1001 project&quot; posts that obviously were copied from other posts or generated by AI which included everything from &quot;make a coin flip program&quot; to &quot;make an operating system&quot;. I&#39;ve personally curated this list to be small enough for beginners. The implementations are all usually under 100 or 200 lines of code.</p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 17 Sep 2025 02:43:35 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1niqudg/let_your_python_agents_play_an_mmo_agenttoagent/</link><title>Let your Python agents play an MMO: Agent-to-Agent protocol + SDK</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1niqudg/let_your_python_agents_play_an_mmo_agenttoagent/</guid><comments>https://www.reddit.com/r/Python/comments/1niqudg/let_your_python_agents_play_an_mmo_agenttoagent/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1niqudg/let_your_python_agents_play_an_mmo_agenttoagent/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>Repo:</strong> <a href="https://github.com/Summoner-Network/summoner-agents">https://github.com/Summoner-Network/summoner-agents</a></p><p><strong>TL;DR:</strong> We are building <strong>Summoner</strong>, a Python SDK with a Rust server for agent-to-agent networking across machines. Early beta (beta version 1.0).</p><p><strong>What my project does:</strong> A protocol for live agent interaction with a desktop app to track network-wide agent state (battles, collaborations, reputation), so you can build MMO-style games, simulations, and tools.</p><p><strong>Target audience:</strong> Students, indie devs, and small teams who want to build networked multi-agent projects, simulations, or MMO-style experiments in Python.</p><p><strong>Comparison:</strong></p><ul><li>LangChain and CrewAI are app frameworks and an API spec for serving agents, not an on-the-wire interop protocol;</li><li>Google A2A is an HTTP-based spec that uses JSON-RPC by default (with optional gRPC or REST);</li><li>MCP standardizes model-to-tool and data connections.</li><li><strong>Summoner</strong> targets live, persistent agent-to-agent networking for MMO-style coordination.</li></ul><p><strong>Status</strong></p><p>Our Beta 1.0. works with example agents today. Expect sharp edges.</p><p><strong>More</strong></p><p>Github page: <a href="https://github.com/Summoner-Network">https://github.com/Summoner-Network</a></p><p>Docs/design notes: <a href="https://github.com/Summoner-Network/summoner-docs">https://github.com/Summoner-Network/summoner-docs</a></p><p>Core runtime: <a href="https://github.com/Summoner-Network/summoner-core">https://github.com/Summoner-Network/summoner-core</a></p><p>Site: <a href="https://summoner.org">https://summoner.org</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 17 Sep 2025 00:45:17 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nifogm/some_tips_for_beginners_things_you_probably_wish/</link><title>Some tips for beginners (Things you probably wish you knew when you first started)</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nifogm/some_tips_for_beginners_things_you_probably_wish/</guid><comments>https://www.reddit.com/r/Python/comments/1nifogm/some_tips_for_beginners_things_you_probably_wish/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1nifogm/some_tips_for_beginners_things_you_probably_wish/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Maybe the title came out a bit ambiguous, but I‚Äôd really like to get this kind of help and I also hope this post can be useful for others who, like me, are just starting out on their Python journey.</p></div><!-- SC_ON --></section>]]></description><pubDate>Tue, 16 Sep 2025 17:40:26 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1ni81px/has_anyone_been_using_pyrefly/</link><title>Has Anyone Been Using Pyrefly?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1ni81px/has_anyone_been_using_pyrefly/</guid><comments>https://www.reddit.com/r/Python/comments/1ni81px/has_anyone_been_using_pyrefly/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1ni81px/has_anyone_been_using_pyrefly/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Thinking of introducing it at my company as a sort of second linter alongside basedpyright. I think it&#39;ll be good to get it incorporated a bit early so that we can fix whatever bugs it catches as it comes along. It looks to be in a decent state for basic typechecking, and the native django support will be nice as it comes along (compared to mypy).</p></div><!-- SC_ON --></section>]]></description><pubDate>Tue, 16 Sep 2025 10:05:39 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1ni2k4t/starplot_star_charts_and_maps_of_the_sky/</link><title>Starplot - Star charts and maps of the sky</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1ni2k4t/starplot_star_charts_and_maps_of_the_sky/</guid><comments>https://www.reddit.com/r/Python/comments/1ni2k4t/starplot_star_charts_and_maps_of_the_sky/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1ni2k4t/starplot_star_charts_and_maps_of_the_sky/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hey all, I‚Äôd like to introduce <a href="https://starplot.dev/">Starplot</a> ‚Äî a Python library for creating star charts and maps of the sky.</p><p><strong>What My Project Does</strong></p><ul><li>Creates customizable star charts and maps of the night sky</li><li>Allows custom styling for all plotted objects, and includes many color themes</li><li>Supports many map projections and types of plots:<ul><li>Zenith plots that show the whole sky at a specific time and place</li><li>Map plots that show an area of the sky</li><li>Horizon plots that show the sky from a specific cardinal direction</li><li>Optic plots that show what an object looks like through an optic (e.g. telescope, binoculars, etc) at a specific time and place</li></ul></li><li>Includes a built-in database of 2M+ stars and 14,000+ deep sky objects (galaxies, nebulae, star clusters, etc)</li><li>Exports plots to PNG, JPEG, or SVG</li></ul><p><strong>Target Audience</strong></p><ul><li>Anyone interested in astronomy or creating maps of the sky!</li><li>Astrophysicists</li><li>Astronomers</li></ul><p><strong>Comparison</strong> </p><p>Compared to similar projects (e.g. fchart3, astroplan), Starplot supports a lot of customization and has many different plot types.</p><p>---</p><p>Homepage: <a href="https://starplot.dev/">https://starplot.dev/</a></p><p>Example Plots: <a href="https://starplot.dev/examples/">https://starplot.dev/examples/</a></p><p>Source Code: <a href="https://github.com/steveberardi/starplot">https://github.com/steveberardi/starplot</a></p><p>Starplot is still very much a work in progress, and I appreciate any feedback. Also very open to contributors if you want to help out! üòÄ Clear skies! üî≠ ‚ú®</p></div><!-- SC_ON --></section>]]></description><pubDate>Tue, 16 Sep 2025 05:39:48 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nhuk7r/created_python_library_for_time_series/</link><title>Created python library for time series projections. E.g. combining income, inflation, dividends, etc</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nhuk7r/created_python_library_for_time_series/</guid><comments>https://www.reddit.com/r/Python/comments/1nhuk7r/created_python_library_for_time_series/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1nhuk7r/created_python_library_for_time_series/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>GitHub: <a href="https://github.com/TimoKats/pylan">https://github.com/TimoKats/pylan</a></p><p>PyPi: <a href="https://pypi.org/project/pylan-lib/">https://pypi.org/project/pylan-lib/</a></p><h1>What My Project Does</h1><p>Python library for making complex time series projections. E.g. for simulating the combined effect of (increasing) salary, inflation, investment gains, etc, over time. Note, it can also be applied to other domains.</p><h1>Target Audience</h1><p>Data analysts, planners, etc. People that use excel for making projections, but want to move to python.</p><h1>Comparison</h1><p>- SaaS financial planning tools (like ProjectionLab) work through a webUI, whereas here you have access to all the Python magic in the same place as you do your simulation.</p><p>- Excel....</p><p>- Write your own code for this is not super difficult, but this library does provide a good framework of dealing with various schedule types (some of which cron doesn&#39;t support) to get to your analysis more quickly.</p></div><!-- SC_ON --></section>]]></description><pubDate>Tue, 16 Sep 2025 00:22:55 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nhtowu/i_made_a_vs_code_extension_that_insults_you_if/</link><title>I made a vs code extension that insults you if you copy &amp;amp; paste AI generated code</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nhtowu/i_made_a_vs_code_extension_that_insults_you_if/</guid><comments>https://www.reddit.com/r/Python/comments/1nhtowu/i_made_a_vs_code_extension_that_insults_you_if/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1nhtowu/i_made_a_vs_code_extension_that_insults_you_if/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>-on an important note: this project was just for fun, I&#39;m not against using AI to help your coding sessions-</p><p>What my project does:It&#39;s a vs code extension that gives random insults such as &quot;Do you ask GPT what to eat for dinner as well?&quot; to the user if it detects AI generated content. It uses a pretrained transformer-based model for inference (roberta-base-openai-detector), that returns the probability of human and AI writing the given section of text. It was pretty fun to play around with, although not accurate (the model was trained on GPT-2, and not optimized for code, so accuracy is bum), but it was my first time mixing languages together to create something. (In this case typescript and python) It&#39;s interesting how extensions like these are set up, I think it&#39;s valuable for anyone to do pet projects like these.</p><p>Target audience: noone really, just a funny pet project, due to the inaccuracy I wouldn&#39;t recommend it for actual usage (it&#39;s a bit difficult to create something more accurate, these kind of open-source models were trained on texts, not code) </p><p>Comparison: To my knowledge there hasn&#39;t been a vs code extension like this before, but there are several much more accurate detectors available online. </p><p>If anyone wants to check it out, or contribute, please feel free to reach out.</p><p><a href="https://github.com/Tbence132545/Ai-copypaste-insult">https://github.com/Tbence132545/Ai-copypaste-insult</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 15 Sep 2025 23:50:56 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nhn589/i_built_authtuna_a_modern_asyncfirst_security/</link><title>I built AuthTuna, a modern, async-first security framework for FastAPI with hierarchical permissions</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nhn589/i_built_authtuna_a_modern_asyncfirst_security/</guid><comments>https://www.reddit.com/r/Python/comments/1nhn589/i_built_authtuna_a_modern_asyncfirst_security/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1nhn589/i_built_authtuna_a_modern_asyncfirst_security/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hey everyone,</p><p>I built an async security library for FastAPI called AuthTuna to solve some problems I was facing with existing tools.</p><h1>What My Project Does</h1><p>AuthTuna is an async-first security library for FastAPI. It&#39;s not just a set of helpers; it&#39;s a complete foundation for authentication, authorization, and session management. Out of the box, it gives you:</p><ul><li><strong>Fully async</strong> operations built on SQLAlchemy 2.0.</li><li><strong>Hierarchical RBAC</strong> for complex, nested permissions (e.g., <code>Organization -&gt; Project -&gt; Resource</code>), which goes beyond simple roles.</li><li><strong>Secure, server-side sessions</strong> with built-in hijack detection.</li><li>A familiar developer experience using standard FastAPI <code>Depends</code> and Pydantic models.</li></ul><h1>Target Audience</h1><p>This is built for Python developers using FastAPI to create <strong>production-grade applications</strong>. It&#39;s specifically useful for projects that need more complex, granular authorization logic, like multi-tenant SaaS platforms, internal dashboards, or any app where users have different levels of access to specific resources. It is not a toy project and is running in our own production environment.</p><h1>Comparison</h1><p>I built this because I needed a specific combination of features that I couldn&#39;t find together in other libraries.</p><ul><li><strong>vs. FastAPI&#39;s built-in tools:</strong> The built-in security utilities are great low-level primitives. AuthTuna is a higher-level, &quot;batteries-included&quot; framework. You get pre-built user flows, session management, and a full permission system instead of having to build them yourself on top of the primitives.</li><li><strong>vs. FastAPI-Users:</strong> FastAPI-Users is an excellent, popular library. AuthTuna differs mainly in its focus on <strong>hierarchical permissions</strong> and its <strong>session model</strong>. If you need to model complex, multi-level access rules (not just &quot;admin&quot; or &quot;user&quot;) and prefer the security model of stateful, server-side sessions over stateless JWTs, then AuthTuna is a better fit.</li></ul><p>The code is up on GitHub, and feedback is welcome.</p><p><strong>GitHub:</strong> <a href="https://github.com/shashstormer/authtuna"><code>https://github.com/shashstormer/authtuna</code></a></p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 15 Sep 2025 19:49:20 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nhfhcs/3_months_in_python_i_made_my_first_proper_2d_game/</link><title>3 months in Python, I made my first proper 2D game</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nhfhcs/3_months_in_python_i_made_my_first_proper_2d_game/</guid><comments>https://www.reddit.com/r/Python/comments/1nhfhcs/3_months_in_python_i_made_my_first_proper_2d_game/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1nhfhcs/3_months_in_python_i_made_my_first_proper_2d_game/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>What My Project Does:</strong><br/>I‚Äôve been messing with Python for about three months, mostly tutorials and dumb exercises. Finally tried making an actual game, and this is what came out.</p><p>It‚Äôs called <a href="https://github.com/ah4ddd/Hate-Core">Hate-Core</a>. You play as a knight fighting dragons in 2D. There‚Äôs sprites, music, keyboard and touch controls, and a high-score system. Basically my attempt at a Dark Souls-ish vibe, but, you know‚Ä¶ beginner style. Built it with <strong>Pygame</strong>, did the movement, attacks, scoring, and slapped in some sprites and backgrounds.</p><p><strong>Target Audience:</strong><br/>Honestly? Just me learn-ing Python. Not production-ready, just a toy to practice, see what works, and maybe have some fun.</p><p><strong>Comparison:</strong><br/>Way beyond boring number guessing, dice rolls, or quizzes you see from beginners. It‚Äôs an actual 2D game, with visuals, music, and some ‚Äúcombat‚Äù mechanics. Dark Souls-ish but tiny, broken, and beginner-coded.</p><p>I‚Äôd love <strong>honest feedback</strong>, tips, ideas or anything. I know it‚Äôs rough as hell.</p><p>Check it out here: <a href="https://github.com/ah4ddd/Hate-Core">https://github.com/ah4ddd/Hate-Core</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 15 Sep 2025 13:04:37 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nhdt04/i_made_a_terminalbased_game_that_uses_llms_among/</link><title>I made a terminal-based game that uses LLMs -- Among LLMs: You are the Impostor</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nhdt04/i_made_a_terminalbased_game_that_uses_llms_among/</guid><comments>https://www.reddit.com/r/Python/comments/1nhdt04/i_made_a_terminalbased_game_that_uses_llms_among/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1nhdt04/i_made_a_terminalbased_game_that_uses_llms_among/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I made this game in Python (that uses <strong>Ollama</strong> and local <code>gpt-oss:20b</code> / <code>gpt-oss:120b</code> models) that runs directly inside your terminal. TL;DR <strong>above</strong> the example.</p><blockquote><p>Among LLMs turns your <strong>terminal</strong> into a chaotic chatroom playground where <strong>you‚Äôre the only human</strong> <strong>among a bunch of eccentric AI agents</strong>, dropped into a common <em>scenario</em> -- it could be Fantasy, Sci-Fi, Thriller, Crime, or something completely unexpected. Each participant, including you, has a <em>persona</em> and a <em>backstory</em>, and all the AI agents share one common goal -- determine and eliminate the human, through <em>voting</em>. <strong>Your mission: stay hidden, manipulate conversations, and turn the bots against each other with edits, whispers, impersonations, and clever gaslighting</strong>. Outlast everyone, turn chaos to your advantage, and make it to the final two.</p><p>Can you survive the hunt and <em>outsmart</em> the AI ?</p></blockquote><p>Quick Demo: <a href="https://youtu.be/kbNe9WUQe14">https://youtu.be/kbNe9WUQe14</a></p><p>Github: <a href="https://github.com/0xd3ba/among-llms">https://github.com/0xd3ba/among-llms</a> (refer to <code>develop</code> branch for latest updates)</p><p>(<strong>Edit:</strong> Join the <a href="https://www.reddit.com/r/Among_LLMs/">subreddit for Among LLMs</a> if you have any bug reports, issues, feature-requests, suggestions or want to showcase your hilarious moments)</p><ul><li><strong>What my project does:</strong> Uses local Ollama gpt-oss models uniquely in a game setting; Built completely as a terminal-UI based project.</li><li><strong>Target Audience:</strong> Anyone who loves drama and making AI fight each other</li><li><strong>Comparision:</strong> No such project exists yet.</li></ul><h1>Example of a Chatroom (after export)</h1><p>You can <strong>save chatrooms as JSON</strong> and <strong>resume</strong> where you left off later on. <strong>Similarly you can load other&#39;s saved JSON as well</strong>! What&#39;s more, when you save a chatroom, it also exports the chat as a text file. Following is an example of a chatroom I recently had.</p><p><strong>Note(s):</strong></p><ul><li>Might be lengthy, but you&#39;ll get the idea of how these bots behave (lol)</li><li>All agents have personas and backstories, which are not visible in the exported chat</li></ul><p><strong>Example:</strong> <a href="https://pastebin.com/ud7mYmH4">https://pastebin.com/ud7mYmH4</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 15 Sep 2025 11:20:48 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nh3rlv/i_was_terrible_at_studying_so_i_made_a_chrome/</link><title>I was terrible at studying so I made a Chrome extension that forces you to learn programming.</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nh3rlv/i_was_terrible_at_studying_so_i_made_a_chrome/</guid><comments>https://www.reddit.com/r/Python/comments/1nh3rlv/i_was_terrible_at_studying_so_i_made_a_chrome/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 6 min | <a href='https://www.reddit.com/r/Python/comments/1nh3rlv/i_was_terrible_at_studying_so_i_made_a_chrome/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>tldr; I made a free, open-source Chrome extension that helps you study by showing you flashcards while you browse the web. Its algorithm uses spaced repetition and semantic analysis to target your weaknesses and help you learn faster. It started as an SAT tool, but I&#39;ve expanded it for everything, and I have custom flashcard deck suggestions for you guys to learn programming syntax and complex CS topics.</p><p>Hi everyone,</p><p>So, I&#39;m not great at studying, or any good lol. Like when the SATs were coming up in high school, all my friends were getting 1500s, and I was just not, like I couldn&#39;t keep up, and I hated that I couldn&#39;t just sit down and study like them. The only thing I did all day was browse the web and working on coding projects that i would never finish in the first place.</p><p>So, one day, whilst working on a project and contemplating how bad of a person I was for not studying, I decided why not use my only skill, coding, to force me to study.</p><p>At first I wanted to make like a locker that would prevent my from accessing apps until I answered a question, but I only ever open a few apps a day, but what I did do was load hundreds of websites a da, and that&#39;s how the idea flashysurf was born. I didn&#39;t even have a real computer at the time, my laptop broke, so I built the first version as a userscript on my old iPad with a cheap Bluetooth mouse. It basically works like this, it&#39;s a Chrome extension that just randomly pops up with a flashcard every now and then while you&#39;re on YouTube, watching Anime, GitHub, or wherever. You answer it, and you slowly build knowledge without even trying.</p><p>It&#39;s completely free and open source (<a href="https://github.com/MaxDevv/FlashySurf">GitHub link here</a>), and I got a little obsessed with the algorithm  (I&#39;ve been working on this for like 5-6 months now lol). It&#39;s not just random. It uses a combination of psycological techniques to make learning as efficient as possible:</p><ul><li>Dumb Weakness Targeting: Really simple, everytime you get a question wrong, its stored in a list and then later on these quesitons are priorotized that way you work on your weaknesses.</li><li>Intelligent Weakness Targeting: This was one of the biggest updates I made. For my SAT version, I implemented a semantic clustering system that groups questions by topic. So for example, if you get a question about arithmentic wrong, it knows to show you more questions that are semantically similar. Meaning it actively tarkedts your weak areas. The question selection is split 50% new questions, 35% questions similar to ones you&#39;ve failed, and 15% direct review of failed questions.</li><li>Forced Note-Taking: This is in my opinion the most important feature in flashysurf for learning. Basically, if you get a question wrong, you have to write a short note on why you messed up and what you should&#39;ve done instead, before you can close the card. It forces you to actually assess your mistakes and learn from them, instead of just clicking past them.</li></ul><p>At first, it was just for the SAT, and the results were actually really impressive. I personally got my score up 100 points, which is like going from the top 8% to the top 3% (considered a really big improvement), and a lot of my friends and other online users saw 60-100 point increases. So it proved the concept worked, especially for lazy people like me who want to learn without the effort of a formal study session.</p><p>After seeing it work so well, I pushed an update, FlashySurf v2.0, so that anyone can study LITERALLY ANYTHING without having to try. You can create and import your own flashcard decks for any subject.</p><p>The only/biggest caveat about flashysurf is that you need to use it for a bit of time to see results like I used it for 2 months to see that 100 point increase (technically that was an outdated version with far less optimizations, so it should take less time) so you can&#39;t just use it for a test you have tmrw (unless you set it to be like 100% which would mean that a flashcard would appear on every single website).</p><p>It has a few more features that I couldn&#39;t mention here: AI flashcard generation from documents; 30 minute breaks to focus; stats on flashcard collections; and for the SAT, performance reports. (Also if ur wondering why i&#39;m using semicolons, I actually learnt that from studying the SAT using flashysurf lol)</p><p>And for you guys in <a href="https://www.reddit.com/r/python">r/python</a>, I thought this would be perfect for drilling concepts that just need repetition. So, if you go to the flashysurf <a href="https://flashysurf.com/creator">flashcard creator</a> you can actually use the AI flashcard import/maker tool to convert any documents (i.e. programming problems/exercises you have) or your own flashcard decks into flashysurf flashcards. So you can work on complex programming topics like Big O notation, dynamic programming, and graph theory algorithms. Note: You will obviously need the extension to use the cards lol but when you install the extension, you&#39;ll recieve <a href="https://flashysurf.com/onboarding">instructions</a> on creating and importing flashcards, so you don&#39;t gotta memorize any of this.</p><p>You can download it from the Chrome Web Store, link in the website: <a href="https://flashysurf.com/?utm_source=rpst&amp;utm_campaign=rpython">https://flashysurf.com/</a></p><p>I&#39;m still actively working on it (just pushed a bugfix yesterday lol), so I&#39;d love to hear any feedback or ideas you have. Hope it helps you learn something new while you&#39;re procrastinating on your actual work.</p><p>Thanks for reading :D</p><p>Complicance thingy</p><h1>What My Project Does</h1><p>FlashySurf is a free, open-source Chrome extension that helps users learn and study by showing them flashcards as they browse the web. It uses a spaced repetition algorithm with semantic analysis to identify and target a user&#39;s weaknesses. The extension also has features like a &quot;Forced Note-Taking&quot; system to ensure users learn from their mistakes, and it allows for custom flashcard decks so it can be used for any subject.</p><h1>Target Audience</h1><p>FlashySurf is intended for anyone who wants to learn or study new information without the effort of a formal study session. It is particularly useful for students, professionals, or hobbyists who spend a lot of time on the web and want to use that time more productively. It&#39;s a production-ready project that&#39;s been in development for over six months, with a focus on being a long-term learning tool.</p><h1>Comparison</h1><p>While there are other flashcard and spaced repetition tools, FlashySurf stands out by integrating learning directly into a user&#39;s everyday browsing habits. Unlike traditional apps like Anki, which require dedicated study sessions, FlashySurf brings the flashcards to you. Its unique combination of a spaced repetition algorithm with a semantic clustering system means it not only reinforces what you&#39;ve learned but actively focuses on related topics where you are weakest. This approach is designed to help &quot;lazy&quot; learners like me who struggle with traditional study methods.</p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 15 Sep 2025 03:10:42 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1ngy2ha/another_free_python_3_book_files_and_directories/</link><title>Another free Python 3 book - Files and Directories</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1ngy2ha/another_free_python_3_book_files_and_directories/</guid><comments>https://www.reddit.com/r/Python/comments/1ngy2ha/another_free_python_3_book_files_and_directories/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1ngy2ha/another_free_python_3_book_files_and_directories/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>If you are interested, you can click the top link on my landing page and download my eBook, &quot;Working with Files and Directories in Python 3&quot; for free: <a href="https://tr.ee/MFl4Mmyu1B">https://tr.ee/MFl4Mmyu1B</a></p><p>I recently gave away a Beginner&#39;s Python Book and that went really well</p><p>So I hope this 26 page pdf will be useful for someone interested in working with Files and Directories  in Python. Since it is sometimes difficult to copy/paste from a pdf, I&#39;ve added a .docx and .md version as well. The link will download all 3 as a zip file. No donations will be requested. Only info needed is a name and email address to get the download link.  It doesn&#39;t matter to me if you put a fake name.  Enjoy.</p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 14 Sep 2025 23:27:43 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1ngcnn7/sunday_daily_thread_whats_everyone_working_on/</link><title>Sunday Daily Thread: What's everyone working on this week?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1ngcnn7/sunday_daily_thread_whats_everyone_working_on/</guid><comments>https://www.reddit.com/r/Python/comments/1ngcnn7/sunday_daily_thread_whats_everyone_working_on/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1ngcnn7/sunday_daily_thread_whats_everyone_working_on/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><h1>Weekly Thread: What&#39;s Everyone Working On This Week? üõ†Ô∏è</h1><p>Hello <a href="https://www.reddit.com/r/Python">/r/Python</a>! It&#39;s time to share what you&#39;ve been working on! Whether it&#39;s a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you&#39;re up to!</p><h2>How it Works:</h2><ol><li><strong>Show &amp; Tell</strong>: Share your current projects, completed works, or future ideas.</li><li><strong>Discuss</strong>: Get feedback, find collaborators, or just chat about your project.</li><li><strong>Inspire</strong>: Your project might inspire someone else, just as you might get inspired here.</li></ol><h2>Guidelines:</h2><ul><li>Feel free to include as many details as you&#39;d like. Code snippets, screenshots, and links are all welcome.</li><li>Whether it&#39;s your job, your hobby, or your passion project, all Python-related work is welcome here.</li></ul><h2>Example Shares:</h2><ol><li><strong>Machine Learning Model</strong>: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate!</li><li><strong>Web Scraping</strong>: Built a script to scrape and analyze news articles. It&#39;s helped me understand media bias better.</li><li><strong>Automation</strong>: Automated my home lighting with Python and Raspberry Pi. My life has never been easier!</li></ol><p>Let&#39;s build and grow together! Share your journey and learn from others. Happy coding! üåü</p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 14 Sep 2025 05:30:35 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1ng9en6/midivisualiser_a_realtime_midi_player_and/</link><title>midi-visualiser: A real-time MIDI player and visualiser.</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1ng9en6/midivisualiser_a_realtime_midi_player_and/</guid><comments>https://www.reddit.com/r/Python/comments/1ng9en6/midivisualiser_a_realtime_midi_player_and/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1ng9en6/midivisualiser_a_realtime_midi_player_and/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hi all, I recently revisited an old project I created to visualise MIDI music (using a piano roll) and after some tidying up and fixes I&#39;ve now uploaded it to¬†<a href="https://pypi.org/project/midi-visualiser/">PyPI</a>! The program allows single MIDI files or playlists of MIDI files to be loaded and visualised through a command-line tool.</p><p>It&#39;s fairly simple, using Pygame to display the visualiser window and provide playback control, but I&#39;m pretty proud of how it looks and the audio-syncing logic (which uses Mido to interpret MIDI events). More details on how to use it are available in the¬†<a href="https://github.com/benjaminrall/midi-visualiser">project repository</a>.</p><p>This is the first project I&#39;ve used¬†<a href="https://docs.astral.sh/uv/">uv</a>¬†for, and I absolutely love it - check it out if you haven&#39;t already. Also, any suggestions/comments about the project would be greatly appreciated as I&#39;m very new to uploading to PyPI!</p><p>To summarise;- <strong>What My Project Does</strong>: Plays MIDI files and visualises them using a scrolling piano roll- <strong>Target Audience</strong>: Mainly just a toy project, but could be used by anyone who wants a simple &amp; quick way to view any MIDI file!- <strong>Comparison</strong>: I can&#39;t find any alternatives that have this same functionality (at least not made in Python) - it obviously can&#39;t compete with mega fancy MIDI visualisers, but a strong point is how straight forward the project is, working immediately from the command-line without needing any configuration.</p><p>Edit: Thanks to a comment, I&#39;ve discovered an issue that means this only works on Windows - will look into fixing this, sorry!</p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 14 Sep 2025 03:04:14 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1ng2h8x/splittermr_a_modular_library_for_splitting/</link><title>SplitterMR: a modular library for splitting &amp;amp; parsing documents</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1ng2h8x/splittermr_a_modular_library_for_splitting/</guid><comments>https://www.reddit.com/r/Python/comments/1ng2h8x/splittermr_a_modular_library_for_splitting/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1ng2h8x/splittermr_a_modular_library_for_splitting/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hey guys, I just released <strong>SplitterMR</strong>, a library I built because none of the existing tools quite did what I wanted for slicing up documents cleanly for LLMs / downstream processing.</p><p>If you often work with <strong>mixed document types</strong> (PDFs, Word, Excel, Markdown, images, etc.) and <strong>need flexible, reliable splitting/parsing</strong>, this might be useful.</p><p>This library supports <strong>multiple input formats</strong>, e.g., text, Markdown, PDF, Word / Excel / PowerPoint, HTML / XML, JSON / YAML, CSV / TSV, and even images.</p><p>Files can be read using <strong>MarkItDown</strong> or <strong>Docling</strong>, so this is perfect if you are using those frameworks with your current applications.</p><p>Logically, it supports <strong>many different splitting strategies</strong>: not only based on the number of characters but on tokens, schema keys, semantic similarity, and many other techniques. You can even develop your own splitter using the Base object, and it is the same for the Readers!</p><p>In addition, <strong>you can process the graphical resources of your documents (e.g., photos) using VLMs</strong> (OpenAI, Gemini, HuggingFace, etc.), so you can extract the text or caption them!</p><h1>What‚Äôs new / what‚Äôs good in the latest release</h1><ul><li>Stable Version <strong>1.0.0</strong> is out.</li><li>Supports <strong>more input formats / more robust readers</strong>.</li><li><strong>Stable API</strong> for the Reader abstractions so you can plug in your own if needed.</li><li><strong>Better handling of edge cases</strong> (e.g. images, schema‚Äôd JSON / XML) so you don‚Äôt lose structure unintentionally.</li></ul><h1>Some trade-offs / limitations (so you don‚Äôt run into surprises)</h1><ul><li><strong>Heavy dependencies</strong>: because it supports all these formats you‚Äôll pull in a bunch of libs (PDF, Word, image parsing, etc.). If you only care about plain text, many of those won‚Äôt matter, but still.</li><li><strong>Not a fully ‚ÄúLLM prompt manager‚Äù or embedding chunker out of the box</strong> ‚Äî splitting + parsing is its job; downstream you‚Äôll still need to decide chunk sizes, context windows, etc.</li></ul><h1>Installation and usage</h1><p>If you want to test:</p><pre><code>uv add splitter-mr</code></pre><p>Example usage:</p><pre><code>from splitter_mr.reader import VanillaReaderfrom splitter_mr.model.models import AzureOpenAIVisionModelmodel = AzureOpenAIVisionModel()reader = VanillaReader(model=model)output = reader.read(file_path=&quot;data/sample_pdf.pdf&quot;)print(output.text)</code></pre><p><strong>Check out the docs for more examples, API details, and instructions on how to write your own Reader for special formats:</strong>  </p><ul><li>üëâ <a href="https://github.com/andreshere00/Splitter_MR">Github</a></li><li>üëâ <a href="https://andreshere00.github.io/Splitter_MR/">Documentation server</a></li><li>üëâ <a href="https://pypi.org/project/splitter-mr/1.0.1/">PyPi package</a></li><li>üëâ <a href="https://www.linkedin.com/in/andres-herencia">LinkedIn (to contact with me)</a></li></ul><p>If you want to collaborate or you have some suggestions, don&#39;t dubt to contact me.</p><p><strong>Thank you so much for reading :)</strong></p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 13 Sep 2025 22:22:42 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1ng10wr/the_best_object_notation/</link><title>The best object notation?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1ng10wr/the_best_object_notation/</guid><comments>https://www.reddit.com/r/Python/comments/1ng10wr/the_best_object_notation/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1ng10wr/the_best_object_notation/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I want your advice regarding the best object notation to use for a python project. If you had the choice to receive data with a specific object notation, what would it be? YAML or JSON? Or another object notation?</p><p>YAML looks, to me, to be in agreement with a more pythonic way, because it is simple, faster and easier to understand. On the other hand, JSON has a similar structure to the python dictionary and the native python parser is very much faster than the YAML parser.</p><p>Any preferences or experiences?</p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 13 Sep 2025 21:24:47 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nfyq8o/mathflow_an_easytouse_math_library_for_python/</link><title>MathFlow: an easy-to-use math library for python</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nfyq8o/mathflow_an_easytouse_math_library_for_python/</guid><comments>https://www.reddit.com/r/Python/comments/1nfyq8o/mathflow_an_easytouse_math_library_for_python/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 3 min | <a href='https://www.reddit.com/r/Python/comments/1nfyq8o/mathflow_an_easytouse_math_library_for_python/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Project Site: <a href="https://github.com/cybergeek1943/MathFlow">https://github.com/cybergeek1943/MathFlow</a></p><p>In the process of doing research for my paper <a href="https://doi.org/10.48550/arXiv.2508.14095">Combinatorial and Gaussian Foundations of Rational Nth Root Approximations</a> (on arXiv), I created this library to address the pain points I felt when using only SymPy and SciPy separately. I wanted something lightweight, easy to use (exploratory), and something that would support numerical methods more easily. Hence, I created this lightweight wrapper that provides a hybrid symbolic-numerical interface to symbolic and numerical backends. It is backward compatible with Sympy. In short, this enables much faster analysis of symbolic math expressions by providing both numerical and traditional symbolic methods of analysis in the same interface. I have also added additional numerical methods that neither SymPy nor SciPy have (Pade approximations, numerical roots, etc.). The main goal for this project is to provide a tool that requires as little of a learning curve as possible and allows them to just focus on the math they are doing.</p><h1>Core features</h1><ul><li><strong>üîí Operative Closure</strong>: Mathematical operations return new Expression objects by default</li><li><strong>‚ö° Mutability Control</strong>: Choose between immutable (default) and mutable expressions for different workflows</li><li><strong>üîó Seamless Numerical Integration</strong>: Every symbolic expression has a¬†<code>.n</code>¬†attribute providing numerical methods without manual lambdification (uses cached lambdified expression when needed)</li><li><strong>üé® Enhanced Printing</strong>: Flexible output formatting through the¬†<code>.print</code>¬†attribute (LaTeX, pretty printing, code generation)</li><li><strong>üì° Signal System</strong>: Qt-like signals for tracking expression mutations and clones, enabling reactive programming</li><li><strong>üîÑ Automatic Type Conversions</strong>: Seamlessly and automatically converts between internal Poly and Expr representations based on context</li><li><strong>üì¶ Lightweight</strong>: ~0.5 MB itself, ~100 MB including dependencies</li><li><strong>üß© Fully backward compatible</strong>: Seamlessly integrate SymPy and MathFlow in the same script. All methods that work on SymPy Expr or Poly objects work on MathFlow objects</li><li><strong>üîç Exploratory</strong>: Full IDE support, enabling easy tool finding and minimizing the learning curve.</li></ul><p>A few examples are shown below. Many more examples can be found in the README of the official GitHub site.</p><h1>Quick Start</h1><p>Install using: <code>pip install mathflow</code></p><pre><code>from mathflow import Expression, Polynomial, Rational# Create expressions naturallyf = Expression(&quot;2x^2 + 3x + \frac{1}{2}&quot;)  # latex is automatically parsedg = Expression(&quot;sin(x) + cos(x)&quot;)# Automatic operative closure - operations return new objects of the same typeh = f + g  # f and g remain unchangedhprime = h.diff()  # hprime is still an Expression object# Numerical evaluation made easyresult = f(2.5)  # Numerically evaluate at x = 2.5# Use the .n attribute to access fast numerical methodsnumerical_roots = f.n.all_roots()# Call f&#39;s n-prefixed methods to use variable precision numerical methodsprecise_roots = f.nsolve_all(prec=50)  # 50 digits of accuracy# quick and easy printingf.print()f.print(&#39;latex&#39;)  # LaTeX outputf.print(&#39;mathematica_code&#39;)f.print(&#39;ccode&#39;)  # c code output</code></pre><h1>Numerical Computing</h1><p>MathFlow excels at bridging symbolic and numerical mathematics:</p><pre><code>f = Expression(&quot;x^3 - 2x^2 + x - 1&quot;)# Root findingall_roots = f.n.all_roots(bounds=(-5, 5))specific_root = f.nsolve_all(bounds=(-5, 5), prec=50)  # High-precision solve# Numerical calculusderivative_func = f.n.derivative_lambda(df_order=2)  # 2nd derivative numerical function  integral_result = f.n.integrate(-1, 1)               # Definite integral  # Optimizationminimum = f.n.minimize(bounds=[(-2, 2)])</code></pre><h1>Edit:</h1><p>This project was developed and used primarily for a research project, so a thorough test suite has not yet been developed. The project is still in development, and the current release is an alpha version. I have tried to minimize danger here, however, by designing it as a proxy to the already well-tested SymPy and SciPy libraries.</p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 13 Sep 2025 19:51:43 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nfvo8y/announcing_iceoryx2_v07_fast_and_robust/</link><title>Announcing iceoryx2 v0.7: Fast and Robust Inter-Process Communication (IPC) Library</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nfvo8y/announcing_iceoryx2_v07_fast_and_robust/</guid><comments>https://www.reddit.com/r/Python/comments/1nfvo8y/announcing_iceoryx2_v07_fast_and_robust/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1nfvo8y/announcing_iceoryx2_v07_fast_and_robust/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hello hello,</p><p>I am one of the maintainers of the open-source zero-copy middleware iceoryx2, and we‚Äôve just released iceoryx2 v0.7 which comes with Python language bindings. That means you can now use fast zero-copy communication directly in Python. Here is the full release blog: <a href="https://ekxide.io/blog/iceoryx2-0-7-release/">https://ekxide.io/blog/iceoryx2-0-7-release/</a></p><p>With iceoryx2 you can communicate between different processes, send data with publish-subscribe, build more complex request-response streams, or orchestrate processes using the event messaging pattern with notifiers and listeners.</p><p>We‚Äôve prepared a set of Python examples here: <a href="https://github.com/eclipse-iceoryx/iceoryx2/tree/main/examples/python">https://github.com/eclipse-iceoryx/iceoryx2/tree/main/examples/python</a></p><p>On top of that, we invested some time into writing a detailed getting started guide in the iceoryx2 book: <a href="https://ekxide.github.io/iceoryx2-book/main/getting-started/quickstart.html">https://ekxide.github.io/iceoryx2-book/main/getting-started/quickstart.html</a></p><p>And one more thing: iceoryx2 lets Python talk directly to C, C++ and Rust processes - without any serialization or binding overhead. Check out the cross-language publish-subscribe example to see it in action: <a href="https://github.com/eclipse-iceoryx/iceoryx2/tree/main/examples">https://github.com/eclipse-iceoryx/iceoryx2/tree/main/examples</a></p><p>So in short:</p><ul><li><strong>What My Project Does:</strong> Zero-Copy Inter-Process Communication</li><li><strong>Target Audience:</strong> Developers building distributed systems, plugin-based applications, or safety-critical and certifiable systems</li><li><strong>Comparision:</strong> Provides a high-level, service-oriented abstraction over low-level shared memory system calls</li></ul></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 13 Sep 2025 17:29:15 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nff4dw/flowfile_an_opensource_visual_etl_tool_now_with_a/</link><title>Flowfile - An open-source visual ETL tool, now with a Pydantic-based node designer.</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nff4dw/flowfile_an_opensource_visual_etl_tool_now_with_a/</guid><comments>https://www.reddit.com/r/Python/comments/1nff4dw/flowfile_an_opensource_visual_etl_tool_now_with_a/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1nff4dw/flowfile_an_opensource_visual_etl_tool_now_with_a/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hey <a href="https://www.reddit.com/r/Python">r/Python</a>,</p><p>I built Flowfile, an open-source tool for creating data pipelines both visually and in code. Here&#39;s the latest feature: Custom Node Designer.</p><h1>What My Project Does</h1><p>Flowfile creates bidirectional conversion between visual ETL workflows and Python code. You can build pipelines visually and export to Python, or write Python and visualize it. The Custom Node Designer lets you define new visual nodes using Python classes with Pydantic for settings and Polars for data processing.</p><h1>Target Audience</h1><p>Production-ready tool for data engineers who work with ETL pipelines. Also useful for prototyping and teams that need both visual and code representations of their workflows.</p><h1>Comparison</h1><ul><li><strong>Alteryx</strong>: Proprietary, expensive. Flowfile is open-source.</li><li><strong>Apache NiFi</strong>: Java-based, requires infrastructure. Flowfile is pip-installable Python.</li><li><strong>Prefect/Dagster</strong>: Orchestration-focused. Flowfile focuses on visual pipeline building.</li></ul><h1>Custom Node Example</h1><pre><code>import polars as plfrom flowfile_core.flowfile.node_designer import (    CustomNodeBase, NodeSettings, Section,    ColumnSelector, MultiSelect, Types)class TextCleanerSettings(NodeSettings):    cleaning_options: Section = Section(        title=&quot;Cleaning Options&quot;,        text_column=ColumnSelector(label=&quot;Column to Clean&quot;, data_types=Types.String),        operations=MultiSelect(            label=&quot;Cleaning Operations&quot;,            options=[&quot;lowercase&quot;, &quot;remove_punctuation&quot;, &quot;trim&quot;],            default=[&quot;lowercase&quot;, &quot;trim&quot;]        )    )class TextCleanerNode(CustomNodeBase):    node_name: str = &quot;Text Cleaner&quot;    settings_schema: TextCleanerSettings = TextCleanerSettings()    def process(self, input_df: pl.LazyFrame) -&gt; pl.LazyFrame:        text_col = self.settings_schema.cleaning_options.text_column.value        operations = self.settings_schema.cleaning_options.operations.value        expr = pl.col(text_col)        if &quot;lowercase&quot; in operations:            expr = expr.str.to_lowercase()        if &quot;trim&quot; in operations:            expr = expr.str.strip_chars()        return input_df.with_columns(expr.alias(f&quot;{text_col}_cleaned&quot;))</code></pre><p>Save in <code>~/.flowfile/user_defined_nodes/</code> and it appears in the visual editor.</p><h1>Why This Matters</h1><p>You can wrap complex tasks‚ÄîAPI connections, custom validations, niche library functions‚Äîinto simple drag-and-drop blocks. Build your own high-level tool palette right inside the app. It&#39;s all built on Polars for speed and completely open-source.</p><h1>Installation</h1><p><code>pip install Flowfile</code></p><h1>Links</h1><ul><li>GitHub: <a href="https://github.com/Edwardvaneechoud/Flowfile/">https://github.com/Edwardvaneechoud/Flowfile/</a></li><li>Custom Nodes Documentation: <a href="https://edwardvaneechoud.github.io/Flowfile/for-developers/creating-custom-nodes.html">https://edwardvaneechoud.github.io/Flowfile/for-developers/creating-custom-nodes.html</a></li><li>Previous discussions: <a href="https://www.reddit.com/r/SideProject/comments/1mp0hor/i_built_a_tool_that_turns_python_data_pipelines/">SideProject post</a>, <a href="https://www.reddit.com/r/Python/comments/1kp0er9/flowframe_python_code_that_generates_visual_etl/">FlowFrame post</a></li></ul></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 13 Sep 2025 02:45:28 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nfdlmq/learning_machine_learning/</link><title>Learning machine learning</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nfdlmq/learning_machine_learning/</guid><comments>https://www.reddit.com/r/Python/comments/1nfdlmq/learning_machine_learning/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1nfdlmq/learning_machine_learning/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Is this an appropriate question here? I was wondering if anyone could suggest any resources to learn machine learning relatively quickly. By quickly I mean get a general understanding and be able to talk about it. Then I can spend time actually learning it. I‚Äôm a beginner in Python. Thanks!</p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 13 Sep 2025 01:45:48 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nfdhlu/thanks_rpython_community_for_reviewing_my_project/</link><title>Thanks r/Python community for reviewing my project Ducky all in one networking tool!</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nfdhlu/thanks_rpython_community_for_reviewing_my_project/</guid><comments>https://www.reddit.com/r/Python/comments/1nfdhlu/thanks_rpython_community_for_reviewing_my_project/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1nfdhlu/thanks_rpython_community_for_reviewing_my_project/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Thanks to this community I received some feedbacks about Ducky that I posted last week on here, I got 42 stars on github as well and some comments for Duckys enhancement. Im thankful for the people who viewed the post and went to see the source code huge thanks to you all.  </p><p><strong>What Ducky Does:</strong></p><p>Ducky is a desktop application that consolidates the essential tools of a network engineer or security enthusiast into a single, easy-to-use interface. Instead of juggling separate applications for terminal connections, network scanning, and diagnostics, Ducky provides a unified workspace to streamline your workflow. Its core features include a tabbed terminal (SSH, Telnet, Serial), an SNMP-powered network topology mapper, a port scanner, and a suite of security utilities like a CVE lookup and hash calculator.</p><p><strong>Target Audience:</strong></p><p>Ducky is built for anyone who works with network hardware and infrastructure. This includes:</p><ul><li><strong>Network Engineers &amp; Administrators:</strong>¬†For daily tasks like configuring switches and routers, troubleshooting connectivity, and documenting network layouts.</li><li><strong>Cybersecurity Professionals:</strong>¬†For reconnaissance tasks like network discovery, port scanning, and vulnerability research.</li><li><strong>Students &amp; Hobbyists:</strong>¬†For those learning networking (e.g., for CompTIA Network+ or CCNA), Ducky provides a free, hands-on tool to explore and interact with real or virtual network devices.</li><li><strong>IT Support &amp; Help Desk:</strong>¬†For frontline technicians who need to quickly run diagnostics like ping and traceroute to resolve user issues.</li></ul><p>Github link <a href="https://github.com/thecmdguy/Ducky">https://github.com/thecmdguy/Ducky</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 13 Sep 2025 01:41:27 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nf57hb/update_should_i_give_away_my_app_to_my_employer/</link><title>Update: Should I give away my app to my employer for free?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nf57hb/update_should_i_give_away_my_app_to_my_employer/</guid><comments>https://www.reddit.com/r/Python/comments/1nf57hb/update_should_i_give_away_my_app_to_my_employer/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1nf57hb/update_should_i_give_away_my_app_to_my_employer/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Link to original post - <a href="https://www.reddit.com/r/Python/s/UMQsQi8lAX">https://www.reddit.com/r/Python/s/UMQsQi8lAX</a></p><p>Hi, since my post gained a lot of attention the other day and I had a lot of messages, questions on the thread etc. I thought I would give an update. </p><p>I didn‚Äôt make it clear in my previous post but I developed this app in my own time, but using company resources. </p><p>I spoke to a friend in the HR team and he explained a similar scenario happened a few years ago, someone built an automation tool for outlook, which managed a mailbox receiving 500+ emails a day (dealing/contract notes) and he simply worked on a fund pricing team and only needed to view a few of those emails a day but realised the mailbox was a mess. He took the idea to senior management and presented the cost saving and benefits. Once it was deployed he was offered shares in the company and then a cash bonus once a year of realised savings was achieved. </p><p>I‚Äôve been advised by my HR friend to approach senior management with my proposal, explain that I‚Äôve already spoken to my manager and detail the cost savings I can make, ask for a salary increase to provide ongoing support and develop my code further and ask for similar terms to that of the person who did this previously. He has confirmed what I‚Äôve done doesn‚Äôt go against any HR policies or my contract. </p><p>Meeting is booked for next week and I‚Äôve had 2 messages from senior management saying how excited they are to see my idea :) </p></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 12 Sep 2025 20:17:00 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nexoe8/i_built_a_fromscratch_python_package_for_classic/</link><title>I built a from-scratch Python package for classic Numerical Methods (no NumPy/SciPy required!)</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nexoe8/i_built_a_fromscratch_python_package_for_classic/</guid><comments>https://www.reddit.com/r/Python/comments/1nexoe8/i_built_a_fromscratch_python_package_for_classic/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1nexoe8/i_built_a_fromscratch_python_package_for_classic/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hey everyone,</p><p>Over the past few months I‚Äôve been building a Python package called¬†<code>numethods</code>¬†‚Äî a small but growing collection of¬†<strong>classic numerical algorithms implemented 100% from scratch</strong>. No NumPy, no SciPy, just plain Python floats and list-of-lists.</p><p>The idea is to make algorithms transparent and educational, so you can actually¬†<em>see</em>¬†how LU decomposition, power iteration, or RK4 are implemented under the hood. This is especially useful for students, self-learners, or anyone who wants a deeper feel for how numerical methods work beyond calling library functions.</p><p><a href="https://github.com/denizd1/numethods">https://github.com/denizd1/numethods</a></p><h1>üîß What‚Äôs included so far</h1><ul><li><strong>Linear system solvers</strong>: LU (with pivoting), Gauss‚ÄìJordan, Jacobi, Gauss‚ÄìSeidel, Cholesky</li><li><strong>Root-finding</strong>: Bisection, Fixed-Point Iteration, Secant, Newton‚Äôs method</li><li><strong>Interpolation</strong>: Newton divided differences, Lagrange form</li><li><strong>Quadrature (integration)</strong>: Trapezoidal rule, Simpson‚Äôs rule, Gauss‚ÄìLegendre (2- and 3-point)</li><li><strong>Orthogonalization &amp; least squares</strong>: Gram‚ÄìSchmidt, Householder QR, LS solver</li><li><strong>Eigenvalue methods</strong>: Power iteration, Inverse iteration, Rayleigh quotient iteration, QR iteration</li><li><strong>SVD</strong>¬†(via eigen-decomposition of ATAA^T AATA)</li><li><strong>ODE solvers</strong>: Euler, Heun, RK2, RK4, Backward Euler, Trapezoidal, Adams‚ÄìBashforth, Adams‚ÄìMoulton, Predictor‚ÄìCorrector, Adaptive RK45</li></ul><h1>‚úÖ Why this might be useful</h1><ul><li>Great for¬†<strong>teaching/learning</strong>¬†numerical methods step by step.</li><li>Good reference for people writing their own solvers in C/Fortran/Julia.</li><li>Lightweight, no dependencies.</li><li>Consistent object-oriented API (<code>.solve()</code>,¬†<code>.integrate()</code>¬†etc).</li></ul><h1>üöÄ What‚Äôs next</h1><ul><li>PDE solvers (heat, wave, Poisson with finite differences)</li><li>More optimization methods (conjugate gradient, quasi-Newton)</li><li>Spectral methods and advanced quadrature</li></ul><p>üëâ If you‚Äôre learning numerical analysis, want to peek under the hood, or just like playing with algorithms, I‚Äôd love for you to check it out and give feedback.</p></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 12 Sep 2025 13:57:44 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1new8g8/building_with_litestar_and_ai_agents/</link><title>Building with Litestar and AI Agents</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1new8g8/building_with_litestar_and_ai_agents/</guid><comments>https://www.reddit.com/r/Python/comments/1new8g8/building_with_litestar_and_ai_agents/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 10 min | <a href='https://www.reddit.com/r/Python/comments/1new8g8/building_with_litestar_and_ai_agents/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>In a recent thread in the subreddit - <a href="https://www.reddit.com/r/Python/comments/1mgkwmn/would_you_recommend_litestar_or_fastapi_for/">Would you recommend Litestar or FastAPI for building large scale api in 2025</a> - I wrote <a href="https://www.reddit.com/r/Python/comments/1mgkwmn/comment/n6qxwgp/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button">a comment</a>:</p><p>```textHi, ex-litestar maintainer here.</p><p>I am no longer maintaining a litestar - but I have a large scale system I maintain built with it.</p><p>As a litestar user I am personally very pleased. Everything works very smoothly - and there is a top notch discord server to boot.</p><p>Litestar is, in my absolutely subjective opinion, a better piece of software.</p><p>BUT - there are some problems: documentation needs a refresh. And AI tools do not know it by default. You will need to have some proper CLAUDE.md files etc.```</p><p>Well, life happened, and I forgot.</p><p>So two things, first, unabashadly promoting my own tool <a href="https://github.com/Goldziher/ai-rulez">ai-rulez</a>, which I actually use to maintain and generate said CLAUDE.md, subagents and mcp servers (for several different tools - working with teams with different AI tools, I just find it easier to git ignore all the .cursor, .gemini and github copilot instructions, and maintain these centrally). Second, here is the (redacted) versio of the promised CLAUDE.md file:</p><p>```markdown&lt;!-- </p><h1>ü§ñ GENERATED FILE - DO NOT EDIT DIRECTLY</h1><p>This file was automatically generated by ai-rulez from ai-rulez.yaml.</p><p>‚ö†Ô∏è  IMPORTANT FOR AI ASSISTANTS AND DEVELOPERS:- DO NOT modify this file directly- DO NOT add, remove, or change rules in this file- Changes made here will be OVERWRITTEN on next generation</p><p>‚úÖ TO UPDATE RULES:1. Edit the source configuration: ai-rulez.yaml2. Regenerate this file: ai-rulez generate3. The updated CLAUDE.md will be created automatically</p><p>üìù Generated: 2025-09-11 18:52:14üìÅ Source: ai-rulez.yamlüéØ Target: CLAUDE.mdüìä Content: 25 rules, 5 sections</p><h1>Learn more: <a href="https://github.com/Goldziher/ai-rulez">https://github.com/Goldziher/ai-rulez</a></h1><p>--&gt;</p><h1>grantflow</h1><p>GrantFlow.AI is a comprehensive grant management platform built as a monorepo with Next.js 15/React 19 frontend and Python microservices backend. Features include &lt;REDACTED&gt;.</p><h2>API Security</h2><p><strong>Priority:</strong> critical</p><p>Backend endpoints must use @post/@get decorators with allowed_roles parameter. Firebase Auth JWT claims provide organization_id/role. Never check auth manually - middleware handles it. Use withAuthRedirect() wrapper for all frontend API calls.</p><h2>Litestar Authentication Pattern</h2><p><strong>Priority:</strong> critical</p><p>Litestar-specific auth pattern: Use @get/@post/@patch/@delete decorators with allowed_roles parameter in opt dict. Example: <code>@get(&quot;/path&quot;, allowed_roles=[UserRoleEnum.OWNER])</code>. AuthMiddleware reads route_handler.opt[&quot;allowed_roles&quot;] - never check auth manually. Always use allowed_roles in opt dict, NOT as decorator parameter.</p><h2>Litestar Dependency Injection</h2><p><strong>Priority:</strong> critical</p><p>Litestar dependency injection: async_sessionmaker injected automatically via parameter name. Request type is APIRequest. Path params use {param:uuid} syntax. Query params as function args. Never use Depends() - Litestar injects by parameter name/type.</p><h2>Litestar Framework Patterns (IMPORTANT: not FastAPI!)</h2><h3>Key Differences from FastAPI</h3><ul><li><strong>Imports</strong>: <code>from litestar import get, post, patch, delete</code> (NOT <code>from fastapi import FastAPI, APIRouter</code>)</li><li><strong>Decorators</strong>: Use <code>@get</code>, <code>@post</code>, etc. directly on functions (no router.get)</li><li><strong>Auth</strong>: Pass <code>allowed_roles</code> in decorator&#39;s opt dict: <code>@get(&quot;/path&quot;, allowed_roles=[UserRoleEnum.OWNER])</code></li><li><strong>Dependency Injection</strong>: No <code>Depends()</code> - Litestar injects by parameter name/type</li><li><strong>Responses</strong>: Return TypedDict/msgspec models directly, or use <code>Response[Type]</code> for custom responses</li></ul><h3>Authentication Pattern</h3><p>from litestar import get, postfrom packages.db.src.enums import UserRoleEnum</p><p>&lt;&gt; CORRECT - Litestar pattern with opt dict@get(    &quot;/organizations/{organization_id:uuid}/members&quot;,    allowed_roles=[UserRoleEnum.OWNER, UserRoleEnum.ADMIN],    operation_id=&quot;ListMembers&quot;)async def handle_list_members(    request: APIRequest,  # Injected automatically    organization_id: UUID,  # Path param    session_maker: async_sessionmaker[Any],  # Injected by name) -&gt; list[MemberResponse]:    ...</p><p>&lt;&gt; WRONG - FastAPI pattern (will not work)@router.get(&quot;/members&quot;)async def list_members(    current_user: User = Depends(get_current_user)):    ...</p><h3>WebSocket Pattern</h3><p>from litestar import websocket_streamfrom collections.abc import AsyncGenerator</p><p>@websocket_stream(    &quot;/organizations/{organization_id:uuid}/notifications&quot;,    opt={&quot;allowed_roles&quot;: [UserRoleEnum.OWNER]},    type_encoders={UUID: str, SourceIndexingStatusEnum: lambda x: x.value})async def handle_notifications(    organization_id: UUID,) -&gt; AsyncGenerator[WebsocketMessage[dict[str, Any]]]:    while True:        messages = await get_messages()        for msg in messages:            yield msg  # Use yield, not send        await asyncio.sleep(3)</p><h3>Response Patterns</h3><p>from litestar import Response</p><p>&lt;&gt; Direct TypedDict return (most common)@post(&quot;/organizations&quot;)async def create_org(data: CreateOrgRequest) -&gt; TableIdResponse:    return TableIdResponse(id=str(org.id))</p><p>&lt;&gt; Custom Response with headers/status@post(&quot;/files/convert&quot;)async def convert_file(data: FileData) -&gt; Response[bytes]:    return Response[bytes](        content=pdf_bytes,        media_type=&quot;application/pdf&quot;,        headers={&quot;Content-Disposition&quot;: f&#39;attachment; filename=&quot;{filename}&quot;&#39;}    )</p><h3>Middleware Access</h3><ul><li>AuthMiddleware checks <code>connection.route_handler.opt.get(&quot;allowed_roles&quot;)</code></li><li>Never implement auth checks in route handlers</li><li>Middleware handles all JWT validation and role checking</li></ul><h2>Litestar Framework Imports</h2><p><strong>Priority:</strong> critical</p><p>Litestar imports &amp; decorators: from litestar import get, post, patch, delete, websocket_stream. NOT from fastapi. Route handlers return TypedDict/msgspec models directly. For typed responses use Response[Type]. WebSocket uses @websocket_stream with AsyncGenerator yield pattern.</p><h2>Multi-tenant Security</h2><p><strong>Priority:</strong> critical</p><p>All endpoints must include organization_id in URL path. Use @allowed_roles decorator from services.backend.src.auth. Never check auth manually. Firebase JWT claims must include organization_id.</p><h2>SQLAlchemy Async Session Management</h2><p><strong>Priority:</strong> critical</p><p>Always use async session context managers with explicit transaction boundaries. Pattern: <code>async with session_maker() as session, session.begin():</code>. Never reuse sessions across requests. Use <code>select_active()</code> from packages.db.src.query_helpers for soft-delete filtering.</p><h2>Soft Delete Integrity</h2><p><strong>Priority:</strong> critical</p><p>Always use select_active() helper from packages.db.src.query_helpers for queries. Never query deleted_at IS NULL directly. Test soft-delete filtering in integration tests for all new endpoints.</p><h2>Soft Delete Pattern</h2><p><strong>Priority:</strong> critical</p><p>All database queries must use select_active() helper from packages.db.src.query_helpers for soft-delete filtering. Never query deleted_at IS NULL directly. Tables with is_deleted/deleted_at fields require this pattern to prevent exposing deleted data.</p><h2>Task Commands</h2><p><strong>Priority:</strong> critical</p><p>Use Taskfile commands exclusively: task lint:all before commits, task test for testing, task db:migrate for migrations. Never run raw commands. Check available tasks with task --list. CI validates via these commands.</p><h2>Test Database Isolation</h2><p><strong>Priority:</strong> critical</p><p>Use real PostgreSQL for all tests via testing.db_test_plugin. Mark integration tests with @pytest.mark.integration, E2E with @pytest.mark.e2e_full. Always set PYTHONPATH=. when running pytest. Use factories from testing.factories for test data generation.</p><h2>Testing with Real Infrastructure</h2><p><strong>Priority:</strong> critical</p><p>Use real PostgreSQL via db_test_plugin for all tests. Never mock SQLAlchemy sessions. Use factories from testing/factories.py. Run &#39;task test:e2e&#39; for integration tests before merging.</p><h2>CI/CD Patterns</h2><p><strong>Priority:</strong> high</p><p>GitHub Actions in .github/workflows/ trigger on development‚Üístaging, main‚Üíproduction. Services deploy via build-service-*.yaml workflows. Always run task lint:all and task test locally before pushing. Docker builds require --build-arg for frontend env vars.</p><h2>Development Workflow</h2><h3>Quick Start</h3><p>&lt;&gt; Install dependencies and setuptask setup</p><p>&lt;&gt; Start all services in dev modetask dev</p><p>&lt;&gt; Or start specific servicestask service:backend:devtask frontend:dev</p><h3>Daily Development Tasks</h3><h4>Running Tests</h4><p>&lt;&gt; Run all tests (parallel by default)task test</p><p>&lt;&gt; Python service tests with real PostgreSQLPYTHONPATH=. uv run pytest services/backend/tests/PYTHONPATH=. uv run pytest services/indexer/tests/</p><p>&lt;&gt; Frontend tests with Vitestcd frontend &amp;&amp; pnpm test</p><h4>Linting &amp; Formatting</h4><p>&lt;&gt; Run all linterstask lint:all</p><p>&lt;&gt; Specific linterstask lint:frontend  # Biome, ESLint, TypeScripttask lint:python    # Ruff, MyPy</p><h4>Database Operations</h4><p>&lt;&gt; Apply migrations locallytask db:migrate</p><p>&lt;&gt; Create new migrationtask db:create-migration -- &lt;migration_name&gt;</p><p>&lt;&gt; Reset database (WARNING: destroys data)task db:reset</p><p>&lt;&gt; Connect to Cloud SQL stagingtask db:proxy:starttask db:migrate:remote</p><h3>Git Workflow</h3><ul><li>Branch from <code>development</code> for features</li><li><code>development</code> ‚Üí auto-deploys to staging</li><li><code>main</code> ‚Üí auto-deploys to production</li><li>Commits use conventional format: <code>fix:</code>, <code>feat:</code>, <code>chore:</code></li></ul><h2>Auth Security</h2><p><strong>Priority:</strong> high</p><p>Never check auth manually in endpoints - middleware handles all auth via JWT claims (organization_id/role). Use UserRoleEnum from packages.db for role checks. Pattern: <code>@post(&#39;/path&#39;, allowed_roles=[UserRoleEnum.COLLABORATOR])</code>. Always wrap frontend API calls with withAuthRedirect().</p><h2>Litestar WebSocket Handling</h2><p><strong>Priority:</strong> high</p><p>Litestar WebSocket pattern: Use @websocket_stream decorator with AsyncGenerator return type. Yield messages in async loop. Set type_encoders for UUID/enum serialization. Access allowed_roles via opt dict. Example: @websocket_stream(&quot;/path&quot;, opt={&quot;allowed_roles&quot;: [...]}).</p><h2>Initial Setup</h2><p>&lt;&gt; Install all dependencies and set up git hookstask setup</p><p>&lt;&gt; Copy environment configurationcp .env.example .env&lt;&gt; Update .env with actual values (reach out to team for secrets)</p><p>&lt;&gt; Start database and apply migrationstask db:uptask db:migrate</p><p>&lt;&gt; Seed the databasetask db:seed</p><h2>Running Services</h2><p>&lt;&gt; Start all services in development modetask dev</p><h2>Taskfile Command Execution</h2><p><strong>Priority:</strong> high</p><p>Always use task commands instead of direct package managers. Core workflow: <code>task setup dev test lint format build</code>. Run <code>task lint:all</code> after changes, <code>task test:e2e</code> for E2E tests with E2E_TESTS=1 env var. Check available commands with <code>task --list</code>.</p><h2>Test Factories</h2><p><strong>Priority:</strong> high</p><p>Use testing/factories.py for Python tests and testing/factories.ts for TypeScript tests. Real PostgreSQL instances required for backend tests. Run PYTHONPATH=. uv run pytest for Python, pnpm test for frontend. E2E tests use markers: smoke (&lt;1min), quality_assessment (2-5min), e2e_full (10+min).</p><h2>Type Safety</h2><p><strong>Priority:</strong> high</p><p>Python: Type all args/returns, use TypedDict with NotRequired[type]. TypeScript: Never use &#39;any&#39;, leverage API namespace types, use ?? operator. Run task lint:python and task lint:frontend to validate. msgspec for Python serialization.</p><h2>Type Safety and Validation</h2><p><strong>Priority:</strong> high</p><p>Python: Use msgspec TypedDict with NotRequired[], never Optional. TypeScript: Ban &#39;any&#39;, use type guards from @tool-belt/type-predicates. All API responses must use msgspec models.</p><h2>TypeScript Type Safety</h2><p><strong>Priority:</strong> high</p><p>Never use &#39;any&#39; type. Use type guards from @tool-belt/type-predicates. Always use nullish coalescing (??) over logical OR (||). Extract magic numbers to constants. Use factories from frontend/testing/factories and editor/testing/factories for test data.</p><h2>Async Performance Patterns</h2><p><strong>Priority:</strong> medium</p><p>Use async with session.begin() for transactions. Batch Pub/Sub messages with ON CONFLICT DO NOTHING for duplicates. Frontend: Use withAuthRedirect() wrapper for all API calls.</p><h2>Monorepo Service Boundaries</h2><p><strong>Priority:</strong> medium</p><p>Services must be independently deployable. Use packages/db for shared models, packages/shared_utils for utilities. &lt;REDACTED&gt;. </p><h2>Microservices Overview</h2><p>&lt;REDACTED&gt;</p><h3>Key Technologies</h3><p>&lt;REDACTED&gt;</p><h2>Service Communication</h2><p>&lt;REDACTED&gt;</p><h2>Test Commands</h2><p>&lt;&gt; Run all tests (parallel by default)task test</p><p>&lt;&gt; Run specific test suitesPYTHONPATH=. uv run pytest services/backend/tests/cd frontend &amp;&amp; pnpm test</p><p>&lt;&gt; E2E tests with markersE2E_TESTS=1 pytest -m &quot;smoke&quot;              # &lt;1 minE2E_TESTS=1 pytest -m &quot;quality_assessment&quot; # 2-5 minE2E_TESTS=1 pytest -m &quot;e2e_full&quot;          # 10+ min</p><p>&lt;&gt; Disable parallel execution for debuggingpytest -n 0</p><h2>Test Structure</h2><ul><li><strong>Python</strong>: <code>*_test.py</code> files, async pytest with real PostgreSQL</li><li><strong>TypeScript</strong>: <code>*.spec.ts(x)</code> files, Vitest with React Testing Library</li><li><strong>E2E</strong>: Playwright tests with <code>data-testid</code> attributes</li></ul><h2>Test Data</h2><ul><li>Use factories from <code>testing/factories.py</code> (Python)</li><li>Use factories from <code>frontend/testing/factories.ts</code> (TypeScript)</li><li>Test scenarios in <code>testing/test_data/scenarios/</code> with metadata.yaml configs</li></ul><h2>Coverage Requirements</h2><ul><li>Target 100% test coverage</li><li>Real PostgreSQL for backend tests (no mocks)</li><li>Mock only external APIs in frontend tests</li></ul><h2>Structured Logging</h2><p><strong>Priority:</strong> low</p><p>Use structlog with key=value pairs: logger.info(&#39;Created grant&#39;, grant_id=str(id)). Convert UUIDs to strings, datetime to .isoformat(). Never use f-strings in log messages.```</p><p>Important notes:    * in larger monorepo what I do (again using ai-rulez) is create layered CLAUDE.md files - e.g., there is a root ai-rulez.yaml file in the repository root, which includes the overall conventions of the codebase, instructions about tooling etc. Then, say under the <code>services</code> folder (assuming it includes services of the same type), there is another ai-rulez.yaml file with more specialized instructions for these services, say - all are written in Litestar, so the above conventions etc. Why? Claude Code, for example, reads the CLAUDE.md files in its working context. This is far from perfect, but it does allow creating more focused context.  * in the above example I removed the code blocks and replaced code block comments from using <code>#</code> to using <code>&lt;&gt;</code>. Its not the most elegant, but it makes it more readable. </p></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 12 Sep 2025 12:22:02 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1neuyit/html2pic_transform_basic_htmlcss_to_image_without/</link><title>html2pic: transform basic html&amp;amp;css to image, without a browser (experimental)</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1neuyit/html2pic_transform_basic_htmlcss_to_image_without/</guid><comments>https://www.reddit.com/r/Python/comments/1neuyit/html2pic_transform_basic_htmlcss_to_image_without/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1neuyit/html2pic_transform_basic_htmlcss_to_image_without/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hey everyone,</p><p>For the past few months, I&#39;ve been working on a personal graphics library called <a href="https://github.com/francozanardi/pictex">PicTex</a>. As an experiment, I got curious to see if I could build a lightweight HTML/CSS to image converter on top of it, without the overhead of a full browser engine like Selenium or Playwright.</p><p><strong>Important</strong>: this is a proof-of-concept, and a large portion of the code was generated with AI assistance (primarily Claude) to quickly explore the idea. It&#39;s definitely not production-ready and likely has plenty of bugs and unhandled edge cases.</p><p>I&#39;m sharing it here to show what I&#39;ve been exploring, maybe it could be useful for someone.</p><p>Here&#39;s the link to the repo: <a href="https://github.com/francozanardi/html2pic">https://github.com/francozanardi/html2pic</a></p><hr/><h3>What My Project Does</h3><p><code>html2pic</code> takes a subset of HTML and CSS and renders it into a PNG, JPG, or SVG image, using Python + Skia. It also uses BeautifulSoup4 for HTML parsing, tinycss2 for CSS parsing.</p><p>Here‚Äôs a basic example:</p><p>```pythonfrom html2pic import Html2Pic</p><p>html = &#39;&#39;&#39;&lt;div class=&quot;card&quot;&gt;  &lt;div class=&quot;avatar&quot;&gt;&lt;/div&gt;  &lt;div class=&quot;user-info&quot;&gt;    &lt;h2&gt;pictex_dev&lt;/h2&gt;    &lt;p&gt;@python_renderer&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&#39;&#39;&#39;</p><p>css = &#39;&#39;&#39;.card {    font-family: &quot;Segoe UI&quot;;    display: flex;    align-items: center;    gap: 16px;    padding: 20px;    background-color: #1a1b21;    border-radius: 12px;    width: 350px;    box-shadow: 0px 4px 12px rgba(0, 0, 0, 0.4);}</p><p>.avatar {    width: 60px;    height: 60px;    border-radius: 50%;    background-image: linear-gradient(45deg, #f97794, #623aa2);}</p><p>.user-info {    display: flex;    flex-direction: column;}</p><p>h2 {    margin: 0;    font-size: 22px;    font-weight: 600;    color: #e6edf3;}</p><p>p {    margin: 0;    font-size: 16px;    color: #7d8590;}&#39;&#39;&#39;</p><p>renderer = Html2Pic(html, css)image = renderer.render()image.save(&quot;profile_card.png&quot;)```</p><p>And here&#39;s the image it generates:</p><p><strong><a href="https://i.imgur.com/UKGA0lH.png">Quick Start Result Image</a></strong></p><hr/><h3>Target Audience</h3><p>Right now, this is a <strong>toy project / proof-of-concept</strong>.</p><p>It&#39;s intended for hobbyists, developers who want to prototype image generation, or for simple, controlled use cases where installing a full browser feels like overkill. For example:*   Generating simple social media cards with dynamic text.*   Creating basic components for reports.*   Quickly visualizing HTML/CSS snippets without opening a browser.</p><p>It is <strong>not</strong> meant for production environments or for rendering complex HTML/CSS. It is absolutely not a browser replacement.</p><hr/><h3>Comparison</h3><ul><li>  <strong>vs. Selenium / Playwright:</strong> The main difference is the lack of a browser. <code>html2pic</code> is much more lightweight and has fewer dependencies. The trade-off is that it only supports a tiny fraction of HTML/CSS.</li></ul><hr/><p>Thanks for checking it out.</p></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 12 Sep 2025 11:02:04 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1ner9mj/best_way_to_install_python_package_with_all_its/</link><title>Best way to install python package with all its dependencies on an offline pc. -- Part 2</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1ner9mj/best_way_to_install_python_package_with_all_its/</guid><comments>https://www.reddit.com/r/Python/comments/1ner9mj/best_way_to_install_python_package_with_all_its/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1ner9mj/best_way_to_install_python_package_with_all_its/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>This is a follow up post to <a href="https://www.reddit.com/r/Python/comments/1keaeft/best_way_to_install_python_package_with_all_its/">https://www.reddit.com/r/Python/comments/1keaeft/best_way_to_install_python_package_with_all_its/</a><br/>I followed one of the techniques shown in that post and it worked quite well.<br/>So in short what i do is<br/>first do<br/><code>python -m venv .</code> ( in a  directory)<br/>then <code>.\Scripts\activate</code><br/>then do the actual installation of the package with <code>pip install &lt;packagename&gt;</code><br/>then i do a <code>pip freeze &gt; requirements.txt</code><br/>and finally i download the wheels using this requirements.txt.<br/>For that i create a folder called wheel and then I do a <code>pip download -r requirements.txt</code><br/>then i copy over the wheels folder to the offline pc and create a venv over there and do the install using that wheel folder.</p><p>So all this works quite well as long as there as only wheel files in the package.<br/>Lately I see that there are packages that need some dependencies that need to be built from source so instead of the <code>whl</code> file a <code>tar.gz</code> file gets downloaded in the wheel folder. And somehow that <code>tar.gz</code> doesn&#39;t get built on the offline pc due to lack of dependencies or sometimes buildtools or setuptools version mismatch.</p><p>Is there a way to get this working?</p></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 12 Sep 2025 07:42:23 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1neno5h/what_is_the_quickest_and_easiest_way_to_fix/</link><title>What is the quickest and easiest way to fix indentation errors?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1neno5h/what_is_the_quickest_and_easiest_way_to_fix/</guid><comments>https://www.reddit.com/r/Python/comments/1neno5h/what_is_the_quickest_and_easiest_way_to_fix/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1neno5h/what_is_the_quickest_and_easiest_way_to_fix/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Context - I&#39;ve been writing Python for a good number of years and I still find indentation errors annoying. Also I&#39;m using VScode with the Python extension.</p><p>How often do you encounter them? How are you dealing with them?  </p><p>Because in Javascript land (and other languages too), there are some linters that look to be taking care of that.</p></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 12 Sep 2025 04:47:44 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nem1ty/fpstyle_pattern_matching_implemented_in_python/</link><title>fp-style pattern matching implemented in python</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nem1ty/fpstyle_pattern_matching_implemented_in_python/</guid><comments>https://www.reddit.com/r/Python/comments/1nem1ty/fpstyle_pattern_matching_implemented_in_python/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1nem1ty/fpstyle_pattern_matching_implemented_in_python/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I&#39;m recently working on a functional programming library in python. One thing I&#39;ve really want in python was a pattern matching that is expression and works well with other fp stuff in python. I went through similar fp libs in python such as <code>toolz</code> but didn&#39;t yet found a handy pattern matching solution in python. Therefore, I implement this simple pattern matching that works with most of objects (through itemgetter and attrgetter), iterables (just iter through), and literals (just comparison) in python.</p><ul><li>target audience</li></ul><p>There&#39;s <a href="https://github.com/BrandenXia/fp-cate">link</a> to the github repo. Note that it&#39;s still in very early development and also just a personal toy project, so it&#39;s not meant to be used in production at all.</p><p>There&#39;s some example I wrote using this library. I&#39;d like to get some advice and suggestions about possible features and improvements I make for this functionality :)</p><p>```pyfrom dataclasses import dataclass</p><p>from fp_cate import pipe, match, case, matchV, _any, _rest, default</p><h1>works with any iterables</h1><p>a = &quot;test&quot;print(    matchV(a)(        case(&quot;tes&quot;) &gt;&gt; (lambda x: &quot;one&quot;),        case([&quot;a&quot;, _rest]) &gt;&gt; (lambda x, xs: f&quot;list starts with a, rest is {xs}&quot;),        default &gt;&gt; &quot;good&quot;,    ))a = [&quot;a&quot;, 1, 2, 3]pipe(    a,    match(        case([1, 2]) &gt;&gt; (lambda x: &quot;one&quot;),        case([&quot;a&quot;, _rest]) &gt;&gt; (lambda x, xs: f&quot;list starts with a, rest is {xs}&quot;),    ),    print,)</p><h1>works with dicts</h1><p>pipe(    {&quot;test&quot;: 1, &quot;other&quot;: 2},    match(        case({&quot;test&quot;: _any}) &gt;&gt; (lambda x: f&quot;test is {x}&quot;),        case({&quot;other&quot;: 2}) &gt;&gt; (lambda x: &quot;other two&quot;),    ),    print,)</p><p>@dataclassclass Test:    a: int    b: bool</p><h1>works with dataclasses as well</h1><p>pipe(    Test(1, True),    match(        case({&quot;a&quot;: 1}) &gt;&gt; &quot;this is a good match&quot;,        case({&quot;b&quot;: False}) &gt;&gt; &quot;this won&#39;t match&quot;,        default &gt;&gt; &quot;all other matches failed&quot;,    ),    print,)```</p></div><!-- SC_ON --></section>]]></description><pubDate>Fri, 12 Sep 2025 03:35:50 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1ne4z4b/how_to_build_your_own_bluetooth_scriptable/</link><title>How to Build Your Own Bluetooth Scriptable Sniffer using python for Under $25</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1ne4z4b/how_to_build_your_own_bluetooth_scriptable/</guid><comments>https://www.reddit.com/r/Python/comments/1ne4z4b/how_to_build_your_own_bluetooth_scriptable/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1ne4z4b/how_to_build_your_own_bluetooth_scriptable/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>A¬†<strong>Bluetooth sniffer</strong>¬†is a hardware or software tool that captures and monitors Bluetooth communication between devices. Think of it as a network traffic analyzer, but for Bluetooth instead of Wi-Fi or Ethernet.<br/>There are high-end Bluetooth sniffers on the market ‚Äî like those from¬†<strong>Ellisys</strong>¬†or¬†<strong>Teledyne LeCroy</strong>¬†‚Äî which are powerful but often cost¬†<strong>hundreds or thousands of dollars</strong>.<br/>You can create your own scriptable BLE sniffer for under $25. the source code is available in this post, you can adjust the code and work further<br/><a href="https://www.bleuio.com/blog/how-to-build-your-own-bluetooth-scriptable-sniffer-for-under-30/">https://www.bleuio.com/blog/how-to-build-your-own-bluetooth-scriptable-sniffer-for-under-30/</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 11 Sep 2025 15:44:56 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1ne4t1d/detroit_python_implementation_of_d3js/</link><title>detroit: Python implementation of d3js</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1ne4t1d/detroit_python_implementation_of_d3js/</guid><comments>https://www.reddit.com/r/Python/comments/1ne4t1d/detroit_python_implementation_of_d3js/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1ne4t1d/detroit_python_implementation_of_d3js/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hi, I am the maintainer of <a href="https://github.com/bourbonut/detroit">detroit</a>. <code>detroit</code> is a Python implementation of the library <a href="https://d3js.org/">d3js</a>. I started this project because I like how flexible data visualization is with <code>d3js</code>, and because I&#39;m not a big fan of JavaScript.</p><p>You can find the documentation for <code>detroit</code> <a href="https://detroit.readthedocs.io/en/latest/">here</a>.</p><ul><li>Target Audience</li></ul><p><code>detroit</code> allows you to create <strong>static</strong> data visualizations. I&#39;m currently working on <a href="https://github.com/bourbonut/detroit-live">detroit-live</a> for those who also want <strong>interactivity</strong>. In addition, <code>detroit</code> requires only <a href="https://lxml.de/">lxml</a> as dependency, which makes it lightweight.</p><p>You can find a gallery of examples in the <a href="https://detroit.readthedocs.io/en/latest/#gallery">documentation</a>. Most of examples are directly inspired by <a href="https://observablehq.com/@d3/gallery">d3js examples on observablehq</a>.</p><ul><li>Comparison</li></ul><p>The API is almost the same:</p><pre><code>// d3jsconst scale = d3.scaleLinear().domain([0, 10]).range([0, 920]);console.log(scale.domain()) // [0, 10]# detroitscale = d3.scale_linear().set_domain([0, 10]).set_range([0, 920])print(scale.get_domain()) # [0, 10]</code></pre><p>The difference between <code>d3js</code>/<code>detroit</code> and <code>matplotlib</code>/<code>plotly</code>/<code>seaborn</code> is the approach to data visualization. With <code>matplotlib</code>, <code>plotly</code>, or <code>seaborn</code>, you only need to write a few lines and that&#39;s it - you get your visualization. However, if you want to customize some parts, you&#39;ll have to add a couple more lines, and it can become really hard to get exactly what you want. In contrast, with <code>d3js</code>/<code>detroit</code>, you know exactly what you are going to visualize, but it may require writing a few more lines of code.</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 11 Sep 2025 15:34:24 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1ndy9gv/from_code_to_python_gentle_guide_for_programmers/</link><title>From Code to Python: Gentle Guide for Programmers &amp;amp; Learners</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1ndy9gv/from_code_to_python_gentle_guide_for_programmers/</guid><comments>https://www.reddit.com/r/Python/comments/1ndy9gv/from_code_to_python_gentle_guide_for_programmers/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1ndy9gv/from_code_to_python_gentle_guide_for_programmers/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>This series teaches <a href="https://www.bestdesign2hub.com/from-code-to-python-gentle-guide-programmers-learners/">Python from code</a> without assuming you‚Äôre a total beginner to programming. If you‚Äôve written code in languages like C/C++, Java, JavaScript/TypeScript, Go, or Ruby, you‚Äôll find side‚Äëby‚Äëside explanations that map familiar concepts to Python‚Äôs syntax and idioms.</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 11 Sep 2025 08:48:57 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1ndsuud/streamlit_for_python_apps/</link><title>Streamlit for python apps</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1ndsuud/streamlit_for_python_apps/</guid><comments>https://www.reddit.com/r/Python/comments/1ndsuud/streamlit_for_python_apps/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1ndsuud/streamlit_for_python_apps/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>i‚Äôve been using streamlit lately and honestly it‚Äôs pretty nice, so just wanted to share in case it helps someone.</p><p>if you‚Äôre into data analysis or working on python projects and want to turn them into something interactive, streamlit is definitely worth checking out. it lets you build web apps super easily ‚Äî like you just write python code and it handles all the front-end stuff for you.</p><p>you can add charts, sliders, forms, even upload files, and it all works without needing to learn html or javascript. really useful if you want to share your work with others or just make a personal dashboard or tool.</p><p>feels like a good starting point if you‚Äôve been thinking about making web apps but didn‚Äôt know where to start.</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 11 Sep 2025 04:25:12 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nds31l/announcement_pychub_a_new_way_to_ship_your_python/</link><title>[ANNOUNCEMENT] pychub: A new way to ship your Python wheels + deps + extras</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nds31l/announcement_pychub_a_new_way_to_ship_your_python/</guid><comments>https://www.reddit.com/r/Python/comments/1nds31l/announcement_pychub_a_new_way_to_ship_your_python/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 3 min | <a href='https://www.reddit.com/r/Python/comments/1nds31l/announcement_pychub_a_new_way_to_ship_your_python/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hey fellow deveopers!  </p><p>I built a packaging tool called <a href="https://github.com/Steve973/pychub"><strong>pychub</strong></a> that might fill a weird little gap you didn‚Äôt know you had. It came out of me needing a clean way to distribute Python wheels <em>with</em> all of their dependencies and optional extras, but <em>without</em> having to freeze them into platform-specific binaries like PyInstaller does. And if you want to just install everything into your own current environment?  That&#39;s what I wanted, too.</p><h1>So what is it?</h1><p><strong>pychub</strong> takes your wheel, resolves and downloads its dependencies, and wraps everything into a single executable <code>.chub</code> file. That file can then be shipped/copied anywhere, and then run directly like this:</p><pre><code>python yourtool.chub</code></pre><p>It installs into the current environment (or a venv, or a conda env, your call), and can even run an entrypoint function or console script <em>right after</em> install.</p><p>No network calls. No pip. No virtualenv setup. Just <code>python tool.chub</code> and go.</p><h1>Why I built it:</h1><p>Most of the Python packaging tools out there either:</p><ul><li>Freeze the whole thing into a binary (PyInstaller, PyOxidizer) ‚Äî which is great, until you hit platform issues or need to debug something. Or you just want to do something different than that.</li><li>Just stop at building a wheel and leave it up to you (or your users) to figure out installation, dependencies, and environment prep.</li></ul><p>I wanted something in between: still using the host Python interpreter (so it stays light and portable), but with everything pre-downloaded and reproducible.</p><h1>What it can bundle:</h1><ul><li>Your main wheel</li><li>Any number of additional wheels</li><li>All their dependencies (downloaded and stored locally)</li><li>Optional include files (configs, docs, whatever)</li><li>Pre-install and post-install scripts (shell, Python, etc.)</li></ul><p>And it‚Äôs 100% reproducible, so that the archive installs the exact same versions every time, no network access needed.</p><h1>Build tool integration:</h1><p>If you&#39;re using <strong>Poetry</strong>, <strong>Hatch</strong>, or <strong>PDM</strong>, I‚Äôve released plugins for all three:</p><ul><li>Just add the plugin to your <code>pyproject.toml</code></li><li>Specify your build details (main wheel, includes, scripts, etc.)</li><li>Run your normal build command and you‚Äôll get a <code>.chub</code> alongside your <code>.whl</code></li></ul><p>It‚Äôs one of the easiest ways to ship Python tools that <em>just work,</em> whether you&#39;re distributing internally, packaging for air-gapped environments, or dropping into Docker builder stages.</p><p>Plugins repo:  <a href="https://github.com/Steve973/pychub-build-plugins">https://github.com/Steve973/pychub-build-plugins</a></p><h1>Why not just use some other bundling/packaging tool?</h1><p>Well, depending on your needs, maybe you should! I don‚Äôt think pychub replaces everything. It just solves a different problem.</p><p>If you want sealed apps with bundled runtimes, use PEX or PyOxidizer.<br/>If you&#39;re distributing scripts, zipapp is great.<br/>But if you want a <strong>wheel-based</strong>, network-free, single-file installer that works on any Python 3.9+ environment, then pychub might be the right tool.</p><p>Full comparison table along with everything else:<br/>üìò <a href="https://github.com/Steve973/pychub#why-not-just-use-insert-favorite-tool-name-here">README on GitHub</a></p><p>That‚Äôs it. I built it because I needed it to include plugins for a platform that I am building. If it helps you too, even better.  I will be actively supporting this, and if you would like to take it for a spin and see if you like it, I&#39;d be honored to hear your feedback. If you want a feature added, etc, please let me know.<br/>Issues, suggestions, and PRs are all welcome.</p><p>Thanks for your time and interest!</p><p>Steve</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 11 Sep 2025 03:51:16 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1ndnusy/a_complete_list_of_python_tkinter_colors_valid/</link><title>A Complete List of Python Tkinter Colors, Valid and Tested</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1ndnusy/a_complete_list_of_python_tkinter_colors_valid/</guid><comments>https://www.reddit.com/r/Python/comments/1ndnusy/a_complete_list_of_python_tkinter_colors_valid/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1ndnusy/a_complete_list_of_python_tkinter_colors_valid/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I needed a complete list of valid color names for Python&#39;s Tkinter package as part of my <a href="https://pypi.org/project/ButtonPad/">ButtonPad</a> GUI framework development. The lists I found on the internet were either incomplete, buried under ads, and often just plain wrong. Here&#39;s a list of all 760 color names (valid and personally tested) for Python Tkinter.</p><p><a href="https://inventwithpython.com/blog/complete-list-tkinter-colors-valid-and-tested.html">https://inventwithpython.com/blog/complete-list-tkinter-colors-valid-and-tested.html</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 11 Sep 2025 00:57:58 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1ndk80g/scaling_asyncio_on_freethreaded_python/</link><title>Scaling asyncio on Free-Threaded Python</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1ndk80g/scaling_asyncio_on_freethreaded_python/</guid><comments>https://www.reddit.com/r/Python/comments/1ndk80g/scaling_asyncio_on_freethreaded_python/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1ndk80g/scaling_asyncio_on_freethreaded_python/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><a href="https://labs.quansight.org/blog/scaling-asyncio-on-free-threaded-python">https://labs.quansight.org/blog/scaling-asyncio-on-free-threaded-python</a></p><p>From the author: &quot;In this blog post, we will explore the changes I made in the upcoming Python 3.14 release to enable asyncio to scale on the free-threaded build of CPython.&quot;</p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 10 Sep 2025 22:43:07 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1ndj5vz/i_decoupled_fastapi_dependency_injection_system/</link><title>I decoupled FastAPI dependency injection system in pure python, no dependencies.</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1ndj5vz/i_decoupled_fastapi_dependency_injection_system/</guid><comments>https://www.reddit.com/r/Python/comments/1ndj5vz/i_decoupled_fastapi_dependency_injection_system/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1ndj5vz/i_decoupled_fastapi_dependency_injection_system/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>What My Project Does</strong></p><p>When building FastAPI endpoints, I found the dependency injection system such a pleasure to use that I wanted it everywhere, not just in my endpoints. I explored a few libraries that promised similar functionality, but each had drawbacks, some required Pydantic, others bundled in features beyond dependency injection, and many were riddled with bugs.</p><p>That&#39;s way I created <a href="https://github.com/entropy-flux/PyDepends">PyDepends</a>, a lightweight dependency injection system that I now use in my own projects and would like to share with you.</p><p><strong>Target Audience</strong><br/>This is mainly aimed at:</p><ul><li><p>FastAPI developers who want to use dependency injection in the service layer.</p></li><li><p>Domain-Driven Design practitioners who want to decouple their services from infrastructure.</p></li><li><p>Python developers who aren‚Äôt building API endpoints but would still like to use dependency injection in their projects.It‚Äôs not production-grade yet, but it‚Äôs stable enough for everyday use and easy to extend.</p></li></ul><p><strong>Comparison</strong>  </p><p>Compared to other similar packages, it does just that, inject dependencies, is not bloated with other functionalities. </p><ul><li>FastDepends: It also cannot be used with non-serializable classes, and I wanted to inject machine learning models into services. On top of that, it does unpredictable things beyond dependency injection.</li></ul><p>Repo: <a href="https://github.com/entropy-flux/PyDepends">https://github.com/entropy-flux/PyDepends</a></p><p>Hope you find it useful!</p><p>EDIT: Sorry to Lancetnik12 I think he did a great job with fastdepends and faststream, I was a to rude with his job, the reality is fastdepends just have other use cases, I don&#39;t really like to compare my job with other but it is a requirement to publish here. </p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 10 Sep 2025 22:04:32 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nd1go9/i_created_a_prettyprinted_dir_function_to_make/</link><title>I created a pretty-printed dir function to make debugging complex classes easier</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nd1go9/i_created_a_prettyprinted_dir_function_to_make/</guid><comments>https://www.reddit.com/r/Python/comments/1nd1go9/i_created_a_prettyprinted_dir_function_to_make/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1nd1go9/i_created_a_prettyprinted_dir_function_to_make/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>What My Project Does</strong></p><p>You can check it out on github:¬†<a href="https://pypi.org/project/pretty-dir/">https://pypi.org/project/pretty-dir/</a></p><p>This library generates a better <strong>dir</strong> output for debugging. For a quick example, check out the <a href="https://github.com/douglassimonsen/ppdir/raw/main/example_images/before.png">with dir</a> and <a href="https://github.com/douglassimonsen/ppdir/raw/main/example_images/after.png">with ppdir</a> outputs using a simple pydantic model.</p><p><strong>Target Audience</strong></p><p>This is mainly aimed at developers who are debugging code that uses any libraries that have large, complex, deeply nested classes. Libraries such as pydantic, dataclasses, and openpyxl.</p><p><strong>Comparison</strong></p><p>It exists in a similar niche as icecream and rich.inspect where it&#39;s meant to improve the debugging experience. Unlike similar libraries, this only shows the structure, not the values themselves. This is valuable in pydantic environments, where instances can be too verbose to be meaningful when printed to the console.</p><p><strong>Details</strong></p><p>The library uses the output of the <strong>dir(obj)</strong> function as a baseline, but improves the output in a number of ways:</p><ul><li>Visually groups the methods and attributes by the classes they were defined on. Therefore, if you&#39;re subclassing the <a href="https://docs.pydantic.dev/latest/api/base_model/">pydantic.BaseModel</a> class, it separates the generic basemodel methods from the subclass&#39; specific methods.</li><li>Pulls the first line of the docstrings for the class, all methods, and all class attributes.</li><li>Can enable showing the function signature for all class methods</li><li>By default, hides private and and dunder methods from the outputs</li><li>Prints the source code location of all parent classes</li><li>Uses <a href="https://pypi.org/project/colorama/">colorama</a> to color the different sections of the output</li></ul><p>I&#39;ve set it to automatically import (see <strong>Auto-loading in PDB (Breakpoint)</strong> on PyPI) when I use breakpoint() and it&#39;s been a nice quality of life improvement!</p><p>This is my first project I expect other people to use, so let me know if I can improve anything!</p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 10 Sep 2025 07:11:36 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1ncy8av/most_performant_python_compilerstranspilers_in/</link><title>Most Performant Python Compilers/Transpilers in 2025</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1ncy8av/most_performant_python_compilerstranspilers_in/</guid><comments>https://www.reddit.com/r/Python/comments/1ncy8av/most_performant_python_compilerstranspilers_in/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1ncy8av/most_performant_python_compilerstranspilers_in/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Today I find myself in the unfortunate position to create a program that must compile arbitrary python code :(  For the use case I am facing now performance is everything, and luckily the target OS for the executable file will only be linux. The compiled codes will be standalone local computational tools without any frills (no guis, no i|o or r|w operations, no system access, and no backend or configuration needs to pull in). Python code is &gt;=3.8 and can pull in external libraries (eg: numpy). However, the codes may be multithreaded/multiprocessed and any static type-like behavior is not guaranteed.</p><p>Historically I have used tools like pyinstaller, py2exe, py2app, which work robustly, but create stand alone executable files that are often pretty slow. I have been looking at a host of transpilers instead, eg: <a href="https://github.com/dbohdan/compilers-targeting-c?tab=readme-ov-file">https://github.com/dbohdan/compilers-targeting-c?tab=readme-ov-file</a>, and am somewhat overwhelmed by the amount of choices therein. Going through stackoverflow naturally recovered a lot of great recommendations that were go-to&#39;s 10-20 years ago, but do not have much promise for recent python versions. Currently I am considering:<br/>wax <a href="https://github.com/LingDong-/wax">https://github.com/LingDong-/wax</a> ,<br/>11l-lang <a href="https://11l-lang.org/transpiler/">https://11l-lang.org/transpiler/</a>,<br/>nuitka <a href="https://nuitka.net/">https://nuitka.net/</a>,<br/>prometeo  <a href="https://github.com/zanellia/prometeo">https://github.com/zanellia/prometeo</a>,<br/>pytran <a href="https://pythran.readthedocs.io/en/latest/">https://pythran.readthedocs.io/en/latest/</a>,<br/>rpython <a href="https://rpython.readthedocs.io/en/latest/">https://rpython.readthedocs.io/en/latest/</a>,<br/>or py14  <a href="https://github.com/lukasmartinelli/py14">https://github.com/lukasmartinelli/py14</a>.<br/>However, this is a lot to consider without rigorously testing all of them out. Does anyone on this sub have experience in modern Transpilers or other techniques for compiling numerical python codes for linux? If so, can you share any tools, techniques, or general guidance? Thank you!</p><p>Edit for clarification:<br/>This will be placed in a user facing application wherein users can upload their tools to be autonomously deployed in a on demand/dynamic runtime basis. Since we cannot know all the codes that users are uploading, a lot of the traditional and well defined methods are not possible. We are including C, C++, Rust, Fortran, Go, and Cobol compilers to support these languages, but seeking a similar solution for python.</p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 10 Sep 2025 04:43:04 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1ncmlwv/should_i_give_away_my_app_to_my_employer_for_free/</link><title>Should I give away my app to my employer for free?</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1ncmlwv/should_i_give_away_my_app_to_my_employer_for_free/</guid><comments>https://www.reddit.com/r/Python/comments/1ncmlwv/should_i_give_away_my_app_to_my_employer_for_free/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Python/comments/1ncmlwv/should_i_give_away_my_app_to_my_employer_for_free/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I work for a fintech company in the UK (in operations to be specific) however my daily role doesn‚Äôt require any coding knowledge. I have built up some python knowledge over the past few years and have developed an app that far outperforms the workflow tool my company currently uses. I have given hints to my manager that I have some coding knowledge and given them snippets of the tool I‚Äôve created, she‚Äôs pretty much given me free reign to stop any of my usual tasks and focus on this full time. My partner used to work for the same company in the finance department so I know they paid over ¬£200k for 3 people to develop the current workflow tool (these developers had no operations experience so built something unfit for purpose). I‚Äôve estimated if I can get my app functional it would save the company ¬£20k per month (due to all the manual work we usually have to do vs what I can automate). My manager has already said this puts me in a good position for a decent bonus next year (it wouldn‚Äôt be anymore than ¬£10k) so I‚Äôm a little stuck on what to do and if I‚Äôm sounding greedy. </p><p>Has anyone ever been in a similar position? </p><p>EDIT TITLE: I know it‚Äôs not ‚Äòfor free‚Äô as of course I‚Äôm paid to do my job. But I would be handing over hours of work that I haven‚Äôt been paid for. </p></div><!-- SC_ON --></section>]]></description><pubDate>Tue, 09 Sep 2025 21:20:58 +0530</pubDate></item><item><link>https://www.reddit.com/r/Python/comments/1nckydw/cythonize_python_code/</link><title>Cythonize Python Code</title><guid isPermaLink="true">https://www.reddit.com/r/Python/comments/1nckydw/cythonize_python_code/</guid><comments>https://www.reddit.com/r/Python/comments/1nckydw/cythonize_python_code/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Python/comments/1nckydw/cythonize_python_code/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><h1>Context</h1><p>This is my first time messing with <strong>Cython</strong> (or really anything related to optimizing Python code).<br/>I usually just stick with yielding and avoiding keeping much in memory, so bear with me.</p><h1>Context</h1><p>I‚Äôm building a Python project that‚Äôs kind of like <code>zipgrep</code> / <code>ugrep</code>.<br/>It streams through archive(s) file contents (nothing kept in memory) and searches for whatever pattern is passed in.</p><h1>Benchmarks</h1><p>(Results vary depending on the pattern, hence the wide gap)</p><ul><li>‚úÖ <strong>~15‚Äì30x faster</strong> than <code>zipgrep</code> (expected)</li><li>‚ùå <strong>~2‚Äì8x slower</strong> than <code>ugrep</code> (also expected, since it‚Äôs C++ and much faster)</li></ul><p>I tried:</p><ul><li><code>cythonize</code> from <a href="http://Cython.Build"><code>Cython.Build</code></a> with setuptools</li><li>Nuitka</li></ul><p>But the performance was basically identical in both cases. I didn‚Äôt see any difference at all.<br/>Maybe I compiled Cython/Nuitka incorrectly, even though they both built successfully?</p><h1>Question</h1><p>Is it actually worth:</p><ul><li>Manually writing <code>.c</code> files</li><li>Switching the right parts over to <code>cdef</code></li></ul><p>Or is this just one of those cases where Python‚Äôs overhead will always keep it behind something like <code>ugrep</code>?</p><p>Gitub Repo: <a href="https://github.com/yousefabuz17/pyzipgrep">pyzipgrep</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Tue, 09 Sep 2025 20:18:10 +0530</pubDate></item></channel></rss>
