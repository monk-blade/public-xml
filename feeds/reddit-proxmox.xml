<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><atom:link href="http://192.168.1.132/?platform=reddit&amp;subreddit=Proxmox&amp;averagePostsPerDay=3&amp;content&amp;view=rss" rel="self" type="application/rss+xml"/><title>/r/Proxmox</title><description>Hot posts in /r/Proxmox (roughly 3 posts per day)</description><link>https://www.reddit.com/r/Proxmox/</link><language>en-us</language><lastBuildDate>Thu, 11 Sep 2025 12:43:17 +0000</lastBuildDate><generator>Upvote RSS</generator><image><url>http://192.168.1.132//app/cache/images/styles-redditmedia-com-t5_2w0wn-styles-communityIcon_l9fx4v8n3cw71-144x400.png</url><title>/r/Proxmox</title><link>https://www.reddit.com/r/Proxmox/</link><width>144</width><height>144</height></image><item><link>https://www.reddit.com/r/Proxmox/comments/1ndq6kz/newb_storage_question/</link><title>Newb Storage question</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1ndq6kz/newb_storage_question/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1ndq6kz/newb_storage_question/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1ndq6kz/newb_storage_question/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Starting a Proxmox homelab at home, one of the major use cases i have is for preservation of media and its sharing using Plex/Jellyfish. My SFF HP ProDesk 1 250g NVME and a 10TB SATA internally im trying to make the best use of. </p><p>I&#39;m trying to make the 10TB harddrive act like general available storage for the network for an ARR VM to load media onto and for it to be accessible to other consumers on the network. Basic stuff i think. </p><p>I spun up a TurnKey Mediaserver VM and gave it the following hardware in pic thinking it&#39;ll act like a NAS. </p><p><a href="https://preview.redd.it/ljzgyahlieof1.png?width=1166&amp;format=png&amp;auto=webp&amp;s=e1700c44fb301aebe5bab1fa0c6b889d575a427f">I dont remmebr why i split up the 10T drive but i did this</a></p><p>Ever since that i have had a very not fun time syncing userIDs across Linux VMs and messing with harddrive mounting and fstab settings.</p><p>Is there a better, easier way of doing this without shelling out more money for additional hardware? or should i just get an external NAS (or standalone baremetal machine + drives)?</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 11 Sep 2025 02:31:08 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1ndptlr/pbs_backup_check_script_for_home_assistant/</link><title>PBS Backup Check script for Home Assistant</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1ndptlr/pbs_backup_check_script_for_home_assistant/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1ndptlr/pbs_backup_check_script_for_home_assistant/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1ndptlr/pbs_backup_check_script_for_home_assistant/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I wanted a simple way to monitor if all my PBS backups are fresh (within 24h) and send the status into Home Assistant. Here’s the script I came up with, and since I found it useful, I’m sharing in case others do too.</p><p>pbs-fresh-check.sh script:</p><pre><code>#!/bin/bashexport PBS_PASSWORD=&quot;pbs-password-here&quot;REPO=&quot;root@pam@pbs-ip-address-here:name-of-your-pbs-datastore-here&quot;now=$(date +%s)ALL_OK=1  # Assume all are OK initiallywhile read -r entry; do    backup_time=$(echo &quot;$entry&quot; | jq -r &#39;.latest_backup&#39;)    diff=$((now - backup_time))    if [ &quot;$diff&quot; -gt 86400 ]; then  # 86400 seconds = 24 hours        ALL_OK=0        break    fidone &lt; &lt;(proxmox-backup-client snapshot list --repository &quot;$REPO&quot; --output-format json \| jq -c &#39;group_by(.[&quot;backup-id&quot;])[] | {repo: .[0][&quot;backup-id&quot;], latest_backup: (max_by(.[&quot;backup-time&quot;])[&quot;backup-time&quot;])}&#39;)if [ &quot;$ALL_OK&quot; -eq 1 ]; then    echo &quot;ON&quot;else    echo &quot;OFF&quot;fi</code></pre><p>command_line.yaml:</p><pre><code># PBS Backup Check  - binary_sensor:      name: &quot;PBS Backup Check&quot;      scan_interval: 3600      command: ssh -i /config/.ssh/id_rsa -o StrictHostKeyChecking=no root@pve-host-ip-address &#39;/home/scripts/pbs-fresh-check.sh&#39;      payload_on: &quot;ON&quot;      payload_off: &quot;OFF&quot;</code></pre></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 11 Sep 2025 02:16:38 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1ndp7z0/what_role_does_a_nas_play_in_your_homelab_proxmox/</link><title>What role does a NAS play in your (homelab) Proxmox environment?  Does it matter what OS the NAS uses?  (Will Windows be fine?)</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1ndp7z0/what_role_does_a_nas_play_in_your_homelab_proxmox/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1ndp7z0/what_role_does_a_nas_play_in_your_homelab_proxmox/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Proxmox/comments/1ndp7z0/what_role_does_a_nas_play_in_your_homelab_proxmox/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I&#39;m having a lot of fun learning Proxmox and Linux (anecdote: I&#39;m currently liking the look of Q4OS).  </p><p>I&#39;m formerly a Windows-only guy and so my home infrastructure (different than homelab) has been Hyper-V and Windows VMs of various flavors, including Windows servers.  I have a separate bare metal box for Windows Server 2022 as a file server (for this important role, I didn&#39;t want to virtualize it and the hardware is so inexpensive these days).  </p><p>What role does a NAS play in your home lab situation (i.e. not a production environment)?  </p><p>I run &quot;only&quot; gigabit networking (not 2.5 or anything faster).  So I&#39;m not planning to have my VMs on a NAS.  Currently all the VMs are on an NVME disk (non-raid) internal to each Proxmox box and I don&#39;t think I need to change that.  Performance has been zippy and I don&#39;t need super-high availability.</p><p>I could see myself storing the data (photos and media) on the NAS though and that could have redundant storage because the data would be important.</p><p>More questions:</p><p>1) Does it matter what OS is used for the NAS?  I ask because I&#39;m very comfortable with Windows and I feel that a Windows Server box is very stable and performant. </p><p>2)  Would I have any problems having Promox and it&#39;s VMs store their data (not the VM OS) on the Windows Server that is functionally a NAS?  As hinted in my opening line, I&#39;m very much a Linux noob.  I would love to continue to use my existing Windows Server &quot;NAS&quot; and not erect a new more &quot;Linux-oriented&quot; NAS.</p><p>I do want to learn about Proxmox Backup Server.  And I read with interest recently about how someone has PBS running as a VM on their TrueNAS box.  I should have asked him about how he found that combination.  Anyhow, I&#39;m hoping I can use my Windows Server as the target &quot;disk&quot; for PBS backups initially, though I do relish the opportunity to learn about TrueNAS.</p></div><!-- SC_ON --></section>]]></description><pubDate>Thu, 11 Sep 2025 01:52:22 +0530</pubDate></item><item><link>https://i.redd.it/rvzz1g7szdof1.jpeg</link><title>Failed node in two node cluster (i.redd.it)</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1ndnh1j/failed_node_in_two_node_cluster/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1ndnh1j/failed_node_in_two_node_cluster/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1ndnh1j/failed_node_in_two_node_cluster/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Woke up to no internet at the homelab and saw this after trying to reboot my primary proxmox host. </p><p>I have two hosts in what I thought was a redundant config but I’m guessing I didn’t have ceph set up all the way. (Maybe because I didn&#39;t have a ceph monitor on the second node.) None of the cluster VMs will start even after setting pvecm expect 1.</p><p>I don’t have anything critical on this pair but I would like to recover if possible rather than nuke and pave.   Is there a way to reinstall proxmox 8.2.2 without distroying the VMs and OSDs? I have the original installer media…</p><p>I did at one time take a stab at setting up PBS on a third host but don&#39;t know if I had that running properly either. But I&#39;ll look into it.</p><p>Thanks all!</p></div><!-- SC_ON --></section><section class='preview-image'><p>&nbsp;</p><img src='https://i.redd.it/rvzz1g7szdof1.jpeg' /></section>]]></description><pubDate>Thu, 11 Sep 2025 00:43:18 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1ndj2qg/how_often_do_you_update_proxmox/</link><title>How often do you update Proxmox</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1ndj2qg/how_often_do_you_update_proxmox/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1ndj2qg/how_often_do_you_update_proxmox/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1ndj2qg/how_often_do_you_update_proxmox/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hi,</p><p>How often do you update your Proxmox servers? Also, do you reboot after the update? </p><p>I typically install updates every month on my Linux machines unless a patch for a critical vulnerability is released.</p><p>Please advise.<br/>Thanks!</p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 10 Sep 2025 22:01:28 +0530</pubDate></item><item><link>https://i.redd.it/kvdoudae8bof1.png</link><title>Proxmox-GitOps: Extensible GitOps container automation for Proxmox ("Everything-as-Code" on PVE 8.4-9.0 / Debian 13.1 default base) (i.redd.it)</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1nda2bo/proxmoxgitops_extensible_gitops_container/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1nda2bo/proxmoxgitops_extensible_gitops_container/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Proxmox/comments/1nda2bo/proxmoxgitops_extensible_gitops_container/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I have shared my project Proxmox-GitOps — an extensible, self-bootstrapping GitOps environment for Proxmox.</p><p>It has matured and is aligned with current Proxmox 9.0 and Debian Trixie which is used as container base configuration, so I’d like to re-introduce it for anyone interested in a Homelab-as-Code starting point.</p><p><strong>GitHub:</strong> <a href="https://github.com/stevius10/Proxmox-GitOps">https://github.com/stevius10/Proxmox-GitOps</a></p><ul><li>One-command bootstrap: deploy to Docker, Docker deploy to Proxmox</li><li>Consistent container base configuration: default app/config users, automated key management, tooling — deterministic, idempotent setup</li><li>Application-logic container repositories: app logic lives in each container repo; shared libraries, pipelines and integration come by convention</li><li>Monorepository with recursively referenced submodules: runtime-modularized, suitable for VCS mirrors, automatically extended by libs</li><li>Pipeline concept<ul><li>GitOps environment runs identically in a container; pushing the codebase (monorepo + container libs as submodules) into CI/CD</li><li>This triggers the pipeline from within itself after accepting pull requests: each container applies the same processed pipelines, enforces desired state, and updates references</li></ul></li><li>Provisioning uses Ansible via the Proxmox API; configuration inside containers is handled by Chef/Cinc cookbooks</li><li>Shared configuration automatically propagates</li><li>Containers integrate seamlessly by following the same predefined pipelines and conventions — at container level and inside the monorepository</li><li>The control plane is built on the same base it uses for the containers, so verifying its own foundation implies a verified container base — a reproducible and adaptable starting point for container automation 🙂</li></ul><p><strong>Major changes</strong></p><ul><li>PVE 8.4–9.0 compatibility with Debian 13.1 (trixie) base configuration and adjusted container libs</li><li>Gitea and UI customization for container information</li><li>Tasks as abstraction for automated script execution (implemented container status checks)</li></ul><p><strong>Configuration examples</strong></p><p><a href="https://github.com/stevius10/Proxmox-GitOps/wiki/Example-Configuration">https://github.com/stevius10/Proxmox-GitOps/wiki/Example-Configuration</a></p><p>It’s still under development, so there may be rough edges — feedback, experiences, or just a thought are more than welcome!</p><p>And really thanks a lot for the interest: I really didn&#39;t expect a rather niche project to be liked by a hundred people on GitHub. Means and motivates a lot — hope it can be useful for others, too!</p></div><!-- SC_ON --></section><section class='preview-image'><p>&nbsp;</p><img src='https://i.redd.it/kvdoudae8bof1.png' /></section>]]></description><pubDate>Wed, 10 Sep 2025 15:32:42 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1ncvwn9/can_borg_backup_be_used_to_create_and_restore/</link><title>Can Borg Backup be used to create and restore baremetal images of a proxmox server?</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1ncvwn9/can_borg_backup_be_used_to_create_and_restore/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1ncvwn9/can_borg_backup_be_used_to_create_and_restore/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1ncvwn9/can_borg_backup_be_used_to_create_and_restore/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I am working with proxmox 9.0.6 and I have successfully installed the most recent borg backup version via the &#39;apt&#39; package manager.</p><p>My server is a HP Proliant Microserver Gen10 with 8TB HW RAID-10 and 32 GB RAM.</p><p>My goal is to be able to create a full baremetal backup of my proxmox server and then be able to fully recover it in case of a catastrophic failure.</p><p>My VM and LXC stuff is properly getting backed up, but if the server itself gets borked, I have to go through the whole tedious process of re-installing proxmox and remember which utilites I need to install (ie: HP raid tools, APC UPS driver, scripts, etc).</p><p>From what I have read on the borg backup site, this seems to be possible.</p><p>There is an example of how to create a bare metal backup, but I can&#39;t find any example of how to recover the system from this backup.</p><p>If anyone has done this successfully, or has a better idea on how to do this, I am open and appreciative to suggestions.</p><p>Cheers!</p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 10 Sep 2025 03:06:28 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1ncv0px/added_a_second_msa2_node_to_the_cluster_along/</link><title>Added a second MS-A2 node to the cluster along with Arc Pro A40 GPU and... I hate it</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1ncv0px/added_a_second_msa2_node_to_the_cluster_along/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1ncv0px/added_a_second_msa2_node_to_the_cluster_along/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1ncv0px/added_a_second_msa2_node_to_the_cluster_along/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Lack of fan control is really annoying on these Intel cards under linux... really we have no other options than pinning it to Windows for control? </p><p>One would think that basic fan control should be part of cards onboard firmware. </p></div><!-- SC_ON --></section>]]></description><pubDate>Wed, 10 Sep 2025 02:31:12 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1ncppug/unprivileged_lxcs_and_mount_points_lxcidmap/</link><title>Unprivileged LXCs and Mount Points (lxc.idmap confusion)</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1ncppug/unprivileged_lxcs_and_mount_points_lxcidmap/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1ncppug/unprivileged_lxcs_and_mount_points_lxcidmap/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Proxmox/comments/1ncppug/unprivileged_lxcs_and_mount_points_lxcidmap/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I have a home lab with a fairly basic setup (I think). On my main Proxmox host, I have a zfs cluster for my nas. I have an LXC for immich and I&#39;m trying to create an upload directory on my nas that I will then passthrough to immich. I have a user on my proxmox host of 1001 that I want immich to read and write as. I did the following in the <code>/etc/pve/lxc#.conf</code> file:</p><pre><code>lxc.idmap: u 0 100000 1001lxc.idmap: g 0 100000 1001lxc.idmap: u 1001 1001 1lxc.idmap: g 1001 1001 1lxc.idmap: u 1002 101002 64534lxc.idmap: g 1002 101002 64534</code></pre><p>I also edited the <code>/etc/subuid</code>:</p><pre><code>root:1001:1</code></pre><p>and the <code>/etc/subgid</code>:</p><pre><code>root:1001:1</code></pre><p>When I start the container, I can see the mount point:</p><pre><code>root@immich:~# ls -all /mnt/total 23drwxr-xr-x  4 root   root     4 Sep  9 10:15 .drwxr-xr-x 17 root   root    21 Sep  9 10:25 ..drwxr-xr-x  2   1001    1001  3 Sep  9 10:25 uploads</code></pre><p>And I can write to the directory from the container:</p><pre><code>root@immich:~# ls -all /mnt/uploadstotal 2drwxr-xr-x 2 1001 1001 3 Sep  9 10:25 .drwxr-xr-x 4 root root 4 Sep  9 10:15 ..-rw-r--r-- 1 root root 0 Sep  9 10:25 test.txt</code></pre><p>However, on the host, that file shows owned by 100000, I thought it would map over to the 1001 user (nasuser):</p><pre><code>root@proxmox:# ls -all photo_uploads/total 15drwxr-xr-x  2 nasuser nasuser  3 Sep  9 10:25 .drwxr-xr-x 18 root    root    18 Sep  9 10:12 ..-rw-r--r--  1  100000  100000  0 Sep  9 10:25 test.txt</code></pre><p>I thought the idea of idmap was that I would write a file from an LXC and dictate the user id that it would write to on the host. Is my idea wrong? Or is what I&#39;m attempting to do just wrong? Thanks!</p></div><!-- SC_ON --></section>]]></description><pubDate>Tue, 09 Sep 2025 23:16:43 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1ncp537/best_cpu_emulation/</link><title>Best CPU emulation</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1ncp537/best_cpu_emulation/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1ncp537/best_cpu_emulation/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1ncp537/best_cpu_emulation/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hello,</p><p>is there some information about which would currently be the best CPU setting in PVE? Both Linux and Windows, for instance. I just found out that &quot;host&quot; setting on one of my VMs brings totally weird behavior, the CPU is permanently on 50% and not coming down, while x86-64-v2-AES, the default setting, seems to be fine.</p><p>Host seems to be recommended for max performance. However the VM behaves really badly.</p><p>Sooo, what&#39;s right?</p></div><!-- SC_ON --></section>]]></description><pubDate>Tue, 09 Sep 2025 22:55:25 +0530</pubDate></item><item><link>https://www.reddit.com/gallery/1ncigfp</link><title>Miniforum nab9 failing to boot after months of use (Gallery)</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1ncigfp/miniforum_nab9_failing_to_boot_after_months_of_use/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1ncigfp/miniforum_nab9_failing_to_boot_after_months_of_use/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Proxmox/comments/1ncigfp/miniforum_nab9_failing_to_boot_after_months_of_use/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Yesterday while at work I was notified that my VMs became unreachable. I was able to ping the hypervisor but unable to access its GUI. I was unable to ping 2/3rd of my VMs and nothing was accessible. I called up the wife and asked her to reboot the box. Unfortunately, nothing came up and no lights on the NICs either. </p><p>When i got home in the afternoon, i rebooted again, no luck. I then pulled it from the rack and brought it to the desk, plugged it in, and i see a kernel panic. There are 2 x 32 GB sticks of ram. I try one at a time, no change. I tried to use the proxmox advanced options and tried both kernel options, and no change. I created  a proxmox  usb drive and tried to do a rescue, more kernel panics. Tried to install fresh and it wont install and gives a kernel panic. I created a debian bootable USB, more kernel panics. The BIOS of the box is on the current version provided by their website. </p><p>Any ideas? I suppose the last step is to try a different hard drive. It’s just using 1tb drive that came with it but i would assume it would say something along the lines of unable to find boot.</p></div><!-- SC_ON --></section><section class='embedded-media'><p><img src="https://preview.redd.it/tt82y9gq15of1.jpg?width=5712&amp;format=pjpg&amp;auto=webp&amp;s=4235eacb99d04df28a5928b40895ea11acacbcfb" height="4284" width="5712" /></p><p><img src="https://preview.redd.it/wxe5m9gq15of1.jpg?width=5712&amp;format=pjpg&amp;auto=webp&amp;s=58f920cfde96193afde382927ee6f4410d800fc7" height="4284" width="5712" /></p><p><img src="https://preview.redd.it/4prjbhgq15of1.jpg?width=5712&amp;format=pjpg&amp;auto=webp&amp;s=202904197ed5b49d0bbac3e01cbd677f854963e4" height="4284" width="5712" /></p><p><img src="https://preview.redd.it/kdmx6cgq15of1.jpg?width=5712&amp;format=pjpg&amp;auto=webp&amp;s=9ae0887e118285673a7b7b0ce3aab8ff2aeab4bd" height="4284" width="5712" /></p><p><img src="https://preview.redd.it/33u26zfq15of1.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;s=3a2255570f56b202eef1a35d364be639823d959c" height="3024" width="4032" /></p><p><img src="https://preview.redd.it/w18qehgq15of1.jpg?width=5712&amp;format=pjpg&amp;auto=webp&amp;s=b14727294acadfd74ae263f140d0d8448ff4ba75" height="4284" width="5712" /></p><p><img src="https://preview.redd.it/gpaosyfq15of1.jpg?width=1125&amp;format=pjpg&amp;auto=webp&amp;s=f69b55357823e9169dd83e3a9d3ece0eecfd1577" height="533" width="1125" /></p></section>]]></description><pubDate>Tue, 09 Sep 2025 18:38:23 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1nc9cp7/newbie_proxmox_wont_install/</link><title>Newbie - Proxmox won’t install…</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1nc9cp7/newbie_proxmox_wont_install/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1nc9cp7/newbie_proxmox_wont_install/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1nc9cp7/newbie_proxmox_wont_install/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>New user. Tried burning the ISO using Rufus and Etcher. It boots into the USB, I pick graphical interface and it just stops each time on the loading drivers.</p><p>Any suggestions to move me forward?This is an 5800x X370 motherboard 16GB RAM and a 3080FE, nothing too old or new…</p></div><!-- SC_ON --></section>]]></description><pubDate>Tue, 09 Sep 2025 09:47:12 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1nc8q7l/eno1_detected_hardware_unit_hang/</link><title>eno1: Detected Hardware Unit Hang</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1nc8q7l/eno1_detected_hardware_unit_hang/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1nc8q7l/eno1_detected_hardware_unit_hang/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Proxmox/comments/1nc8q7l/eno1_detected_hardware_unit_hang/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hello,</p><p>Over the last month, I&#39;ve been losing connection to Proxmox and all of the VM&#39;s I run in it. When I view the system log it is full of errors with the following</p><p><code>Sep 08 21:33:15 pve kernel: e1000e 0000:00:1f.6 eno1: Detected Hardware Unit Hang:</code></p><p>It seems to happen overnight, usually around 1AM. The first time I noticed, I did a hard restart on the box, and then I updated Proxmox to 8.4.12. It&#39;s continuing to happen, so this time I unplugged my ethernet cable and then plugged it back in and everything came up.</p><p>I have seen posts on forums about something similar and the suggested remedy was to change/update the driver, but that&#39;s a bit foreign to me.</p><p>I&#39;m also not sure if it is driver or network related. The only reason I wonder if it is network related is that I had a similar problem a few months back with my work laptop. It would drop the connection overnight, and I&#39;d have to disable/enable the ethernet adapter to reconnect or restart the laptop. That went away on the laptop, but now it is here on my Proxmox box.</p><p>It&#39;s also worth mentioning that I did set up a cronjob to keep my freemyip DDNS updated, and that cronjob coincides with the issue. It may be that I just need to get rid of that cronjob.</p><p>Before I look more into the network side of it (Unifi system) I wanted to see if there was anything I could check out in Proxmox first.</p><p>Thanks!</p></div><!-- SC_ON --></section>]]></description><pubDate>Tue, 09 Sep 2025 09:14:41 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1nc3t8v/anyone_upgraded_to_pve_9_on_old_hw_ie_dell_r720/</link><title>Anyone Upgraded to PVE 9 on old HW (i.e. Dell R720)</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1nc3t8v/anyone_upgraded_to_pve_9_on_old_hw_ie_dell_r720/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1nc3t8v/anyone_upgraded_to_pve_9_on_old_hw_ie_dell_r720/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1nc3t8v/anyone_upgraded_to_pve_9_on_old_hw_ie_dell_r720/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I see the note in the upgrade guide that older HW isn&#39;t thoroughly tested. I&#39;m curious if anyone has upgraded on older hardware such as a Dell R720 server?</p></div><!-- SC_ON --></section>]]></description><pubDate>Tue, 09 Sep 2025 05:19:54 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1nbrnib/downsize_vm_size/</link><title>Downsize VM size?</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1nbrnib/downsize_vm_size/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1nbrnib/downsize_vm_size/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1nbrnib/downsize_vm_size/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Running Proxmox 9 with a Debian 13 VM. </p><p>I was dumb, couldn&#39;t figure out how to get Nextcloud upload working in chunks and had to increase the VM size by 80GB to allow uploading of a 70GB file, since it wanted it to store the whole file inside the VM before moving to the NAS storage.</p><p>Now the VM is 150GB in size, vastly larger than it needs to be, which slows down backups, etc. </p><p>How can I reduce the VM size? </p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 08 Sep 2025 21:30:11 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1nbpqd3/terraform_on_proxmox/</link><title>Terraform on Proxmox</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1nbpqd3/terraform_on_proxmox/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1nbpqd3/terraform_on_proxmox/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1nbpqd3/terraform_on_proxmox/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hey,</p><p>I am looking to practice IaC on my Proxmox VE. When I looked opentofu I found 2 providers, one is</p><p>BPG/proxmoxand the other istelmate/proxmox</p><p>Both have 1500-2500 stars on github.How do you choose?</p><p>Aim is nothing super fancy but having a simple homelab with what I can play around w Opentofu+Ansible, maybe adding a second server, I have a proxy that has wireguard in it, I just hate how everything is clickops and want to have a single source of truth. </p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 08 Sep 2025 20:17:58 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1nbpfhg/proxmox_9_debian_13_sending_systemd_journal_logs/</link><title>Proxmox 9 / Debian 13 – Sending systemd journal logs to Graylog</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1nbpfhg/proxmox_9_debian_13_sending_systemd_journal_logs/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1nbpfhg/proxmox_9_debian_13_sending_systemd_journal_logs/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1nbpfhg/proxmox_9_debian_13_sending_systemd_journal_logs/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hi everyone,</p><p>I recently upgraded to Proxmox 9 (based on Debian 13), and I noticed that traditional syslog (rsyslog) is no longer used by default. Now, systemd-journald is the default logging system.</p><p>I’d like to forward Proxmox logs to Graylog.</p><p>Has anyone successfully done this? How did you set it up? Any example configurations would be very helpful.</p><p>Thanks!</p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 08 Sep 2025 20:06:14 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1nbmddv/vmware_free/</link><title>VMware Free</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1nbmddv/vmware_free/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1nbmddv/vmware_free/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1nbmddv/vmware_free/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Seeing the words <strong>VMware</strong> and <strong>Free</strong> together had significant meaning, for a long time - some reference to the free version of VMware.</p><p>Enter Broadcom, and what we wished to see was them recanting their decisions, making <strong>VMware Free</strong> for those with more time and risk appetite than money.</p><p>Now the two words together has a new significant meaning - good news once more, a statement saying I’ve been freed from VMware.</p><p>Isn’t it poetic? Mahatma Ghandi said “Be the change you wish to see in the world.” So there you go, we’re <strong>VMware Free</strong>: we now are the change we wished to see in the world.</p><p>Well done my friends, bloody good show.</p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 08 Sep 2025 17:57:44 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1nblo7x/using_vms_for_gaming/</link><title>Using VMs for gaming</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1nblo7x/using_vms_for_gaming/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1nblo7x/using_vms_for_gaming/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1nblo7x/using_vms_for_gaming/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I have a 5090, 9950X3D and 64GB of ram, in addition, im gonna have an A40 soon. Could I use proxmox, to split my 9950X3D into a 9800X and 9800X3D equivalent for 2 VMs, give both VMs 32GB of ram, assign one the 5090 and another the A40, and then use one VM for gaming myself, while a friend plays remotely on the other one?</p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 08 Sep 2025 17:24:56 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1nbl7c9/proxmox_ceph_cluster_network_layout_feedback/</link><title>Proxmox + Ceph Cluster Network Layout — Feedback Wanted</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1nbl7c9/proxmox_ceph_cluster_network_layout_feedback/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1nbl7c9/proxmox_ceph_cluster_network_layout_feedback/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Proxmox/comments/1nbl7c9/proxmox_ceph_cluster_network_layout_feedback/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>Cluster Overview</strong></p><p><strong>Proxmox Network:</strong></p><ul><li><code>enoA1</code> → <code>vmbr0</code> → <a href="http://10.0.0.0/24"><code>10.0.0.0/24</code></a> → 1 Gb/s → Management + GUI</li><li><code>enoA2</code> → <code>vmbr10</code> → <a href="http://10.0.10.0/24"><code>10.0.10.0/24</code></a> → 1 Gb/s → Corosync cluster heartbeat</li><li><code>ensB1</code> → <code>vmbr1</code> → <a href="http://10.1.1.0/24"><code>10.1.1.0/24</code></a> → 10 Gb/s → VM traffic / Ceph public</li></ul><p><strong>Ceph Network:</strong></p><ul><li><code>ensC1</code> → <a href="http://10.2.2.2/24"><code>10.2.2.2/24</code></a> → 25 Gb/s → Ceph cluster traffic (MTU 9000)</li><li><code>ensC2</code> → <a href="http://10.2.2.1/24"><code>10.2.2.1/24</code></a> → 25 Gb/s → Ceph cluster traffic (MTU 9000)</li></ul><p><strong>ceph.conf (sanitized)</strong></p><pre><code>[global]auth_client_required = cephxauth_cluster_required = cephxauth_service_required = cephxcluster_network = 10.2.2.0/24public_network = 10.2.2.0/24mon_host = 10.2.2.1 10.2.2.2 10.2.2.3fsid = &lt;redacted&gt;mon_allow_pool_delete = truems_bind_ipv4 = truems_bind_ipv6 = falseosd_pool_default_size = 3osd_pool_default_min_size = 2[client]keyring = /etc/pve/priv/$cluster.$name.keyring[mon.node1]public_addr = 10.2.2.1[mon.node2]public_addr = 10.2.2.2[mon.node3]public_addr = 10.2.2.3</code></pre><p><strong>corosync.conf (sanitized)</strong></p><pre><code>logging {  debug: off  to_syslog: yes}nodelist {  node {    name: node1    nodeid: 1    quorum_votes: 1    ring0_addr: 10.0.10.1  }  node {    name: node2    nodeid: 2    quorum_votes: 1    ring0_addr: 10.0.10.2  }  node {    name: node3    nodeid: 3    quorum_votes: 1    ring0_addr: 10.0.10.3  }}quorum {  provider: corosync_votequorum}totem {  cluster_name: proxmox-cluster  config_version: 3  interface {    linknumber: 0  }  ip_version: ipv4-6  link_mode: passive  secauth: on  version: 2}</code></pre><p>When I added an ssd pool and moved my vm to it from hdd led to my node crashing. I asked for advice on reddit and they said that this was because of network saturation. So I am looking for advice and improvements. I have found two issues in my config and that is to have seperate cluster and public network. Also to have to have a secondary failover corosync ring interface. Any thoughts you have?</p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 08 Sep 2025 17:00:44 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1nbhgcn/no_login_monitoring_view_of_proxmox/</link><title>No login monitoring view of Proxmox</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1nbhgcn/no_login_monitoring_view_of_proxmox/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1nbhgcn/no_login_monitoring_view_of_proxmox/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1nbhgcn/no_login_monitoring_view_of_proxmox/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Is there a no login monitoring view of my node?</p><p>I&#39;m doing this: <a href="https://www.reddit.com/r/homelab/comments/1n94ndx/homelab_monitoring_on_a_pegbaord/">https://www.reddit.com/r/homelab/comments/1n94ndx/homelab_monitoring_on_a_pegbaord/</a> </p><p>but Proxmor requires login which i&#39;d like to avoid. </p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 08 Sep 2025 13:09:01 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1nbgwt6/any_downside_to_proxmox/</link><title>Any downside to proxmox?</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1nbgwt6/any_downside_to_proxmox/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1nbgwt6/any_downside_to_proxmox/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1nbgwt6/any_downside_to_proxmox/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I know very little about proxmox and Linux.  </p><p>I have a couple of machines running proxmox and I work hard not to fiddle and therefore break stuff. </p><p>I’m thinking about taking an otherwise unused laptop or mini pc to install Linux and learn and play.  </p><p>Is there any downside to starting with proxmox and then just have KVMs or LXCs with Linux distros to play with, vs installing the distro directly?</p><p>Thanks!</p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 08 Sep 2025 12:34:01 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1nbfjkx/debian_131_lxc_template_available_to_download_via/</link><title>Debian 13.1 LXC template available to download via the GUI.</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1nbfjkx/debian_131_lxc_template_available_to_download_via/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1nbfjkx/debian_131_lxc_template_available_to_download_via/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p><a href='https://www.reddit.com/r/Proxmox/comments/1nbfjkx/debian_131_lxc_template_available_to_download_via/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>I&#39;ve got some upgrades to plan. Alma 10 next please :)</p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 08 Sep 2025 11:10:16 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1nbc6o8/moving_from_vmware_to_proxmox_those_of_you_who/</link><title>Moving from VMWare to Proxmox. Those of you who made the switch- what do you know now that you wish you knew then?</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1nbc6o8/moving_from_vmware_to_proxmox_those_of_you_who/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1nbc6o8/moving_from_vmware_to_proxmox_those_of_you_who/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Proxmox/comments/1nbc6o8/moving_from_vmware_to_proxmox_those_of_you_who/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hello all - I&#39;ve been running a cluster of VMWare in my homelab/datacenter and my hardware is getting long in the tooth. Like an idiot, I made some snap purchases of new hardware that are not on the VMWare HCL so I&#39;ve decided to make the switch to Proxmox and have built a 2-node cluster that is attached to my existing two TrueNAS iSCSI targets.</p><p>I&#39;m going to start moving workloads from my VMWare cluster to my Proxmox cluster but before I do I want to learn from those who have gone before: what gotchas did you discover? I would hate to migrate my set of workloads off of servers on my VMWare cluster and start tearing things down only to discover Some Thing that forces me to rethink the way I&#39;ve done my deployment or worse, forces me to tear down and rebuild my new cluster because I&#39;ve unknowingly backed myself into a corner.</p><p>I&#39;m intentionally not going the Ceph route yet as my two TrueNas boxes are rock solid and have a lot of life left in them. Eventually I&#39;ll retire them for Ceph storage but I&#39;m very comfortable with iSCSI and don&#39;t want to move away from it just yet. I&#39;ve got enough on my plate and my credit card already cries from the two Proxmox node purchases I&#39;ve already made.</p><p>Edit: I added a Qdevice on one of my TrueNAS core boxes as an Ubuntu VM. I now have a three-vote quorum to avoid split brain. Thanks for the recommendation all!</p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 08 Sep 2025 08:08:00 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1nb9c0n/putting_spinners_to_sleep/</link><title>Putting spinners to sleep</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1nb9c0n/putting_spinners_to_sleep/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1nb9c0n/putting_spinners_to_sleep/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1nb9c0n/putting_spinners_to_sleep/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hi friends. I just finished setting up my new PM host with 4 8TB drives. I am not using them yet and would like for them to spin down when not in use. I estimate they are using about 35 watts of power. I did some searching and see that the hdparm -S 120 /dev/sdX command for each drive will do that. How can I get the commands to run automatically after I reboot the server?</p><p>Thanks a million for any advice.</p></div><!-- SC_ON --></section>]]></description><pubDate>Mon, 08 Sep 2025 05:49:23 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1naxr55/ive_made_a_webbased_vm_launcher/</link><title>I've made a web-based VM launcher</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1naxr55/ive_made_a_webbased_vm_launcher/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1naxr55/ive_made_a_webbased_vm_launcher/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1naxr55/ive_made_a_webbased_vm_launcher/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hi all,</p><p>I always wanted to have a macropad to start/stop my VM&#39;s. But I couldn&#39;t find a suitable device so I decided to use old phone/tablet (anything with the web browser).</p><p>I also added a filter - to hide the VM&#39;s which have the same GPU(or other hardware).</p><p>It is a simple python web server which shows the page. Just 2 dependencies: Flask and proxmoxer.</p><p><a href="https://preview.redd.it/a1ekpn6dxynf1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=690ca29ce19aeeefcba0878c6339200144d6740e">https://preview.redd.it/a1ekpn6dxynf1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=690ca29ce19aeeefcba0878c6339200144d6740e</a></p><p>Here is the link <a href="https://github.com/Yury-MonZon/ProxPad">https://github.com/Yury-MonZon/ProxPad</a></p><p>Feel free to suggest new features/PRs.</p><p>Update: non-proxmox macropad functions in the works now</p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 07 Sep 2025 22:00:42 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1nav011/im_completely_lost_in_storage/</link><title>I’m completely lost in storage</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1nav011/im_completely_lost_in_storage/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1nav011/im_completely_lost_in_storage/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Proxmox/comments/1nav011/im_completely_lost_in_storage/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hi everyone, I’m not new to Linux, but I am new to Proxmox. I’m currently testing with a new Proxmox install in my setup that previously ran Debian. </p><p>I managed to install Proxmox. Damn that was easy. Never had an install this easy. Great!</p><p>I then managed to run Plex in a LXC with automated setup. Runs very good too. The issue started when I wanted to add my existing library to this Plex instance. It again took me a few days to figure it out, and then solved it with just 1 command. Great again!!</p><p>Next step was creating a VM that again was easy with some online help. But for the love of God I just can’t get my existing hard drives with almost 8TB of data to become visible in that VM. </p><p>I tried to pass through the disk to the VM using the /disk/by-id method, but it seams that the VM then has to partition and format the disk to create some storage. So it passes the physical disk, but not its contents. </p><p>I found several other ways to get it going but none of them give me the result I want/need. </p><p>So at this point your help is needed and appreciated. </p><p>My end goal is running 1 VM, that runs Plex, SABNZBD and TranmissionBT. This won’t be the biggest problem. Literally every instruction I come by is about adding disks that can be wiped completely and that’s not going to work for me. </p><p>Can someone tell me the best way to get my disks allocated to that (or any) VM without completely wiping them and so that the content is available in the VM? An instruction or a link to one would be even better. </p><p>Many thanks in advance.</p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 07 Sep 2025 20:13:33 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1nauequ/restore_vms_using_veeam_to_proxmox_ve_905/</link><title>Restore VMs using Veeam to Proxmox VE 9.0.5 - Workaround!</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1nauequ/restore_vms_using_veeam_to_proxmox_ve_905/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1nauequ/restore_vms_using_veeam_to_proxmox_ve_905/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1nauequ/restore_vms_using_veeam_to_proxmox_ve_905/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p><strong>What&#39;s the problem?</strong></p><p>Veeam doesn&#39;t currently support Proxmox 9.0.5. Restoring old backups (e.g., when migrating from HyperV to Proxmox) fails because Veeam can&#39;t create the disks. This is caused by the VM version 10, which is the default version for VMs.  </p><p><strong>What&#39;s the workaround I&#39;m presenting here?</strong></p><p>The configuration of the new VM in Proxmox has to be &quot;manipulated&quot; at the right moment, because you can&#39;t influence Veeam&#39;s ability to always try to create a V10 VM. This isn&#39;t possible via the GUI because the VM is locked (CREATE LOCK).</p><p>Using ChatGPT, I created a small tool that waits for a new VM to be created (you have to specify the ID; Veeam always uses the next available ID) and then immediately downgrades the version to 9.2. This makes the restore work!</p><p>I hope this script might help others as well.</p><p><a href="https://github.com/fqfr/veeam-proxmox-workaround/tree/main">https://github.com/fqfr/veeam-proxmox-workaround/tree/main</a></p></div><!-- SC_ON --></section>]]></description><pubDate>Sun, 07 Sep 2025 19:49:40 +0530</pubDate></item><item><link>https://i.redd.it/ltpdsx31sqnf1.png</link><title>I'm always running low on RAM, so I wrote a script to quickly see which VM/LXC is the culprit (i.redd.it)</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1nasrvd/im_always_running_low_on_ram_so_i_wrote_a_script/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1nasrvd/im_always_running_low_on_ram_so_i_wrote_a_script/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1nasrvd/im_always_running_low_on_ram_so_i_wrote_a_script/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hi all, I&#39;m relatively RAM-constrained on my proxmox host, so wanted a way to get a quick visual of where the consumption is going. I worked with AI to generate a script, thought it might be useful to others.</p><p>And you can find the code on my Github page: <a href="https://github.com/micklynch/proxmox-ram-monitor">https://github.com/micklynch/proxmox-ram-monitor</a></p><p>Open to suggestions or feel free to open up a PR.<br/>(ToDo: Currently can&#39;t find the top process from the VMs).</p><p>Also, LMK if there is an existing way to do this. Cheers</p></div><!-- SC_ON --></section><section class='preview-image'><p>&nbsp;</p><img src='https://i.redd.it/ltpdsx31sqnf1.png' /></section>]]></description><pubDate>Sun, 07 Sep 2025 18:39:24 +0530</pubDate></item><item><link>https://i.redd.it/751tvans7nnf1.jpeg</link><title>Can’t create Ubuntu VM the “normal” way since upgrade to 9.0? (Debian, cloud-init, other VMs fine) (i.redd.it)</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1nag6kw/cant_create_ubuntu_vm_the_normal_way_since/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1nag6kw/cant_create_ubuntu_vm_the_normal_way_since/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/Proxmox/comments/1nag6kw/cant_create_ubuntu_vm_the_normal_way_since/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hi-</p><p>Have been creating VMs and LXCs for a while.  Hadn’t had a reason to create a fresh Ubuntu VM until today.  Creating Debian VMs works fine, tried a TrueNAS scale and a Home Assistant OS one.  No issues.  Can create a ubuntu VM using cloud-init if I want to.  But I don’t want to.  Using both 22.04 and 24.04 ISO’s, Ubuntu server install fails either when downloading a security update or installing the kernel.   </p><p>Most often says “internal server error” and lists the ipv6 address of the host.  However, it’s done a lot already that implies DNS is resolving and it’s getting access to archive.ubuntu.org.  If I go to shell from the installer I can ping, curl just fine to all sorts of addresses including archive.ubuntu.org.  But it fails in one of the two places here - either explicitly failed, or just hanging (I’ve included a screenshot of explicit failure, the hang happens after dozens of Get files from us.archive.ubuntu.com on a big Linux firmware file (537mb).  True whether I use q35 or i1440fx, SeaBIOS or UEFI, qemu or not, SCSI or SATA, whether I have ipv6 enabled on the host or not (by setting inet6 on vmbr0 to manual in /etc/network/interfaces), CPU type is x86-64-v2-AES or host, balooning device or not.  I’ve tried a lot of permutations.  Anyone else experiencing this?  Anyone have any bright ideas?</p></div><!-- SC_ON --></section><section class='preview-image'><p>&nbsp;</p><img src='https://i.redd.it/751tvans7nnf1.jpeg' /></section>]]></description><pubDate>Sun, 07 Sep 2025 06:40:05 +0530</pubDate></item><item><link>https://www.reddit.com/r/Proxmox/comments/1na2dub/debian_container_doesnt_boot_after_the_131_update/</link><title>Debian container doesn't boot after the 13.1 update</title><guid isPermaLink="true">https://www.reddit.com/r/Proxmox/comments/1na2dub/debian_container_doesnt_boot_after_the_131_update/</guid><comments>https://www.reddit.com/r/Proxmox/comments/1na2dub/debian_container_doesnt_boot_after_the_131_update/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/Proxmox/comments/1na2dub/debian_container_doesnt_boot_after_the_131_update/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Just a head up to warn that my debian lxc container doesn&#39;t boot anymore after the update from 13.0 to 13.1</p><p>Here is the error message :</p><pre><code>run_buffer: 571 Script exited with status 25lxc_init: 845 Failed to run lxc.hook.pre-start for container &quot;100&quot;__lxc_start: 2034 Failed to initialize container &quot;100&quot;</code></pre><p>I couldn&#39;t find a solution with google, just an unrelated old problem with binutils, I restored the CT from a backup, but I think it&#39;s caused by the update of systemd</p><p><strong>Edit</strong> : after more research on a test CT, it seems it&#39;s not the update of systemd inside the CT but the version 13.1 that is not supported by the starting script:</p><pre><code>DEBUG    utils - ../src/lxc/utils.c:run_buffer:560 - Script exec /usr/share/lxc/hooks/lxc-pve-prestart-hook 109 lxc pre-start produced output: unsupported debian version &#39;13.1&#39;</code></pre><p><strong>Edit 2</strong> : yep, it was that after changing the line 39 of the file /usr/share/perl5/PVE/LXC/Setup/Debian.pm</p><p>from</p><pre><code>die &quot;unsupported debian version &#39;$version&#39;\n&quot; if !($version &gt;= 4 &amp;&amp; $version &lt;= 13);</code></pre><p>to</p><pre><code>die &quot;unsupported debian version &#39;$version&#39;\n&quot; if !($version &gt;= 4 &amp;&amp; $version &lt;= 14);</code></pre><p>and the container starts again.</p></div><!-- SC_ON --></section>]]></description><pubDate>Sat, 06 Sep 2025 20:57:24 +0530</pubDate></item></channel></rss>
